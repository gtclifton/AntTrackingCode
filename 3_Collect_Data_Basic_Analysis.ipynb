{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all the data that has been tracked and associated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "from pympler.tracker import SummaryTracker\n",
    "from scipy import stats, signal\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn import linear_model\n",
    "import cv2\n",
    "import h5py\n",
    "from itertools import groupby\n",
    "from math import ceil\n",
    "import pickle\n",
    "import math\n",
    "from scipy.linalg import norm\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# %qtconsole\n",
    "%matplotlib qt5\n",
    "%matplotlib auto\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "from matplotlib.patches import Polygon, Ellipse\n",
    "from matplotlib import patches\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "sys.path.append('/home/gravishlab/Documents/Python/')\n",
    "sys.path.append('/home/gravishlab/Documents/Python/AntTrackCode')\n",
    "sys.path.append('/home/gravishlab/Documents/Python/Tracker/')\n",
    "sys.path.append('/home/gravishlab/Documents/Python/Tracker/Tracker/')\n",
    "from Tracker.Tracker import Tracker\n",
    "\n",
    "# import multiprocessing\n",
    "# import threading\n",
    "import subprocess\n",
    "from subprocess import call\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "\n",
    "# stop telling me i have a nan in an array with a logical comparison\n",
    "with np.errstate(invalid='ignore'):\n",
    "    np.less([np.nan, 0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build file list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Videos:  8266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8266"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_locations = '/media/gravishlab/SeagateExpansionDrive/AntTrack/'\n",
    "file_list = []\n",
    "\n",
    "# searches for files\n",
    "file_list = glob.glob(os.path.join(vid_locations, '**/**/*0000.mp4'))\n",
    "# file_list = glob.glob(os.path.join(vid_locations, 'Tunnel_20180329-30/**/*0000.mp4'))\n",
    "file_list = sorted(file_list)\n",
    "print('Total Number of Videos: ',len(file_list))\n",
    "                \n",
    "file_list = file_list\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.992 pixels per mm\n"
     ]
    }
   ],
   "source": [
    "# TUNNEL EXPERIMENTS\n",
    "pix2mm = 959.7563/30 # Measured 3cm in 4 cameras\n",
    "fps = 239.16\n",
    "\n",
    "v_multiplier=  fps / pix2mm\n",
    "print('%0.3f pixels per mm'%pix2mm)\n",
    "\n",
    "\n",
    "# ARENA EXPERIMENT\n",
    "# pix2cm = np.mean([ 3/np.mean([869.047, 873.866, 870.576]),  2/583.876])\n",
    "# print('Pixels per cm:', 1/(3/np.mean([869.047, 873.866, 870.576])),' and ', 1/(2/583.876))\n",
    "\n",
    "# BRIDGE EXPERIMENT\n",
    "# pix2cm = np.mean([ 2/np.mean([926.069, 930.107]),  2.4/1110.773, 2.5/1158.836])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: BUILD DATA SET AND SAVE AS PICKLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR EACH COLONY, BUILD DATA AND SAVE AS PICKLE\n",
    "\n",
    "vid_locations = '/media/gravishlab/SeagateExpansionDrive/AntTrack/'\n",
    "colonies = glob.glob(os.path.join(vid_locations, 'Tunnel**/'))\n",
    "# %run LoadInTrackedData.ipynb # load in function of interest\n",
    "from ipynb.fs.defs.LoadInTrackedData import load_and_analyze_videos_to_df\n",
    "\n",
    "for col in colonies:\n",
    "    print('\\n', col)\n",
    "    f_list = sorted(glob.glob(os.path.join(col, '**/*0000.mp4')))\n",
    "    load_and_analyze_videos_to_df(f_list)\n",
    "    \n",
    "\n",
    "# # LOAD IN DATA\n",
    "# %run LoadInTrackedData.ipynb\n",
    "# df, trial_info = load_and_analyze_videos_to_df(file_list)\n",
    "# # df, trial_info = load_and_analyze_videos_to_df(file_list)\n",
    "\n",
    "\n",
    "# # if just building trial list\n",
    "# # trial_info = create_trial_info(file_list)\n",
    "\n",
    "del f_list, col, colonies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find long trials and bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND LONG TRIALS \n",
    "# import random\n",
    "\n",
    "\n",
    "temp = df.copy()\n",
    "# look only at trials longer than 50fr\n",
    "idcs = [index for index, row in temp.iterrows() if len(row.v)>50]\n",
    "longtracks = df.loc[idcs,]\n",
    "\n",
    "# # MEDIAN V\n",
    "# colony_R = [col.split('20180')[-1][1:] for col in longtracks['colony'].values.tolist()]\n",
    "# date_days = [col[-2:] for col in longtracks['date'].values.tolist()]\n",
    "# day_R = [col.split('-').index(day) for day, col in zip(date_days, colony_R)]\n",
    "# subs_string = longtracks['substrate'].values.tolist()\n",
    "# substrate_R = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "# v_med_R = np.array(longtracks['median_v'])\n",
    "# df_med_R = pd.DataFrame( {\"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R,\n",
    "#                        \"v_med\" : v_med_R } )\n",
    "\n",
    "# del idcs, colony_R, day_R, substrate_R, v_med_R, date_days, subs_string, temp\n",
    "\n",
    "\n",
    "\n",
    "# # BOOTSTRAP\n",
    "# n_boot = 50;\n",
    "\n",
    "# # make a numpy array of each random sample for one entry in dataframe\n",
    "# sample = []\n",
    "# for boot in range(0,100):\n",
    "# #     sample.append( np.array([random.choice(tr) for tr in list(temp.v)]) )\n",
    "#     sample.append( np.array([random.choice(row.v) if len(row.v)>50 else np.nan for index, row in longtracks.iterrows() ]))\n",
    "    \n",
    "# # convert sample list into np array\n",
    "# allsamples = np.transpose(np.vstack(sample))\n",
    "# samplesubset = allsamples[:,0:n_boot]\n",
    "\n",
    "# # make new dataframe to be output to R as feather\n",
    "# shortcolnames = [col.split('20180')[-1][1:] for col in longtracks['colony'].values.tolist()]\n",
    "# colony_R = np.repeat(np.array(shortcolnames), n_boot)\n",
    "# date_days = [col[-2:] for col in longtracks['date'].values.tolist()]\n",
    "# col_days = [col.split('-').index(day) for day, col in zip(date_days, shortcolnames)]\n",
    "# day_R = np.repeat(np.array(col_days), n_boot)\n",
    "# subs_string = longtracks['substrate'].values.tolist()\n",
    "# subs_int = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "# substrate_R = np.repeat(subs_int, n_boot)\n",
    "# indiv_R = np.repeat(np.array(longtracks.index), n_boot)\n",
    "# df_R = pd.DataFrame( {\"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R,\n",
    "#                        \"indiv\" : indiv_R, \"v\" : np.concatenate(samplesubset)})\n",
    "\n",
    "# del allsamples, samplesubset, shortcolnames, colony_R, day_R, substrate_R, date_days, subs_string, subs_int, indiv_R, sample\n",
    "del temp\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually save things as pickle or feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13-14\n",
      "15-16\n",
      "20-21\n",
      "22-23\n",
      "24-25\n",
      "27-28\n",
      "29-30\n",
      "08-09\n",
      "    Done saving pickle\n"
     ]
    }
   ],
   "source": [
    "# SAVE DATAFRAME AS FEATHER\n",
    "# import time\n",
    "# import feather\n",
    "\n",
    "# # save master dataframe as pickle\n",
    "# df_preference = (df>0).astype(np.int8)\n",
    "# start_time = time.time()\n",
    "# df.to_pickle(vid_locations + 'AllTracks')#, compression='infer', protocol=4) \n",
    "# print('Saved all trackways dataframe as pickle - duration: ', time.time()-start_time)\n",
    "\n",
    "# save master dataframe with TDs for each colony\n",
    "# colonies = glob.glob(os.path.join(vid_locations, 'Tunnel**/'))\n",
    "# for col in colonies:\n",
    "#     col_OI = col.split('/')[-2][-5:]\n",
    "#     df.loc[(df['colony']!='Tunnel_201803'+col_OI)].to_pickle(vid_locations + '/AllTracks_TDs_%s'%col_OI, protocol = 4)#, compression='infer', protocol=4) \n",
    "#     print(col_OI)\n",
    "# print('    Done saving pickle')\n",
    "    \n",
    "# save master dataframe as feather\n",
    "# start_time = time.time()\n",
    "# # newdf = df[['ID','colony','datetime','date','median_v','substrate','x_raw']].copy()\n",
    "# # feather.write_dataframe(newdf, vid_locations + 'AllTracks.feather')\n",
    "# print('Saved all trackways dataframe as feather - duration: ', time.time()-start_time)\n",
    "\n",
    "# save long tracks dataframe as pickle\n",
    "# start_time = time.time()\n",
    "# longtracks.to_pickle(vid_locations + 'LongTracks')\n",
    "# print('Saved long trackways dataframe as pickle - duration: ', time.time()-start_time)\n",
    "\n",
    "# save long tracks dataframe as feather\n",
    "# start_time = time.time()\n",
    "# # feather.write_dataframe(longtracks, vid_locations + 'LongTracks.feather')\n",
    "# print('Saved long trackways dataframe as feathers - duration: ', time.time()-start_time)\n",
    "\n",
    "# print('Saved median and bootstrap files as feathers')\n",
    "# feather.write_dataframe(df_med_R, vid_locations + 'Median.feather')\n",
    "# # feather.write_dataframe(df_R, vid_locations + 'Bootstrap.feather')\n",
    "# del df_med_R, df_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD IN DATA FROM PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading in all trackways pickle\n",
      "   colony: 13-14\n",
      "   colony: 15-16\n",
      "   colony: 20-21\n",
      "   colony: 22-23\n",
      "   colony: 24-25\n",
      "   colony: 27-28\n",
      "   colony: 29-30\n",
      "   colony: 08-09\n",
      "read in all trackways pickle -- duration:  53.11151313781738\n"
     ]
    }
   ],
   "source": [
    "# LOAD IN DATA FROM PICKLE OR FEATHER (SKIP ALL NEXT DATAFRAME SECTIONS) - SPECIFY WHETHER TO INCLUDE TD DATA\n",
    "print('loading in all trackways pickle')\n",
    "start_time = time.time()\n",
    "colonies = glob.glob(os.path.join(vid_locations, 'Tunnel**/'))\n",
    "for col in colonies[0:]:\n",
    "    col_OI = col.split('/')[-2][-5:]\n",
    "    print('   colony: %s'%col_OI)\n",
    "    tmp = pd.read_pickle(vid_locations + 'AllTracks_' + col_OI)\n",
    "#     tmp = pd.read_pickle(vid_locations + 'AllTracks_TDs_' + col_OI)\n",
    "    if col == colonies[0]:\n",
    "        df = tmp.copy()\n",
    "    else:\n",
    "        df = pd.concat([df,tmp], ignore_index=True)\n",
    "    del tmp, col_OI\n",
    "print('read in all trackways pickle -- duration: ', time.time()-start_time)\n",
    "\n",
    "\n",
    "# load in master dataframe\n",
    "# print('loading in all trackways pickle')\n",
    "# start_time = time.time()\n",
    "# df = pd.read_pickle(vid_locations + 'AllTracks')\n",
    "# print('read in all trackways pickle -- duration: ', time.time()-start_time)\n",
    "\n",
    "# make list of trials\n",
    "# %run LoadInTrackedData.ipynb # loads all functions\n",
    "# from ipynb.fs.defs.LoadInTrackedData import create_trial_info # loads only one function\n",
    "# trial_info = create_trial_info(file_list)\n",
    "\n",
    "# load in dataframe of long trackways\n",
    "# start_time = time.time()\n",
    "# longtracks = pd.read_pickle(vid_locations + 'LongTracks')\n",
    "# print('read in all trackways pickle -- duration: ', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to delete a bunch of columns from a dataframe\n",
    "columns_to_drop = ['LA', 'RA', 'area', 'error', 'sinuosity',\n",
    "                  'xy_cov_matrix', 'median_vx', 'median_vy', 'measurements', 'xfilt','yfilt', 'x_final', 'y_final', 'vx_final', 'vy_final', 'v_final']\n",
    "for colmn in columns_to_drop:\n",
    "    if colmn in df: # remove columns if already exist\n",
    "        df = df.drop(colmn, axis = 1)\n",
    "\n",
    "# for joint_num in range(0,6):\n",
    "#     columns_to_drop = ['TD_dists_all', 'TD_dist_x', 'TD_dist_y', 'TD_dist_idcs',\n",
    "#                       'joint%i_TD_dists'%joint_num, 'joint%i_TD_dist_x'%joint_num, 'joint%i_TD_dist_y'%joint_num, 'joint%i_TD_dist_idcs'%joint_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT THINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot out all walking trajectories\n",
    "\n",
    "For each colony, plots out trajectories on each substrate. Good way of visualizing if there are pheromone paths etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND PHEROMONE TRAILS BASED ON Y LOCATION\n",
    "\n",
    "allsubs = [tr['substrate'] for tr in trial_info]\n",
    "subtypes = sorted(list(set(allsubs)))\n",
    "allcols = [tr['colony'] for tr in trial_info]\n",
    "coltypes = sorted(list(set(allcols)))\n",
    "wid = 1000\n",
    "hei = 550\n",
    "\n",
    "for coltype in coltypes:\n",
    "    plt.figure(figsize = (20,4))\n",
    "    plt.clf()\n",
    "    col_data = df.loc[df['colony'] == coltype]\n",
    "    \n",
    "    for kk, subtype in enumerate(subtypes):\n",
    "        dataOI = col_data.loc[col_data['substrate'] == subtype]\n",
    "        \n",
    "        # define subplot\n",
    "        spwid=0.23\n",
    "#         ax=plt.axes([0.05+spwid*int(kk), 0, spwid-.01-.07, 1])\n",
    "        \n",
    "        gs = gridspec.GridSpec(1,4)\n",
    "        gs.update(left = 0.05+spwid*int(kk), right = 0.05+spwid*(int(kk)+1), wspace = 0)\n",
    "        \n",
    "        # plot all traces\n",
    "        for index, row in dataOI.iterrows():\n",
    "            ax1 = plt.subplot(gs[0,:-1])\n",
    "            ax1.plot(row['x_raw'], row['y_raw'], '-k', linewidth = 1, alpha = 0.1)\n",
    "            ax1.set_xlim((0, wid))\n",
    "            ax1.set_ylim((0, hei))\n",
    "        ax1.set_aspect(1)\n",
    "        ax1.invert_yaxis()\n",
    "        if kk > 0:\n",
    "            ax1.get_yaxis().set_visible(False)\n",
    "#         n_long = len(longtracks.loc[longtracks['colony'] == coltype].loc[ longtracks['substrate'] == subtype ])\n",
    "#         plt.title(('%s -- n: %s -- n > 50 fr: %s' % (subtype, len(dataOI), n_long)), horizontalalignment = 'left', x = 0)\n",
    "        plt.title(('%s -- n: %s' % (subtype, len(dataOI))), horizontalalignment = 'left', x = 0)\n",
    "        \n",
    "#         # plot hist of all y values\n",
    "#         ax2 = plt.subplot(gs[0,-1])\n",
    "        \n",
    "#         # plotting through pandas\n",
    "# #         all_ys = pd.DataFrame( {\"y_raw\" : np.concatenate(dataOI['y_raw'].values)})\n",
    "# #         ax2=plt.axes([0.05+spwid*int(kk)+(spwid-0.07), .32, .07, .36])\n",
    "# #         all_ys['y_raw'].hist(orientation = 'horizontal', alpha = 0.5)\n",
    "\n",
    "#         # ploting through matplotlib\n",
    "#         all_ys = np.concatenate(dataOI['y_raw'].values)\n",
    "#         hist, bins = np.histogram(all_ys, bins = 20)\n",
    "#         barwidth = bins[1]-bins[0]\n",
    "#         centers = (bins[:-1]+bins[1:])/2                          \n",
    "#         ax2.barh(centers, hist, align = 'center', height = barwidth, alpha = 0.5)\n",
    "#         ax2.set_ylim(0,hei)\n",
    "#         ax2.set_ylim(ax2.get_ylim()[::-1])\n",
    "#         ax2.set_aspect(ax2.get_xbound()[1]/wid*3)\n",
    "#         ax2.get_yaxis().set_visible(False)\n",
    "#         ax2.get_xaxis().set_visible(False)\n",
    "#         ax2.set_frame_on(False)\n",
    "   \n",
    "#         # identify pheromone trails using mode\n",
    "#         ax1.axhline(centers[np.argmax(hist)],color='r', linestyle = '--', alpha = 0.5)\n",
    "#         ax2.axhline(centers[np.argmax(hist)],color='r', linestyle = '--', alpha = 0.5, xmax = 0.95)\n",
    "#         ax1.axhspan(centers[np.argmax(hist)]-2*barwidth, centers[np.argmax(hist)]+2*barwidth, color = 'r', alpha = 0.2)\n",
    "        \n",
    "#         # identify pheromone trails using median\n",
    "#         ax1.axhline(np.mean(all_ys), alpha = 0.5)\n",
    "#         ax1.axhspan(np.mean(all_ys)-np.std(all_ys), np.mean(all_ys)+np.std(all_ys), alpha = 0.2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.suptitle('Colony: %s' % coltype, x=0.02, y = 0.93, fontsize = 16, horizontalalignment = 'left')\n",
    "    \n",
    "    plt.savefig(vid_locations + 'Figures/' + 'PheromoneTrail_%s.png' % coltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT AND SAVE TRAJECTORIES FOR EACH HOUR OF RECORDING\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "\n",
    "alldates = [tr['date'] for tr in trial_info]\n",
    "alltimes = [tr['time'] for tr in trial_info]\n",
    "dates = sorted(list(set(alldates)))\n",
    "\n",
    "dpi = 300\n",
    "nfig = 0\n",
    "\n",
    "for date in dates:\n",
    "    print('Date: ', date)\n",
    "    whichones = [i for i,x in enumerate(alldates) if x == date]\n",
    "    todaystimes = [alltimes[x] for x in whichones]\n",
    "    todayshours = [int(x[0:2]) for x in todaystimes]\n",
    "    \n",
    "    \n",
    "    for hour  in list(range(0,24)):\n",
    "        whichoftoday = [whichones[i] for i,x in enumerate(todayshours) if \n",
    "                        (x == hour)]\n",
    "        tracksubset = [tracks[i] for i in whichoftoday]\n",
    "        trialnames = [file_list[i] for i in whichoftoday]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        plt.clf()\n",
    "        \n",
    "        num_flights = 0\n",
    "        cnt = 0\n",
    "        for cnt, track in enumerate(tracksubset):\n",
    "            if track != []:\n",
    "                for k, obj in track.items():\n",
    "\n",
    "                    if len(obj['x']) < 10:\n",
    "                        continue\n",
    "\n",
    "                    # plot with each trial as separate color IN PIXELS\n",
    "                    plt.plot(obj['xfilt'], obj['yfilt'], '-')\n",
    "\n",
    "                    # vary color based on velocity\n",
    "        #             plt.set_cmap('copper')\n",
    "        #             temp=obj['vfilt']/np.amax(obj['vfilt'])\n",
    "        #             plt.scatter(pix2cm*obj['xfilt'][1::], pix2cm*obj['yfilt'][1::], #'-' ,\n",
    "        #                      c=temp, edgecolor='none')#.tolist()).tolist()\n",
    "\n",
    "                    num_flights += 1\n",
    "\n",
    "#         print('Trials in hour ', hour, ': ', cnt) #whichoftoday)\n",
    "        plt.xlabel('x (cm)')\n",
    "        plt.ylabel('y (cm)')\n",
    "        plt.title('%s -- %d:00-%d:00.\\nn = %d' %(date, hour, hour+1,cnt) ,loc = 'left')\n",
    "        plt.gca().set_aspect(1)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.xlim((0, 1280))\n",
    "        plt.ylim((0, 700))\n",
    "        plt.gcf()\n",
    "        \n",
    "        # save figure\n",
    "        pname = os.path.join(vid_locations, 'Trackway%d.png'%(nfig))\n",
    "        plt.savefig(pname)\n",
    "        plt.close('all')\n",
    "        \n",
    "        nfig = nfig +1\n",
    "            \n",
    "# save images as movie\n",
    "os.system(\"ffmpeg -r 4 -i '\" + vid_locations  + \"Trackway%01d.png' -vcodec mpeg4 -y '\" \n",
    "          + vid_locations + \"Trackways.mp4'\")\n",
    "\n",
    "# delete all trackway vids\n",
    "pics2delete = glob.glob(os.path.join(vid_locations, 'Trackway*.png'))\n",
    "for pic in pics2delete:\n",
    "    os.remove(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIOLIN PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# violin plot of median speed vs. substrate FOR ALL TRIALS\n",
    "\n",
    "plt.figure()\n",
    "pltcolors = ['#464F56', '#BA4246', '#087E8B', '#701C6F']\n",
    "my_pal = {\"0mm\": '#464F56', \"1mm\": '#BA4246', \"3mm\": '#087E8B', \"5mm\": '#701C6F'}\n",
    "ax = sns.violinplot(x = 'substrate', y = 'median_v',  \n",
    "                    data = df[(df['v'].map(lambda x: np.sum(np.isfinite(x))>50).values) &\n",
    "                             (df['colony'] != 'Tunnel_20180508-09')], cut = 0 , palette=my_pal) #hue = 'substrate',\n",
    "ax.set_ylabel('median v [pix/s]')\n",
    "# sns.stripplot(x = 'treatment', y = 'mean_vx', hue = 'headwind', data = df, split = True, jitter = True)\n",
    "plt.gcf()\n",
    "# ax = sns.violinplot(x = 'substrate', y = 'median_v',  data = df, cut = 0 ) #hue = 'substrate',\n",
    "# add how many trials in each plot to figure\n",
    "# nobs = df['substrate'].value_counts().values\n",
    "nobs = df[df['v'].map(lambda x: np.sum(np.isfinite(x))>50).values]['substrate'].value_counts().values\n",
    "nobs = nobs[::-1]\n",
    "pos = range(len(nobs))\n",
    "\n",
    "# if want in mm/s\n",
    "plt.yticks(np.arange(0,1500, step = pix2mm*5), np.arange(0,int(1500/pix2mm), step = 5))\n",
    "ax.set_ylabel('median v [mm/s]')\n",
    "\n",
    "for tick,label in zip(pos, ax.get_xticklabels()):\n",
    "    ax.text(pos[tick], -20, ('n_tracks = ' + str(nobs[tick])), \n",
    "            horizontalalignment = 'center', size = 'x-small', weight = 'semibold')\n",
    "\n",
    "\n",
    "subtypes = sorted(list(set(df['substrate'])))\n",
    "for sub in subtypes:\n",
    "    print(\n",
    "        np.median(df[(df['v'].map(lambda x: np.sum(np.isfinite(x))>50).values) & (df['colony'] != 'Tunnel_20180508-09') & (df['substrate'] == sub)]['median_v'].values)/pix2mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make bootstrap histograms of speeds on each substrate\n",
    "\n",
    "# subsample all bootstraps\n",
    "lens = [50] #range(1,51,20)\n",
    "nfig = 0\n",
    "for n_boot in lens:\n",
    "    print(n_boot)\n",
    "#     print(n_boot)\n",
    "    boot_df = []\n",
    "    samplesubset = []\n",
    "    samplesubset = allsamples[:,0:n_boot]\n",
    "    boot_df = pd.DataFrame( {\"substrate\" : np.repeat(longtracks['substrate'].values, n_boot),\n",
    "                           \"v\" : np.concatenate(samplesubset), \"colony\" : np.repeat(longtracks['colony'].values, n_boot)})\n",
    "    \n",
    "    # FIGURE FOR ALL COLONIES\n",
    "    plt.figure()\n",
    "    ax = sns.violinplot(x = 'substrate', y = 'v',  data = boot_df, cut = 0 )\n",
    "    ax.set_ylabel('v [pix/s]')\n",
    "    plt.text(-.45,2400, 'All Colonies -- # iterations: %i' % n_boot)\n",
    "    plt.gca().set_ylim([0, 2500])\n",
    "    \n",
    "    # save figure\n",
    "    pname = os.path.join(vid_locations, 'Figures','Bootstrap_All.png')\n",
    "    plt.savefig(pname)\n",
    "    plt.close('all')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # FIGURE FOR EACH COLONY\n",
    "    # *** CAN I MAKE A LIST OF COLTYPES JUST FROM DF?\n",
    "    allcols = [tr['colony'] for tr in trial_info]\n",
    "    coltypes = list(set(allcols))\n",
    "\n",
    "    for coltype in sorted(coltypes):\n",
    "        plt.figure()\n",
    "        ax = sns.violinplot(x = 'substrate', y = 'v',  data = boot_df.loc[boot_df['colony'] == coltype], cut = 0 )\n",
    "        ax.set_ylabel('v [pix/s]')\n",
    "        ntr = len(boot_df.loc[boot_df['colony'] == coltype])/n_boot\n",
    "        plt.text(-.45,2400, '%s -- # trials: %i --- # iterations: %i' % (coltype, ntr, n_boot))\n",
    "        plt.gca().set_ylim([0, 2500])\n",
    "        \n",
    "        \n",
    "        # SAVE THINGS?\n",
    "#         pname = os.path.join(vid_locations, 'Figures', 'Bootstrap_%s.png'%(coltype))\n",
    "#         plt.savefig(pname)\n",
    "   # plt.close('all')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     nfig = nfig +1\n",
    "            \n",
    "# save images as movie\n",
    "# os.system(\"ffmpeg -r 4 -i '\" + vid_locations  + \"Bootstrap%02d.png' -vcodec mpeg4 -y '\" \n",
    "#           + vid_locations + \"Bootstrap.mp4'\")\n",
    "\n",
    "# delete all trackway vids\n",
    "# pics2delete = glob.glob(os.path.join(vid_locations, 'Bootstrap*.png'))\n",
    "# for pic in pics2delete:\n",
    "#     os.remove(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CINNAMON COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** DISTRIBUTION PLOT FOR PERCENT OF TOTAL DIST TRAVELED AT EACH SPEED FOR JUST CINNAMON TRIALS - FOR RIGHT AFTER BURST VS **\n",
    "def get_dist_traveled_df(x, var_OI, bins):\n",
    "    glenna=x[var_OI]/pix2mm\n",
    "    ordering = np.argsort(np.digitize(glenna,bins))\n",
    "    ordered = glenna[ordering]\n",
    "    split = np.split(ordered,np.where(np.diff(np.digitize(glenna,bins)[ordering])>0)[0]+1)\n",
    "    split_sum = np.array([np.sum(x) for x in split])\n",
    "    bin_idcs = np.unique(np.digitize(glenna,bins))\n",
    "    bin_sums = np.zeros(bins.shape)\n",
    "#     print(bin_idcs, [x[0] for x in split])\n",
    "    bin_sums[bin_idcs.astype(int)] = split_sum/fps\n",
    "    \n",
    "    return bin_sums\n",
    "\n",
    "longtracks = df[df['v'].map(lambda x: np.sum(np.isfinite(x))>50).values]\n",
    "\n",
    "var_OI = 'movave_v'\n",
    "sp_max = 60\n",
    "precision = 10 # how many bins per 1 unit\n",
    "bins = np.linspace(0,sp_max, sp_max*precision+1)\n",
    "longtracks['hist_dist'] =df.apply( get_dist_traveled_df, args = (var_OI, bins), axis=1)\n",
    "subtypes = sorted(list(set(df['substrate'])))\n",
    "\n",
    "plt.close('all')\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "time_starts = [80000, 90000]\n",
    "time_stops = [90000, 120000]\n",
    "percent_cutoff = 0.02\n",
    "\n",
    "plt.figure(figsize = (14,4))\n",
    "for coltype in ['Tunnel_20180508-09']:#coltypes[1:2]:\n",
    "    print( coltype)\n",
    "\n",
    "    for ss,subtype in enumerate(subtypes[0:4]):\n",
    "        ax = plt.subplot(1,4,ss+1)\n",
    "        print(' -- ', subtype)\n",
    "        sub_df = longtracks.loc[(longtracks['substrate']==subtype) & (longtracks['colony']==coltype)]\n",
    "        \n",
    "        # plot no cinnamon time\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: int(x)<90000)).values]['hist_dist']\n",
    "        total_dist_traveled = np.sum(vals_OI.sum())\n",
    "        hist_OI = vals_OI.sum()/total_dist_traveled\n",
    "#         plt.bar(bins, hist_OI , width =1/precision, color = 'k', alpha = 0.2, align = 'edge')\n",
    "        print(' -- -- total dist: %0.2f mm'%total_dist_traveled)\n",
    "        kde_data = np.repeat(bins+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "        kde = stats.gaussian_kde(kde_data)\n",
    "        kde_fit = kde.evaluate(bins)/precision\n",
    "        if ss == 0:\n",
    "            ref_speed = bins[np.argmax(kde_fit)]+1/(2*precision)\n",
    "            plt.xlabel('speed (mm/s)')\n",
    "            plt.ylabel('fraction of dist traveled')\n",
    "        plt.axvline(x=ref_speed, ymin = 0, ymax = 1, color = 'k', linestyle = ':', alpha = 0.4)\n",
    "        top_percent = np.flip(bins,0)[np.cumsum(np.flip(hist_OI,0))>percent_cutoff][0]\n",
    "        plt.axvline(x=top_percent, ymin = 0, ymax = 0.6, color = 'k', linestyle = '-', alpha = 0.4)\n",
    "        plt.plot(bins[hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '-', color = 'k', alpha = 0.4)\n",
    "        plt.text(30, 0.11/precision, '%i'%len(vals_OI), color = 'k', alpha = 0.4)\n",
    "        plt.text(40, 0.11/precision, '%0.2f cm'%(total_dist_traveled/10), color = 'k', alpha = 0.4)\n",
    "        \n",
    "        # plot cinammon time far from blast\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: (int(x)>=90000) & (int(x[-3])%5-1>=2))).values]['hist_dist']\n",
    "        total_dist_traveled = np.sum(vals_OI.sum())\n",
    "        hist_OI = vals_OI.sum()/total_dist_traveled\n",
    "#         plt.bar(bins[:-1], hist_OI , width =1/precision, color = pltcolors[ss], alpha = 0.05, align = 'edge')\n",
    "        kde_data = np.repeat(bins+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "        kde = stats.gaussian_kde(kde_data)\n",
    "        kde_fit = kde.evaluate(bins)/precision\n",
    "        plt.plot(bins[hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '--', color = pltcolors[ss], alpha = 0.5)\n",
    "        top_percent = np.flip(bins,0)[np.cumsum(np.flip(hist_OI,0))>percent_cutoff][0]\n",
    "        plt.axvline(x=top_percent, ymin = 0, ymax = 0.6, color = pltcolors[ss], linestyle = '--', alpha = 0.5)\n",
    "        plt.text(30, 0.10/precision, '%i'%len(vals_OI), color = pltcolors[ss], alpha = 0.5)\n",
    "        plt.text(40, 0.10/precision, '%0.2f'%(total_dist_traveled/10), color = pltcolors[ss], alpha = 0.5)\n",
    "        \n",
    "        # plot cinammon time close to blast\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: (int(x)>=90000) & (int(x[-3])%5-1<2))).values]['hist_dist']\n",
    "        total_dist_traveled = np.sum(vals_OI.sum())\n",
    "        hist_OI = vals_OI.sum()/total_dist_traveled\n",
    "#         plt.bar(bins[:-1], hist_OI , width =1/precision, color = pltcolors[ss], alpha = 0.3, align = 'edge')\n",
    "        kde_data = np.repeat(bins+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "        kde = stats.gaussian_kde(kde_data)\n",
    "        kde_fit = kde.evaluate(bins)/precision\n",
    "        plt.plot(bins[hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '-', color = pltcolors[ss])\n",
    "        top_percent = np.flip(bins,0)[np.cumsum(np.flip(hist_OI,0))>percent_cutoff][0]\n",
    "        plt.axvline(x=top_percent, ymin = 0, ymax = 0.6, color = pltcolors[ss], linestyle = '-')\n",
    "        plt.text(30, 0.09/precision, '%i'%len(vals_OI), color = pltcolors[ss], alpha = 1)\n",
    "        plt.text(40, 0.09/precision, '%0.2f'%(total_dist_traveled/10), color = pltcolors[ss], alpha = 1)\n",
    "        \n",
    "        plt.ylim([0, 0.12/precision])\n",
    "    #         plt.yscale('log')\n",
    "    #         plt.ylim([.0001, 1])\n",
    "        plt.xlim([0,sp_max])\n",
    "        if ss>0:\n",
    "            plt.gca().get_yaxis().set_visible(False)\n",
    "\n",
    "plt.savefig('cinnamon_distance.svg', transparency = True)\n",
    "\n",
    "\n",
    "\n",
    "# glenna=longtracks[var_OI].iloc[67]/pix2mm\n",
    "# ordering = np.argsort(np.digitize(glenna,bins))\n",
    "# ordered = glenna[ordering]\n",
    "# split = np.split(ordered,np.where(np.diff(np.digitize(glenna,bins)[ordering])==1)[0]+1)\n",
    "# split_sum = np.array([np.sum(x) for x in split])\n",
    "# bin_idcs = np.unique(np.digitize(glenna,bins))\n",
    "# bin_sums = np.zeros(bins.shape)\n",
    "# bin_sums[bin_idcs.astype(int)] = split_sum/fps\n",
    "\n",
    "\n",
    "# BAR PLOT OF CINNAMON STUFF:\n",
    "plt.figure(figsize=(3,8))\n",
    "cin_vals = np.full((3,4,2), np.nan)\n",
    "percent_cutoffs = [0.5,0.05,0.02]\n",
    "for pp, percent_cutoff in enumerate(percent_cutoffs):\n",
    "    plt.subplot(3,1,pp+1)\n",
    "    for ss,subtype in enumerate(subtypes[0:4]):\n",
    "        sub_df = longtracks.loc[(longtracks['substrate']==subtype) & (longtracks['colony']==coltype)]\n",
    "        \n",
    "        # no cinnamon:\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: int(x)<90000)).values]['hist_dist']\n",
    "        total_dist_traveled = np.sum(vals_OI.sum())\n",
    "        hist_OI = vals_OI.sum()/total_dist_traveled\n",
    "        top_percent = np.flip(bins,0)[np.cumsum(np.flip(hist_OI,0))>percent_cutoff][0]\n",
    "        cin_vals[pp, ss, 0] = top_percent\n",
    "        \n",
    "        # close to blast:\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: (int(x)>=90000) & (int(x[-3])%5-1<2))).values]['hist_dist']\n",
    "        total_dist_traveled = np.sum(vals_OI.sum())\n",
    "        hist_OI = vals_OI.sum()/total_dist_traveled\n",
    "        top_percent = np.flip(bins,0)[np.cumsum(np.flip(hist_OI,0))>percent_cutoff][0]\n",
    "        cin_vals[pp, ss, 1] = top_percent\n",
    "        \n",
    "        plt.plot(cin_vals[pp,ss,:], (4-ss)*np.ones(2), '.', color= pltcolors[ss])\n",
    "        plt.plot(cin_vals[pp,ss,:], (4-ss)*np.ones(2), '-', color= pltcolors[ss])      \n",
    "        plt.xlim((0,50))\n",
    "        plt.ylabel('cutoff: %0.2f'%percent_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ** DISTRIBUTION PLOT FOR PROPORTION OF TRIAL AT EACH SPEED FOR JUST CINNAMON TRIALS - FOR RIGHT AFTER BURST VS **\n",
    "plt.close('all')\n",
    "longtracks = df[df['v'].map(lambda x: np.sum(np.isfinite(x))>50).values]\n",
    "subtypes = sorted(longtracks['substrate'].unique())\n",
    "coltypes = sorted(longtracks['colony'].unique())\n",
    "\n",
    "var_OI = 'movave_v'\n",
    "sp_max = 55\n",
    "precision = 1 # how many bins per 1 unit\n",
    "bins = np.linspace(0,sp_max, sp_max*precision+1)\n",
    "\n",
    "\n",
    "longtracks['hist']=longtracks[var_OI].apply(lambda x: np.histogram(x/pix2mm, bins = bins)[0]/np.sum(np.isfinite(x)))\n",
    "\n",
    "pltcolors = ['#464F56', '#BA4246', '#087E8B', '#701C6F']\n",
    "\n",
    "time_starts = [80000, 90000]\n",
    "time_stops = [90000, 120000]\n",
    "\n",
    "\n",
    "plt.figure(figsize = (14,4))\n",
    "for coltype in ['Tunnel_20180508-09']:#coltypes[1:2]:\n",
    "    print( coltype)\n",
    "\n",
    "    for ss,subtype in enumerate(subtypes[0:4]):\n",
    "        ax = plt.subplot(1,4,ss+1)\n",
    "        print(subtype)\n",
    "        sub_df = longtracks.loc[(longtracks['substrate']==subtype) & (longtracks['colony']==coltype)]\n",
    "        \n",
    "        # plot no cinnamon time\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: int(x)<90000)).values]['hist']\n",
    "        hist_OI = vals_OI.mean()\n",
    "#         plt.bar(bins[:-1], hist_OI , width =1/precision, color = 'k', alpha = 0.2, align = 'edge')\n",
    "        kde_data = np.repeat(bins[:-1]+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "        kde = stats.gaussian_kde(kde_data)\n",
    "        kde_fit = kde.evaluate(bins[:-1])/precision\n",
    "        if ss == 0:\n",
    "            ref_speed = bins[np.argmax(kde_fit)]+1/(2*precision)\n",
    "        plt.axvline(x=ref_speed, ymin = 0, ymax = 1, color = 'k', linestyle = ':', alpha = 0.4)\n",
    "        plt.plot(bins[:-1][hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '-', color = 'k', alpha = 0.4)\n",
    "        plt.text(40, 0.09, 'n: %i'%len(vals_OI), color = 'k', alpha = 0.4)\n",
    "        \n",
    "        \n",
    "        # plot cinammon time far from blast\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: (int(x)>=90000) & (int(x[-3])%5-1>=2))).values]['hist']\n",
    "        hist_OI = vals_OI.mean()\n",
    "#         plt.bar(bins[:-1], hist_OI , width =1/precision, color = pltcolors[ss], alpha = 0.05, align = 'edge')\n",
    "        kde_data = np.repeat(bins[:-1]+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "        kde = stats.gaussian_kde(kde_data)\n",
    "        kde_fit = kde.evaluate(bins[:-1])/precision\n",
    "        plt.plot(bins[:-1][hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '--', color = pltcolors[ss], alpha = 0.5)\n",
    "        plt.text(40, 0.08, 'n: %i'%len(vals_OI), color = pltcolors[ss], alpha = 0.5)\n",
    "        \n",
    "        # plot cinammon time close to blast\n",
    "        vals_OI = sub_df.loc[(sub_df['time'].map(lambda x: (int(x)>=90000) & (int(x[-3])%5-1<2))).values]['hist']\n",
    "        hist_OI = vals_OI.mean()\n",
    "#         plt.bar(bins[:-1], hist_OI , width =1/precision, color = pltcolors[ss], alpha = 0.3, align = 'edge')\n",
    "        kde_data = np.repeat(bins[:-1]+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "        kde = stats.gaussian_kde(kde_data)\n",
    "        kde_fit = kde.evaluate(bins[:-1])/precision\n",
    "        plt.plot(bins[:-1][hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '-', color = pltcolors[ss])\n",
    "        plt.text(40, 0.07, 'n: %i'%len(vals_OI), color = pltcolors[ss], alpha = 1)\n",
    "        \n",
    "        \n",
    "        plt.ylim([0,0.12/precision])\n",
    "#         plt.yscale('log')\n",
    "#         plt.ylim([.0001, 1])\n",
    "        plt.xlim([0,55])\n",
    "\n",
    "        if ss==0:\n",
    "            plt.xlabel('windowed moving ave vel. (mm/s)')\n",
    "            plt.ylabel('fraction of recorded time')\n",
    "            \n",
    "del longtracks, sub_df, kde, kde_fit, ref_speed, kde_data, vals_OI, hist_OI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND PROPORTION OF FRAMES AT EACH SPEED FOR COLONY BEFORE AND AFTER PERTURBATION\n",
    "plt.close('all')\n",
    "longtracks = df[df['v_final'].map(lambda x: np.sum(np.isfinite(x))>50).values]\n",
    "subtypes = sorted(longtracks['substrate'].unique())\n",
    "coltypes = sorted(longtracks['colony'].unique())\n",
    "\n",
    "\n",
    "sp_max = 2000\n",
    "ac_max = 150000\n",
    "n_bins = int(1800/20)\n",
    "data_for_hist = []\n",
    "n_precision = 10000 # 100: one data point per 1% of time at that speed, 1000: one data point per 0.1% of time at that speed\n",
    "n_col = 8\n",
    "\n",
    "time_starts = [80000, 90000]\n",
    "time_stops = [90000, 120000]\n",
    "\n",
    "filmed_time = {}\n",
    "for timerange in range(0,2):\n",
    "\n",
    "    for coltype in ['Tunnel_20180508-09']:#coltypes[1:2]:\n",
    "        print( coltype)\n",
    "\n",
    "        for ss,subtype in enumerate(subtypes[0:4]):\n",
    "\n",
    "            counts_all = []\n",
    "            tmp = dict()\n",
    "            \n",
    "            # compile proportion of time in each velcoity bin for \n",
    "            number_of_frames = longtracks.loc[(longtracks['substrate']==subtype) & (longtracks['colony']==coltype) & \n",
    "                           (pd.to_numeric(longtracks['time'])> time_starts[timerange])& \n",
    "                           (pd.to_numeric(longtracks['time'])< time_stops[timerange])]['movave_v'].apply(lambda x: len(x)).sum()\n",
    "            filmed_time[timerange, ss] = number_of_frames/fps\n",
    "            print('timerange %i - %s - %i frames - %0.1f s'%(timerange, subtype, number_of_frames, filmed_time[trange, ss]))\n",
    "            for k,track in longtracks.loc[(longtracks['substrate']==subtype) & (longtracks['colony']==coltype) \n",
    "                                         & (pd.to_numeric(longtracks['time'])> time_starts[timerange])\n",
    "                                         & (pd.to_numeric(longtracks['time'])< time_stops[timerange])].iterrows():\n",
    "                counts, _ = np.histogram(track['movave_v'], bins=n_bins, range=(0,sp_max)) # average velocity over moving window\n",
    "#                 counts, _ = np.histogram(track['v_final'], bins=n_bins, range=(0,sp_max)) # instantaneous velocity\n",
    "#                 counts, _ = np.histogram(np.diff(track['v_final'])*240/np.diff(track['frames_final']), bins=n_bins, range=(0,ac_max)) # instantaneous accel\n",
    "                counts_all.append(counts/counts.sum())\n",
    "\n",
    "            counts_ave = np.mean(counts_all, axis=0)\n",
    "\n",
    "\n",
    "            # how much precision would you like (hundredths = *100)\n",
    "            vp_vs = np.repeat(np.linspace((sp_max/n_bins)/2,sp_max-(sp_max/n_bins)/2,n_bins), np.round(counts_ave*n_precision).astype(int)) # for velocities\n",
    "#             vp_vs = np.repeat(np.linspace((ac_max/n_bins)/2,ac_max-(ac_max/n_bins)/2,n_bins), np.round(counts_ave*n_precision).astype(int)) # for accelerations\n",
    "            tmp['substrate'] = subtype\n",
    "            tmp['colony'] = coltype\n",
    "            tmp['time'] = timerange\n",
    "            tmp['velocity'] = vp_vs\n",
    "            tmp['minute'] = \n",
    "    #         print(len(vp_vs))\n",
    "\n",
    "            data_for_hist.append(tmp)\n",
    "\n",
    "\n",
    "    tmp_df = pd.DataFrame(data_for_hist)\n",
    "    vp_df = pd.DataFrame( {\"substrate\" : np.repeat(tmp_df['substrate'].values, [len(a) for a in tmp_df['velocity']]),\n",
    "                            \"velocity\" : np.hstack(tmp_df['velocity']), \n",
    "                           \"colony\" : np.repeat(tmp_df['colony'].values, [len(a) for a in tmp_df['velocity']]),\n",
    "                          \"timerange\" : np.repeat(tmp_df['time'].values, [len(a) for a in tmp_df['velocity']]),\n",
    "                          })\n",
    "    \n",
    "\n",
    "# pre- and during perturbations for colonies 9+\n",
    "plt.figure(figsize = (5,7))\n",
    "ymax = 0.004\n",
    "pltcolors = ['r','g','c','b']\n",
    "\n",
    "for tt, trange in enumerate([1,0]):\n",
    "    for coltype in ['Tunnel_20180508-09']:\n",
    "        ax=plt.axes([0.15, 0.1+0.45*tt, 0.8, 0.35])\n",
    "        \n",
    "        comparison_curve,_ = np.histogram(vp_df.loc[\n",
    "            (vp_df['substrate']=='0mm') & (vp_df['colony']==coltype) & (vp_df['timerange']==0)]['velocity'].values,\n",
    "                                        bins = np.linspace(0,sp_max,n_bins+1))\n",
    "        bins = np.linspace(0,sp_max,n_bins+1)\n",
    "        flat_cutoff = np.argmax(comparison_curve)\n",
    "        plt.axvline(x=bins[flat_cutoff], ymin =0, ymax =10, c='r', ls=':')\n",
    "        plt.text(1300, 0.0022, '% above cutoff:', color = 'k')\n",
    "        plt.text(1300, 0.0036, 'max vel (mm/s):', color = 'k')\n",
    "\n",
    "        for ss,subtype in enumerate(subtypes[0:4]):\n",
    "            # FOR VELOCITY\n",
    "            data_OI = vp_df.loc[(vp_df['substrate']==subtype) & (vp_df['colony']==coltype)\n",
    "                                  & (vp_df['timerange']==trange)]['velocity']\n",
    "            sns.distplot(data_OI, bins = bins, label = '%s'%subtype, color = pltcolors[ss], kde_kws={'cut': 0})\n",
    "            curve,_ = np.histogram(data_OI.values, bins = bins)\n",
    "            curve_max = np.max(data_OI.values)\n",
    "            percent_above_cutoff = np.sum(curve[flat_cutoff:])/np.sum(curve)*100\n",
    "            plt.axvline(x=curve_max, ymin = 0, ymax = 0.1, c=pltcolors[ss], ls='-')\n",
    "            plt.text( 1300, 0.002-0.0002*ss, '%s - %0.1f = %0.1f s'%(subtype, percent_above_cutoff, \n",
    "                                                                   percent_above_cutoff/100*filmed_time[trange,ss]), color = pltcolors[ss] )\n",
    "            plt.text( 1300, 0.0034-0.0002*ss, '%s - %0.1f'%(subtype, curve_max/pix2mm), color = pltcolors[ss] )\n",
    "            \n",
    "            # FOR ACCEL\n",
    "#             sns.distplot(vp_df.loc[(vp_df['substrate']==subtype) & (vp_df['colony']==coltype)\n",
    "#                                   & (vp_df['timerange']==trange)]['velocity'], \n",
    "#                          bins = np.linspace(0,ac_max,n_bins+1), label = '%s'%subtype)\n",
    "        plt.title('%i to %i'%(time_starts[trange]/100, time_stops[trange]/100), loc = 'left')\n",
    "        \n",
    "#         plt.ylim((0,ymax))\n",
    "#         plt.xlim((0,sp_max))\n",
    "#         plt.gca().set_xticks(np.arange(0,1600, step = 500))\n",
    "#         plt.gca().set_xticklabels(np.arange(0,1600, step = 500))\n",
    "#         plt.gca().set_yticklabels(np.arange(0,ymax + 0.001, step = 0.001)*100)\n",
    "#         plt.gca().set_yticks(np.arange(0,ymax + 0.001, step = 0.001))\n",
    "        \n",
    "        # in mm/s\n",
    "        plt.ylim((0,ymax))\n",
    "        plt.xlim((0,sp_max))\n",
    "        plt.gca().set_xticks(np.arange(0,sp_max, step = 10*pix2mm))\n",
    "        plt.gca().set_xticklabels(np.arange(0,sp_max/pix2mm, step =  10))\n",
    "        plt.gca().set_yticklabels(np.arange(0,ymax + 0.001, step = 0.001)*100)\n",
    "        plt.gca().set_yticks(np.arange(0,ymax + 0.001, step = 0.001))\n",
    "        if tt ==0:\n",
    "            plt.xlabel('moving window ave. velocity (mm/s)')\n",
    "        else:\n",
    "            plt.xlabel('')\n",
    "        \n",
    "        \n",
    "        # accel in mm/s2\n",
    "#         pix2mm = 1000/32\n",
    "#         plt.ylim((0,0.00007))\n",
    "#         plt.xlim((0,ac_max))\n",
    "#         plt.gca().set_xticks(np.arange(0,ac_max, step = 1000*pix2mm))\n",
    "#         plt.gca().set_xticklabels(np.arange(0,ac_max/pix2mm/1000, step =  1))\n",
    "#         plt.xlabel('ac (m/s2)')\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        plt.ylabel('Percent of time')\n",
    "#         plt.gca().set_yscale('log')\n",
    "#         plt.ylim((1e-7,1e-2))\n",
    "\n",
    "# del longtracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot velocity profile for given trial\n",
    "\n",
    "takes the longest track from a given trial\n",
    "finds points that are within ROI\n",
    "plot points on first frame of video, outside of ROI = blue, inside ROI = colored by total speed\n",
    "plots velocity profile and histogram of inside ROI points\n",
    "\n",
    "part 2 plots ave dist or speed within a window and uses that to identify \"moving points\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT VELOCITY PROFILE FROM GIVEN TRACK\n",
    "\n",
    "tr_num = 405# 593#105 #91 #105\n",
    "videofile = df.video[tr_num]\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "cap.set(1,int(df.frames_final[tr_num][0])+1)\n",
    "ret, frame = cap.read()\n",
    "wid = frame.shape[1]\n",
    "hei = frame.shape[0]\n",
    "buffer = 60\n",
    "\n",
    "if not ret:\n",
    "    print('what happened?')\n",
    "    \n",
    "# draw ROI on image\n",
    "cv2.rectangle(frame, (0+buffer-1,0+buffer-1), (frame.shape[1]-buffer-1,frame.shape[0]-buffer-1),\n",
    "              (255,255,255), thickness=2, lineType=8, shift=0)\n",
    "\n",
    "# set figure features/colors\n",
    "plt.figure()\n",
    "pix2mm = 1000/32\n",
    "# plt.set_cmap('cool')\n",
    "# temp=track[longest_trial]['frames']/np.amax(track[longest_trial]['frames'])\n",
    "temp=np.array(df.v[tr_num])/pix2mm  #/np.amax(track[longest_trial]['vfilt'])\n",
    "# temp = np.append(temp, temp[len(temp)-1])\n",
    "atemp = np.diff(df.v[tr_num])/(np.diff(df.frames_final[tr_num]))*240/pix2mm # acceleration\n",
    "norm2 = colors.Normalize(vmin=0, vmax = 50)\n",
    "\n",
    "# plot trajectory on top of image of first frame\n",
    "ax1=plt.axes([0.1, 0.53, 0.9, 0.4])\n",
    "plt.title(videofile[51::])\n",
    "plt.imshow(frame)\n",
    "sc=plt.scatter(df.x[tr_num], df.y[tr_num], cmap=cm.cool, #'-' ,\n",
    "         c=temp, edgecolor='none', norm=norm2)\n",
    "plt.scatter(df.x[tr_num][1], df.y[tr_num][1], s=15, c=\"r\",\n",
    "        edgecolor='none')\n",
    "plt.xlim((0,wid-1));\n",
    "plt.ylim((0,hei-1));\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "# plot speed vs. frame\n",
    "ax2=plt.axes([0.12, 0.1, 0.6, 0.35])\n",
    "# plot moving points rectangles\n",
    "# pc = PatchCollection(rects, facecolor = 'r', alpha = 0.3, edgecolor = 'r')\n",
    "# ax2.add_collection(pc)\n",
    "plt.plot(df.frames_final[tr_num], temp, '-k');\n",
    "plt.scatter(df.frames_final[tr_num], temp, #'-' ,\n",
    "         cmap=cm.cool, c=temp, edgecolor='none', norm=norm2)\n",
    "# plt.plot(df.frames_final[tr_num], df.loc[tr_num].dist_90fr*(240/90),'.r', markersize = 1)\n",
    "plt.plot(df.frames_final[tr_num], np.array(df.loc[tr_num].v_movave)/pix2mm,'-r', markersize = 1)\n",
    "# plt.scatter(track[longest_trial]['frames'][1], track[longest_trial]['vfilt'][1], s=15, c=\"r\",\n",
    "#         edgecolor='none')\n",
    "plt.ylabel('speed (mm/s)')\n",
    "# plt.ylim((-20,35));\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # acceleration plot\n",
    "# ax3 = ax2.twinx()\n",
    "# plt.plot(df.frames_final[tr_num][:-1], atemp, '-g');\n",
    "# plt.ylim((-2000,3500));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT VELOCITY PROFILE OF LONGEST TRACK IN GIVEN VIDEO\n",
    "# Tests out methods of finding ROI points and moving points\n",
    "plt.close('all')\n",
    "import cv2\n",
    "\n",
    "#which video to look at?\n",
    "# 85 = good steady walking on 0mm\n",
    "# 550 = shows stopping and cut-off\n",
    "# 723 = 3 mm walking no stopping\n",
    "# 293 = steady 1 mm walking\n",
    "vid_num = 550\n",
    "# track = tracks[vid_num]\n",
    "videofile = file_list[vid_num]\n",
    "# videofile = np.unique(df['video'].values)[vid_num]\n",
    "track = df[df['video']==videofile]\n",
    "print(videofile)\n",
    "\n",
    "# how long are the trials?\n",
    "# lengths = [len(obj['x']) for k, obj in track.items()] # using variables generated (takes a long time to read in data vs. pickle of dataframe)\n",
    "lengths = [len(obj['x']) for index, obj in track.iterrows()] # using dataframe\n",
    "print('trial lengths: ', lengths)\n",
    "longest_trial = np.argmax(np.array(lengths))\n",
    "print('longest trial: ', longest_trial)\n",
    "# longest_trial = 1\n",
    "# trackOI = track[longest_trial] # using variable\n",
    "trackOI = track.loc[track.index[0]] # using dataframe\n",
    "print('len of track: ', len(trackOI['frames']))\n",
    "\n",
    "# load video for first frame\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "cap.set(1,trackOI['frames'][0]+1)\n",
    "ret, frame = cap.read()\n",
    "wid = frame.shape[1]\n",
    "hei = frame.shape[0]\n",
    "if not ret:\n",
    "    print('what happened?')\n",
    "    \n",
    "# find which frames are close to edge\n",
    "buffer = 60 \n",
    "edgeidcs = ((np.array(trackOI['x_raw']) < buffer) | (np.array(trackOI['x_raw']) > wid-(buffer+20)) | \n",
    "            (np.array(trackOI['y_raw']) < buffer) | (np.array(trackOI['y_raw']) > hei-buffer))\n",
    "ROIidcs = ~edgeidcs\n",
    "\n",
    "# draw ROI on image\n",
    "cv2.rectangle(frame, (0+buffer-1,0+buffer-1), (frame.shape[1]-buffer-20-1,frame.shape[0]-buffer-1),\n",
    "              (255,255,255), thickness=2, lineType=8, shift=0)\n",
    "    \n",
    "    \n",
    "# FIND MOVING POINTS\n",
    "ROIpts = trackOI['vfilt'][ROIidcs[0:-1]]\n",
    "ROIfrs = trackOI['frames'][0:-1][ROIidcs[0:-1]]\n",
    "Mov_val = []\n",
    "Mov_allfr = []\n",
    "\n",
    "\n",
    "# DISTANCE METHOD\n",
    "\n",
    "# variables\n",
    "b_wid = 10\n",
    "b_sep = 40\n",
    "dist_thres = 50 # pix/window - ~90 pix is 2 mm\n",
    "\n",
    "for fr in ROIfrs:\n",
    "    fr = int(fr)\n",
    "    \n",
    "    if fr - b_sep < 0:\n",
    "        continue\n",
    "        \n",
    "    # what frames do we want to measure position in\n",
    "    box1frs = np.array(range(int(fr) - b_wid - b_sep, int(fr) - b_sep))\n",
    "    box2frs = np.array(range(int(fr) + b_sep, int(fr) + b_sep + b_wid ))\n",
    "    \n",
    "    # if box frames aren't in track, do not keep point\n",
    "    box1idcs = np.isin(trackOI['frames'], box1frs) #np.searchsorted(trackOI['frames'], box1frs)\n",
    "    box2idcs = np.isin(trackOI['frames'], box2frs) \n",
    "    if ~np.any(box1idcs) | ~np.any(box2idcs):\n",
    "        # print('one of box frames is not in track - removing fr ', fr)\n",
    "        continue\n",
    "\n",
    "    # find ave location of ant in time box\n",
    "    box1x = np.mean(np.array(trackOI['x_raw'])[box1idcs])\n",
    "    box1y = np.mean(np.array(trackOI['y_raw'])[box1idcs])\n",
    "    box2x = np.mean(np.array(trackOI['x_raw'])[box2idcs])\n",
    "    box2y = np.mean(np.array(trackOI['y_raw'])[box2idcs])\n",
    "    dist_traveled = np.sqrt(np.power(box1x-box2x,2) + np.power(box1y-box2y,2))\n",
    "    \n",
    "    Mov_allfr = np.append(Mov_allfr, fr)\n",
    "    Mov_val = np.append(Mov_val, dist_traveled)\n",
    "\n",
    "Mov_fr = Mov_allfr[Mov_val>dist_thres] # frs when measure is above threshold\n",
    "Mov_val_keep = Mov_val[Mov_val>dist_thres] # vals when measure is above threshold\n",
    "Mov_idc = np.array([i for i, x in enumerate(trackOI['frames']) if x in Mov_fr]) # where in original data are moving points\n",
    "Mov_v = np.array([trackOI['vfilt'][i] for i in Mov_idc])\n",
    "\n",
    "    \n",
    "# MEDIAN SPEED METHOD\n",
    "wMov_val = []\n",
    "wMov_fr = []\n",
    "\n",
    "# variables\n",
    "win_wid = 12 # actually half the width\n",
    "nfr_cutoff = 20\n",
    "speed_cutoff = 2 # pix/win\n",
    "\n",
    "for fr in ROIfrs:\n",
    "    fr = int(fr)\n",
    "    winfrs = np.array(range(fr - win_wid, fr + win_wid))\n",
    "    winidcs = np.isin(trackOI['frames'], winfrs)\n",
    "    \n",
    "    if np.sum(winidcs) < nfr_cutoff:\n",
    "        continue   \n",
    "    win_medspeed = np.median(trackOI['vfilt'][winidcs[0:-1]])\n",
    "    win_meanspeed = np.mean(trackOI['vfilt'][winidcs[0:-1]])\n",
    "#     print(fr, ' - ', win_medspeed)\n",
    "    \n",
    "    wMov_fr = np.append(wMov_fr, fr)\n",
    "#     wMov_val = np.append(wMov_val, win_medspeed)\n",
    "    wMov_val = np.append(wMov_val, win_meanspeed)\n",
    "wMov_val_keep = wMov_val[[wfr in Mov_fr for wfr in wMov_fr]] # vals when measure is above threshold\n",
    "wMov_fr_keep = wMov_fr[[wfr in Mov_fr for wfr in wMov_fr]] # frs when measure is above threshold\n",
    "\n",
    "    \n",
    "# Find rectangles of when measurement is above threshold\n",
    "rects = []\n",
    "if len(Mov_fr)>2:\n",
    "    temp = np.diff(Mov_fr) > 1\n",
    "    find_stops = np.append(temp, True)\n",
    "    find_starts = np.append(np.array([True]),temp)\n",
    "    rect_starts = Mov_fr[find_starts]\n",
    "    rect_stops = Mov_fr[find_stops]\n",
    "else:\n",
    "    rect_starts = []\n",
    "    rect_stops = []\n",
    "\n",
    "for kk,rst in enumerate(rect_starts):\n",
    "#         print(kk)\n",
    "#         print(rst)\n",
    "#         print(rect_stops[kk]-rst)\n",
    "    rect = Rectangle([rst, 0], (rect_stops[kk]-rst), 40, angle=0)\n",
    "    rects.append(rect)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# PLOT THINGS\n",
    "\n",
    "# set figure features/colors\n",
    "plt.figure()\n",
    "# plt.set_cmap('cool')\n",
    "# temp=track[longest_trial]['frames']/np.amax(track[longest_trial]['frames'])\n",
    "temp=trackOI['vfilt']#/np.amax(track[longest_trial]['vfilt'])\n",
    "temp = np.append(temp, temp[len(temp)-1])\n",
    "norm2 = colors.Normalize(vmin=0, vmax = 40)\n",
    "\n",
    "# PANEL A\n",
    "# plot trajectory on top of image of first frame\n",
    "ax1=plt.axes([0.1, 0.53, 0.8, 0.4])\n",
    "plt.title(videofile[62::])\n",
    "plt.imshow(frame)\n",
    "# plt.plot(track[longest_trial]['xfilt'][edgeidcs], track[longest_trial]['yfilt'][edgeidcs], '-')\n",
    "plt.scatter(np.array(trackOI['x_raw'])[edgeidcs], np.array(trackOI['y_raw'])[edgeidcs], s=2, c=(0.1,0.1,0.6),\n",
    "        edgecolor='none')\n",
    "sc=plt.scatter(np.array(trackOI['x_raw'])[ROIidcs], np.array(trackOI['y_raw'])[ROIidcs], cmap=cm.cool, s=6, #'-' ,\n",
    "         c=temp[ROIidcs]/pix2mm, edgecolor='none', norm=norm2)\n",
    "plt.scatter(trackOI['x_raw'][1], trackOI['y_raw'][1], s=15, c=\"y\",\n",
    "        edgecolor='none')\n",
    "plt.xlim((0,wid-1));\n",
    "plt.ylim((0,hei-1));\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.colorbar(sc)\n",
    "\n",
    "\n",
    "# PANEL B\n",
    "# plot speed vs. frame\n",
    "ax2=plt.axes([0.08, 0.1, 0.6, 0.35])\n",
    "# plot moving points rectangles\n",
    "pc = PatchCollection(rects, facecolor = 'r', alpha = 0.1, edgecolor = [])\n",
    "ax2.add_collection(pc)\n",
    "# plot all data within ROI\n",
    "# plt.scatter(track[longest_trial]['frames'][0:-1][ROIidcs[0:-1]], track[longest_trial]['vfilt'][ROIidcs[0:-1]], #'-' ,\n",
    "#          cmap=cm.cool, c=temp[0:-1][ROIidcs[0:-1]], edgecolor='none', norm=norm2)\n",
    "# plot only moving points\n",
    "plt.scatter(Mov_fr, Mov_v/pix2mm, s=20, #'-' ,\n",
    "         cmap=cm.cool, c=Mov_v/pix2mm, edgecolor='none', norm=norm2)\n",
    "plt.plot(trackOI['frames'][0:-1], trackOI['vfilt']/pix2mm, '-k', alpha = 0.5);\n",
    "plt.scatter(trackOI['frames'][0], (trackOI['vfilt']/pix2mm)[0], s=15, c=\"y\",\n",
    "        edgecolor='none')\n",
    "plt.ylabel('speed (mm/s)')\n",
    "plt.ylim((0,40));\n",
    "plt.show()\n",
    "\n",
    "# Plot moving point measures - dist traveled/as speed\n",
    "ax3 = ax2.twinx()\n",
    "ax3.set_ylim((0,40/(240/90)));\n",
    "ax3.spines['right'].set_color('red')\n",
    "ax3.tick_params(axis= 'y', colors = 'red')\n",
    "ax3.yaxis.label.set_color('red')\n",
    "# plot as dist_traveled\n",
    "plt.scatter(Mov_allfr, Mov_val/pix2mm, s=3, c='r', edgecolor = 'None',alpha = 0.3)\n",
    "plt.scatter(Mov_fr, Mov_val_keep/pix2mm, s=3, c='r', edgecolor = 'None')\n",
    "plt.ylabel('net mm traveled/0.375s')\n",
    "\n",
    "# plot as speed\n",
    "# plt.scatter(Mov_allfr, Mov_val*(240/90), s=3, c='r', edgecolor = 'None')\n",
    "# plt.ylabel('net dist traveled per 1s [pix]')\n",
    "# plt.ylim((0,1500));\n",
    "\n",
    "# plot moving point measure - median/mean speed \n",
    "plt.sca(ax2)\n",
    "plt.plot(wMov_fr, wMov_val/pix2mm, 'g', alpha = 0.3)\n",
    "plt.scatter(wMov_fr_keep, wMov_val_keep/pix2mm, s=3, c='g', edgecolor = 'None')\n",
    "\n",
    "if len(Mov_v)>1:\n",
    "    # plot violine plot\n",
    "    # plt.subplots_adjust(bottom = 0.1, right = 0.8, top = 0.9)\n",
    "    hax =plt.axes([0.75, 0.1, 0.1, 0.35])\n",
    "    \n",
    "    # track[longest_trial]['vfilt'][ROIidcs[0:-1]]\n",
    "    hax.violinplot(Mov_v/pix2mm, showmeans = True, showmedians = True)\n",
    "    hax.get_xaxis().set_visible(False)\n",
    "    hax.get_yaxis().set_visible(False)\n",
    "    plt.ylim((0,40));\n",
    "#     hax.spines['right'].set_visible(False)\n",
    "#     hax.spines['top'].set_visible(False)\n",
    "#     hax.spines['bottom'].set_visible(False)\n",
    "#     hax.set_yticklabels([])\n",
    "#     hax.tick_params(direction = 'in')\n",
    "    hax.set_frame_on(False)\n",
    "    \n",
    "    \n",
    "    # average/median speed violin plot\n",
    "    haxME =plt.axes([0.8, 0.1, 0.1, 0.35])\n",
    "    parts = haxME.violinplot(wMov_val_keep/pix2mm, showmeans = True, showmedians = True)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('green')\n",
    "    for partname in ('cbars','cmins','cmaxes','cmeans','cmedians'):\n",
    "        pc = parts[partname]\n",
    "        pc.set_edgecolor('green')\n",
    "    haxME.get_xaxis().set_visible(False)\n",
    "    haxME.get_yaxis().set_visible(False)\n",
    "    haxME.set_frame_on(False)\n",
    "    plt.ylim((0,40));\n",
    "    haxME.patch.set_alpha(0)\n",
    "    \n",
    "    # dist traveled violin plot\n",
    "    haxMA =plt.axes([0.85, 0.1, 0.1, 0.35])\n",
    "    parts = haxMA.violinplot(Mov_val_keep/pix2mm, showmeans = True, showmedians = True)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('red')\n",
    "    for partname in ('cbars','cmins','cmaxes','cmeans','cmedians'):\n",
    "        pc = parts[partname]\n",
    "        pc.set_edgecolor('red')\n",
    "    haxMA.get_xaxis().set_visible(False)\n",
    "#     haxMA.get_yaxis().set_visible(False)\n",
    "    haxMA.spines['left'].set_visible(False)\n",
    "    haxMA.spines['top'].set_visible(False)\n",
    "    haxMA.spines['bottom'].set_visible(False)\n",
    "    haxMA.tick_params(direction = 'in')\n",
    "    haxMA.get_yaxis().tick_right()\n",
    "    haxMA.set_yticklabels([])\n",
    "#     haxMA.set_frame_on(False)\n",
    "    plt.ylim((0,40/(240/90)));\n",
    "    haxMA.patch.set_alpha(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot median speed vs. time\n",
    "# import matplotlib.dates as mdates\n",
    "# plt.figure(figsize=(16,6))\n",
    "# plt.plot(df.datetime, df.median_v, '.k')\n",
    "# alldates = [tr.date() for tr in df.datetime];\n",
    "# dates = sorted(list(set(alldates)))\n",
    "# lightson = [datetime.datetime.combine(d, datetime.time(6,59)) for d in dates]\n",
    "# lightsoff = [datetime.datetime.combine(d, datetime.time(19,9)) for d in dates]\n",
    "# lightsoff = [datetime.datetime.combine(dates[0], datetime.time(0,0))] + lightsoff\n",
    "# lightson = lightson + [datetime.datetime.combine(dates[-1], datetime.time(23,59)) ]\n",
    "\n",
    "# for loff,lon in zip(lightsoff,lightson):\n",
    "# #     print(loff, lon)\n",
    "#     plt.axvspan(loff,lon,facecolor='k',alpha = 0.2)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.ylabel('median v (pix/s)')\n",
    "# plt.text(datetime.datetime(2018,2,20,19,9), 1150,'webcam wont\\ntrigger\\nin dark', horizontalalignment='left')\n",
    "# plt.text(datetime.datetime(2018,2,21,9,30), 1150,'cant record\\nwhile\\nworking', horizontalalignment='left')\n",
    "# plt.text(datetime.datetime(2018,2,22,9,30), 1150,'short recording\\nsessions\\nwhile working', horizontalalignment='left')\n",
    "# plt.text(datetime.datetime(2018,2,22,19,9), 950,'fixed\\nnighttime\\ntriggering', horizontalalignment='left')\n",
    "# plt.text(datetime.datetime(2018,2,22,23,0), 1150,'computer\\nfroze\\novernight', horizontalalignment='left')\n",
    "# plt.text(datetime.datetime(2018,2,23,13,0), 1150,'wont trigger\\nuntil after \\n3min pause', horizontalalignment='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOINT TRAJECTORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot video of tracking on raw footage <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_101027_16276736-0000.mp4\n",
      "** Deleted Model_Predictions.mp4 file\n",
      "saving Model_Predictions.mp4 file\n"
     ]
    }
   ],
   "source": [
    "# plot images with tracked data on it\n",
    "tr_num = 105#105 #91 #105\n",
    "videofile = df.video[tr_num]\n",
    "print(videofile)\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "plt.close('all')\n",
    "\n",
    "def WRTant_to_WRTframe(val_x, val_y, frame_center_x, frame_center_y, ant_ang_deg):\n",
    "    ant_ang = ant_ang_deg *np.pi/180\n",
    "    R = np.array([[np.cos(ant_ang), -1*np.sin(ant_ang)],\n",
    "                  [np.sin(ant_ang),    np.cos(ant_ang)]])\n",
    "    rotated_vals = np.dot(R,np.array([val_x-100,val_y-100]))\n",
    "    translated_vals = rotated_vals*np.array([1,1]) + np.array([frame_center_x, frame_center_y])  \n",
    "    return translated_vals[0], translated_vals[1];\n",
    "\n",
    "def plot_ant_pt(ant_part, ant_part_num, df, tr_num, fr_num, ant_x, ant_y, ant_ang_deg, buffer):\n",
    "    x = df['%s%i_x'%(ant_part,ant_part_num)][tr_num][fr_num]\n",
    "    y = df['%s%i_y'%(ant_part,ant_part_num)][tr_num][fr_num]\n",
    "    conf = df['%s%i_conf'%(ant_part,ant_part_num)][tr_num][fr_num]\n",
    "    (newx, newy) = WRTant_to_WRTframe(x, y, ant_x, ant_y, ant_ang_deg)\n",
    "#     print('old vals: %i, %i  TO %0.1f, %0.1f'%(x,y,newx, newy))\n",
    "\n",
    "    # define colormap to show confidence\n",
    "    norm2 = colors.Normalize(vmin=0, vmax=1)\n",
    "    plt.scatter(newx+buffer, newy+buffer, c = conf, s = 10, cmap = cm.bwr,\n",
    "               edgecolor = 'none', norm=norm2)# '.g')\n",
    "    return;\n",
    "\n",
    "def save_image(vlocation, nfig, name_base):\n",
    "    pname = os.path.join(vlocation, '%s%d.png'%(name_base,nfig))\n",
    "    plt.savefig(pname)\n",
    "    nfig = nfig + 1\n",
    "    plt.pause(0.2)\n",
    "#     plt.close('all')\n",
    "    return nfig\n",
    "\n",
    "def save_video(vlocation, name_base):\n",
    "    # save images as movie\n",
    "    if os.path.isfile((vlocation+'/%s.mp4'%name_base)):\n",
    "        os.remove(vlocation + \"/%s.mp4\"%name_base)\n",
    "        print('** Deleted %s.mp4 file'%name_base)\n",
    "    print('saving %s.mp4 file'%name_base)\n",
    "    command_p1 = \"ffmpeg -r 20 -i '%s/%s\"%(vlocation, name_base)\n",
    "    command_p2 = \" -vcodec libx264 '%s/%s.mp4'\"%(vlocation, name_base)\n",
    "    command = command_p1 + \"%01d.png'\" + command_p2\n",
    "#     print(command)\n",
    "    os.system(command)\n",
    "    plt.pause(10)\n",
    "\n",
    "    # delete all trackway vids\n",
    "    pics2delete = glob.glob(os.path.join(vlocation, '%s*.png'%name_base))\n",
    "    for pic in pics2delete:\n",
    "        os.remove(pic)\n",
    "    return\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "for im_n, fr_OI in enumerate( df.frames_final[tr_num]):\n",
    "    plt.clf()\n",
    "    # load frame\n",
    "    ff=np.where(df.frames[tr_num]==fr_OI)[0][0]\n",
    "    cap.set(1,int(fr_OI))\n",
    "    ret, frame = cap.read()\n",
    "    x_dim = frame.shape[1]\n",
    "    y_dim = frame.shape[0]\n",
    "    \n",
    "    # load ant x, y and angle\n",
    "    x = df.x_raw[tr_num][ff]\n",
    "    y = df.y_raw[tr_num][ff]\n",
    "    ang = df.angle_improved[tr_num][ff]\n",
    "    (thorax_x, thorax_y) = WRTant_to_WRTframe(df.thorax_x[tr_num][ff], df.thorax_y[tr_num][ff], x, y, ang)\n",
    "#     print(x,y,ang)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # PLOT THINGS\n",
    "    ax1=fig.add_axes([0.03,0.1, 0.5, 0.3])\n",
    "    ax1.set_position([0.03,0.1, 0.5, 0.3])\n",
    "    plt.imshow(frame)\n",
    "    plt.plot(x, y, '.w')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    ax2=fig.add_axes([0.35,0.1, 0.7, 0.7]) #plt.axes()\n",
    "#     ax2.set_position([0.35,0.1, 0.7, 0.7], which = 'both')\n",
    "    # zoom into around ant\n",
    "    buffer = 150\n",
    "    blank_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer,3),dtype=np.uint8)* 1# 1.001# np.max(temp) # gray background  1.0001#\n",
    "    bframe = blank_frame.copy()\n",
    "    bframe[buffer:-buffer, buffer:-buffer,:] = frame\n",
    "    if not np.isnan(ang):\n",
    "        xrange = range(int(round(thorax_x)), int(round(thorax_x+2*buffer)))\n",
    "        yrange = range(int(round(thorax_y)), int(round(thorax_y+2*buffer)))\n",
    "    else:\n",
    "        xrange = range(int(round(x)), int(round(x+2*buffer)))\n",
    "        yrange = range(int(round(y)), int(round(y+2*buffer)))\n",
    "    xrange_actual = np.array(sorted(list( set(xrange) & set(range(0, x_dim+2*buffer) ) )))[[0,-1]]\n",
    "    yrange_actual = np.array(sorted(list( set(yrange) & set(range(0, y_dim+2*buffer) ) )))[[0,-1]]\n",
    "    frame_zoom = bframe[np.ix_(yrange_actual, xrange_actual)]\n",
    "    plt.xlim(xrange_actual)\n",
    "    plt.ylim(yrange_actual)\n",
    "    plt.text(xrange_actual[0]+20, yrange_actual[0]+20, 'Fr: %i'%fr_OI, color='w')\n",
    "    plt.imshow(bframe)\n",
    "    cmap = cm.bwr\n",
    "    plt.scatter(x+buffer, y+buffer, s=20, c=np.array(0.5), \n",
    "            norm = colors.Normalize(vmin=0, vmax=1), marker= 'o')\n",
    "    \n",
    "    \n",
    "    if not np.isnan(ang):\n",
    "        plt.scatter(thorax_x+buffer, thorax_y+buffer, c = df.thorax_conf[tr_num][ff], s = 10, \n",
    "                cmap = cmap, norm = colors.Normalize(vmin=0, vmax=1))\n",
    "        for jj in range(0,6):\n",
    "            plot_ant_pt('joint',jj, df, tr_num, ff, x, y, ang, buffer)\n",
    "        for aa in range(0,2):\n",
    "            plot_ant_pt('antenna',aa, df, tr_num, ff, x, y, ang, buffer)\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    cax = plt.axes([0.93,0.1,0.02,0.7])\n",
    "    plt.colorbar(cax=cax)\n",
    "    plt.clim(0,1)\n",
    "    plt.set_cmap(cm.bwr)\n",
    "    \n",
    "    \n",
    "    vlocation = '/media/gravishlab/SeagateExpansionDrive/AntTrack'\n",
    "    save_image(vlocation, im_n, 'Model_Predictions')\n",
    "save_video(vlocation, 'Model_Predictions')\n",
    "    #     plt.pause(0.1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to analyze tracked data, removing low confidence points and lowpass filter -- apply to individual trial/limb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080521_16276736-0000.mp4\n",
      "before removing outliers:  46  nan of  118\n",
      "after removing outliers:  54  nan of  118\n",
      "final filter len:  44  nan of  118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "# INTERPOLATING AND LOWPASS FILTERING FUNCTIONS\n",
    "\n",
    "def remove_lowconf_pts(arr, conf, conf_cutoff, jump_limit):\n",
    "    arr_highconf = arr.copy()\n",
    "    # get rid of low confidence pts\n",
    "    arr_highconf[conf<conf_cutoff]=np.nan\n",
    "    return arr_highconf\n",
    "\n",
    "def remove_jumps(arr, jump_limit):\n",
    "    yy = np.isnan(arr)\n",
    "    xx = range(len(yy))\n",
    "    arr_nojump = np.empty(yy.shape)*np.nan\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == False: # if is not a group of nan\n",
    "            g = np.array(list(g))\n",
    "#             print(len(g))\n",
    "            if len(g)>3:\n",
    "                # get rid of drastic changes\n",
    "                if jump_limit != None:\n",
    "                    arr_OI = arr[g]\n",
    "                    d_arr = np.abs(np.diff(arr_OI))\n",
    "                    d_jump = np.abs(d_arr) > jump_limit\n",
    "                    d_jump_cumsum = np.cumsum(np.insert(d_jump,0,0))\n",
    "                    d_jump_opp = (d_jump_cumsum%2).astype(bool)\n",
    "                    if np.sum(d_jump_opp==True)>np.sum(d_jump_opp == False):\n",
    "                        d_jump_opp = np.logical_not(d_jump_opp)\n",
    "                    arr_OI[d_jump_opp]=np.nan\n",
    "                arr_nojump[g]=arr_OI\n",
    "                    \n",
    "    return arr_nojump\n",
    "    \n",
    "\n",
    "\n",
    "def middle_half(alist, wanted_parts=4):\n",
    "    alist= alist[np.logical_not(np.isnan(alist))]\n",
    "    length = len(alist)\n",
    "    sections = np.array([ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ])\n",
    "    middle_half = np.concatenate(sections[1:3])\n",
    "    if not len(middle_half)>0:\n",
    "        return  np.nan, np.nan\n",
    "    else:\n",
    "        full_range = (np.max(alist)-np.min(alist))\n",
    "        middle_range = (np.max(middle_half)-np.min(middle_half))\n",
    "        med = np.mean(middle_half)\n",
    "#         print(middle_range/full_range)\n",
    "        if middle_range/full_range < 0.93: # theoretically for normal distribution mid_range/full_range = 0.16625\n",
    "#             print('not  normal dist')\n",
    "            sigma = middle_range/3\n",
    "#             print('removed outliers')\n",
    "        else:\n",
    "            sigma = full_range/4\n",
    "#         print(med, sigma)\n",
    "    return med, sigma\n",
    "\n",
    "def remove_outliers(arr):\n",
    "    med, sigma = middle_half(arr)\n",
    "    where_far_away = (np.abs(arr-med)> 2*sigma)\n",
    "    arr[where_far_away]=np.nan\n",
    "    return arr\n",
    "\n",
    "def remove_outliers2d(arr_x, arr_y):\n",
    "    med_x, sigma_x = middle_half(arr_x)\n",
    "    med_y, sigma_y = middle_half(arr_y)\n",
    "#     if sigma_x < 15:\n",
    "#         sigma_x = 15\n",
    "    where_far_away = np.logical_or(np.abs(arr_x-med_x)> 2*sigma_x, np.abs(arr_y-med_y)> 2*sigma_y)\n",
    "#     print('removing %i outliers'%np.sum(where_far_away))\n",
    "    arr_x[where_far_away]=np.nan\n",
    "    arr_y[where_far_away]=np.nan\n",
    "    return arr_x, arr_y\n",
    "\n",
    "def remove_outliers(arr_x, arr_y):\n",
    "    med_x, sigma_x = middle_half(arr_x)\n",
    "    med_y, sigma_y = middle_half(arr_y)\n",
    "    \n",
    "    where_far_away = np.logical_or(np.abs(arr_x-med_x)> 2*sigma_x, np.abs(arr_y-med_y)> 2*sigma_y)\n",
    "    arr_x[where_far_away]=np.nan\n",
    "    arr_y[where_far_away]=np.nan\n",
    "    \n",
    "    return arr_x, arr_y\n",
    "\n",
    "def find_nan_gaps(arr, limit):  \n",
    "    yy = np.isnan(arr)\n",
    "    xx = range(len(yy))\n",
    "    where_gapOI = np.full(arr.shape, False)\n",
    "    where_othergaps = np.full(arr.shape, False)\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == True: # if is a group of nan\n",
    "            g = list(g)\n",
    "            if any(x in g for x in [0, len(arr)-1]): # if first or last group\n",
    "                where_othergaps[np.array(g)]=True\n",
    "#                 print('remove: ', len(g), g)\n",
    "                continue\n",
    "                \n",
    "            if len(g)<= limit: # length is below limit\n",
    "                where_gapOI[np.array(g)]=True\n",
    "#                 print('interp: ', len(g), g)\n",
    "            else:\n",
    "                where_othergaps[np.array(g)]=True\n",
    "#                 print('remove: ', len(g), g)\n",
    "    return where_gapOI, where_othergaps\n",
    "\n",
    "def find_interp_idcs(where_interpolate):\n",
    "    interp_idcs = []\n",
    "    for val in [-1,0,1]:\n",
    "        interp_idcs = np.concatenate([interp_idcs,np.where(where_interpolate)[0]+val])\n",
    "    interp_idcs = np.sort(np.array(list(set(interp_idcs)))) # get of repeat elements\n",
    "    interp_idcs = interp_idcs[np.logical_and(interp_idcs>-1, interp_idcs < len(where_interpolate))].astype(np.uint32) # only elements in range\n",
    "    return interp_idcs\n",
    "\n",
    "def interp_vals(arr, interp_idcs): # array includes nan values\n",
    "    interp = arr.copy()\n",
    "    if len(interp_idcs)>0:\n",
    "        temp = arr[interp_idcs]\n",
    "        interpolated_vals = np.interp(\n",
    "            interp_idcs, \n",
    "            interp_idcs[np.logical_not(np.isnan(temp))], temp[np.logical_not(np.isnan(temp))] )\n",
    "        interp[interp_idcs] = interpolated_vals\n",
    "    return interp\n",
    "    \n",
    "def lowpass_filt_sections(arr):\n",
    "    yy = np.isnan(arr)\n",
    "    xx = range(len(yy))\n",
    "    full_filtered = np.empty(yy.shape)*np.nan\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == False: # if is a group of nan\n",
    "            g = list(g)\n",
    "#             print('section to lowpass fitler: ', len(g))\n",
    "            if len(g)>9:\n",
    "                b, a = signal.butter(2,0.3,btype='low')\n",
    "                filtered = signal.filtfilt(b, a, arr[np.array(g)])\n",
    "                full_filtered[np.array(g)]=filtered\n",
    "    return full_filtered\n",
    "\n",
    "\n",
    "\n",
    "def interpolate_filter_tracking(df, tr_num, tracked_pt, conf_cutoff, jump_limit, nan_gap_limit, plots = False):\n",
    "    \n",
    "    all_frames = df['frames'][tr_num]\n",
    "    frames_OI = df['frames_final'][tr_num]\n",
    "    frames_OI_idcs = np.isin(all_frames, frames_OI)\n",
    "    \n",
    "    # initialize variables\n",
    "    joint_x, joint_y, x_offset, y_offset, conf, \\\n",
    "    joint_x_highconf, joint_y_highconf, joint_x_interp, joint_y_interp, joint_x_filt, joint_y_filt = \\\n",
    "    (np.empty(all_frames.shape)*np.nan for i in range(11))\n",
    "    \n",
    "    # set up variables\n",
    "    joint_x = df['%s_x'%tracked_pt][tr_num]\n",
    "    joint_y = df['%s_y'%tracked_pt][tr_num]\n",
    "    if tracked_pt != 'thorax': # account for inaccurate initial guess of body center, make relative to LEAP tracked thorax\n",
    "        if 'thorax_x_filt' in df:\n",
    "            x_offset = df['thorax_x_filt'][tr_num]\n",
    "            y_offset = df['thorax_y_filt'][tr_num]\n",
    "        else:\n",
    "            x_offset = df['thorax_x'][tr_num]\n",
    "            y_offset = df['thorax_y'][tr_num]\n",
    "        joint_x = joint_x - x_offset\n",
    "        joint_y = joint_y - y_offset\n",
    "    conf = df['%s_conf'%tracked_pt][tr_num]\n",
    "    joint_x_highconf = remove_lowconf_pts(joint_x, conf, conf_cutoff, jump_limit)\n",
    "    joint_y_highconf = remove_lowconf_pts(joint_y, conf, conf_cutoff, jump_limit)\n",
    "    \n",
    "    # remove big jumps\n",
    "    joint_x_highconf = remove_jumps(joint_x_highconf, jump_limit)\n",
    "    joint_y_highconf = remove_jumps(joint_y_highconf, jump_limit)\n",
    "    \n",
    "    # remove outliers\n",
    "    print('before removing outliers: ', np.sum(np.isnan(joint_x_highconf)), ' nan of ', len(joint_x_highconf) )\n",
    "    joint_x_highconf, joint_y_highconf = remove_outliers2d(joint_x_highconf, joint_y_highconf)\n",
    "    print('after removing outliers: ', np.sum(np.isnan(joint_x_highconf)), ' nan of ', len(joint_x_highconf) )\n",
    "    \n",
    "    # interpolate \n",
    "    where_interpolate, where_remove = find_nan_gaps(joint_x_highconf, nan_gap_limit)\n",
    "    joint_x_interp = interp_vals(joint_x_highconf, find_interp_idcs(where_interpolate))\n",
    "    joint_y_interp = interp_vals(joint_y_highconf, find_interp_idcs(where_interpolate))\n",
    "\n",
    "    # lowpass filter\n",
    "    joint_x_filt = lowpass_filt_sections(joint_x_interp)\n",
    "    joint_y_filt = lowpass_filt_sections(joint_y_interp)\n",
    "#     print(joint_x_filt.shape)\n",
    "    \n",
    "    if plots:\n",
    "        # PLOT THINGS\n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        ax1=plt.subplot(2,1,1)\n",
    "        ax_limits=[]\n",
    "        ax_limits.append([np.nanmin(joint_x)-10, np.nanmax(joint_x)+10])\n",
    "        ax2 = plt.subplot(2,1,2)\n",
    "        ax_limits.append([np.nanmin(joint_y)-10, np.nanmax(joint_y)+10])\n",
    "\n",
    "        for xx,ax in enumerate([ax1, ax2]):\n",
    "            for kk, inter in enumerate(all_frames[where_interpolate]):\n",
    "                if kk == 0:\n",
    "                    rect = Rectangle((inter-0.5, ax_limits[xx][0]),\n",
    "                                     1, np.diff(ax_limits[xx]), alpha = 0.2, fc = 'm', ec = None, label = 'interpolated')\n",
    "                else:\n",
    "                    rect = Rectangle((inter-0.5, ax_limits[xx][0]),\n",
    "                                     1, np.diff(ax_limits[xx]), alpha = 0.2, fc = 'm', ec = None)\n",
    "                ax.add_patch(rect)\n",
    "            for kk,remov in enumerate(all_frames[where_remove]):\n",
    "                if kk == 0:\n",
    "                    rect = Rectangle((remov-0.5, ax_limits[xx][0]),\n",
    "                                     1, np.diff(ax_limits[xx]), alpha = 0.05, fc = 'k', ec = None, label = 'removed')\n",
    "                else:\n",
    "                    rect = Rectangle((remov-0.5, ax_limits[xx][0]),\n",
    "                                     1, np.diff(ax_limits[xx]), alpha = 0.05, fc = 'k', ec = None)\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "        plt.sca(ax1)\n",
    "        cmap = cm.bwr\n",
    "        plt.scatter(all_frames, joint_x, c = conf, s = 10, \n",
    "                cmap = cmap, norm = colors.Normalize(vmin=0, vmax=1), label = 'raw tracking')\n",
    "# #         plt.plot(frames_OI, joint_x_highconf, '-k', alpha = 0.2)\n",
    "        plt.plot(all_frames, joint_x_interp, '.k', alpha = 0.5, MarkerSize = 2)#, label = 'interpolated')\n",
    "        plt.plot(all_frames, joint_x_filt, '-g', alpha = 0.5, label = 'filtered', )\n",
    "        plt.ylabel('x (pix)')\n",
    "        plt.legend(loc = 'upper right', frameon=False, fontsize = 7)\n",
    "        titleparts = videofile.split('/')\n",
    "        plt.title('%s -- %s -- %s\\n%s -- conf. cutoff: %0.1f -- jump limit: %i -- max nan gap for interp: %i'\n",
    "                  %(titleparts[-2], titleparts[-1].split('_')[0], titleparts[-1].split('_')[1],\n",
    "                    tracked_pt, conf_cutoff, jump_limit, nan_gap_limit),\n",
    "                 loc = 'left')\n",
    "#         plt.axhline(y=-58.82, xmin = 0, xmax = .8) # for file 589, trackway 833 -- show outlier range\n",
    "#         plt.axhline(y=-58.82+2*15.99, xmin = 0, xmax = .8)\n",
    "#         plt.axhline(y=-58.82-2*15.99, xmin = 0, xmax = .8)\n",
    "        \n",
    "\n",
    "\n",
    "        plt.sca(ax2)\n",
    "#         plt.plot(frames_OI, joint_y_highconf, '-k', alpha = 0.5)\n",
    "        plt.plot(all_frames, joint_y_interp, '.k', alpha = 0.5, label = 'interpolated', MarkerSize = 2)\n",
    "        plt.plot(all_frames, joint_y_filt, '-g', alpha = 0.5, label = 'filtered', )\n",
    "#         plt.plot(frames_OI, joint_y_filt, '.g', alpha = 0.5, label = 'filtered', MarkerSize = 3)\n",
    "        plt.scatter(all_frames, joint_y, c = conf, s = 10, \n",
    "                cmap = cmap, norm = colors.Normalize(vmin=0, vmax=1))\n",
    "        plt.ylabel('y (pix)')\n",
    "        plt.gca().invert_yaxis()\n",
    "#         plt.axhline(y=30.01, xmin = 0, xmax = .9) # for file 589, trackway 833 -- show outlier range\n",
    "#         plt.axhline(y=30.01+2*7.4, xmin = 0, xmax = .9)\n",
    "#         plt.axhline(y=30.01-2*7.4, xmin = 0, xmax = .9)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        cax = plt.axes([0.93,0.1,0.02,0.8])\n",
    "        plt.colorbar(cax=cax, label='confidence')\n",
    "        plt.clim(0,1)\n",
    "    \n",
    "    if tracked_pt != 'thorax':\n",
    "        joint_x_filt = joint_x_filt + x_offset\n",
    "        joint_y_filt = joint_y_filt + y_offset\n",
    "    print('final filter len: ', np.sum(np.isnan(joint_x_filt)), ' nan of ', len(joint_x_filt) )\n",
    "    del rect, \n",
    "    return;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RUN ON SPECIFIC TRIAL & PLOT\n",
    "plt.close('all')\n",
    "for tr_num in [9]:#range(833,834):#105 #91 #105\n",
    "    videofile = df.video[tr_num]\n",
    "    print(videofile)\n",
    "    for joint_num in range(0,1):\n",
    "        tracked_pt = 'joint%i'%joint_num\n",
    "        interpolate_filter_tracking(df, tr_num, tracked_pt, \n",
    "                                conf_cutoff = 0.6, jump_limit = 10, nan_gap_limit = 5, plots = True)\n",
    "del tracked_pt, videofile\n",
    "#     tracked_pt = 'thorax'\n",
    "#     interpolate_filter_tracking(df, tr_num, tracked_pt, \n",
    "#                                 conf_cutoff = 0.6, jump_limit = 10, nan_gap_limit = 5, plots = True)\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def WRTant_to_WRTframe(val_x, val_y, frame_center_x, frame_center_y, ant_ang_deg):\n",
    "    ant_ang = ant_ang_deg *np.pi/180\n",
    "    R = np.array([[np.cos(ant_ang), -1*np.sin(ant_ang)],\n",
    "                  [np.sin(ant_ang),    np.cos(ant_ang)]])\n",
    "    if R.ndim == 3:\n",
    "        rotated_vals = np.einsum('ijk, ki->kj', R, (np.array([val_x,val_y])-100).T).T\n",
    "#         print(R.shape, rotated_vals.shape, rotated_vals[:,0])\n",
    "        translated_vals = rotated_vals + np.array([frame_center_x, frame_center_y])  \n",
    "        return translated_vals[0,:], translated_vals[1,:];\n",
    "    elif R.ndim == 2:\n",
    "        rotated_vals = np.einsum('ij, i->j', R, (np.array([val_x,val_y])-100).T).T\n",
    "#         print(R.shape, rotated_vals.shape, rotated_vals[:])\n",
    "        translated_vals = rotated_vals + np.array([frame_center_x, frame_center_y])  \n",
    "        return translated_vals[0], translated_vals[1];\n",
    "    else:\n",
    "        print('something went wrong with R dimensions')\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze tracked data in WHOLE DATAFRAME, removing low confidence points and lowpass filter -- rotate wrt full frame, rotate wrt tracked neck and thorax\n",
    "-- apply to whole dataframe: thorax, neck, and limbs<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATAFRAME FUNCTIONS\n",
    "\n",
    "def find_nan_gaps(arr, limit):  \n",
    "    yy = np.isnan(arr)\n",
    "    xx = range(len(yy))\n",
    "    where_gapOI = np.full(arr.shape, False)\n",
    "    where_othergaps = np.full(arr.shape, False)\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == True: # if is a group of nan\n",
    "            g = list(g)\n",
    "            if any(x in g for x in [0, len(arr)-1]): # if first or last group\n",
    "                where_othergaps[np.array(g)]=True\n",
    "#                 print('remove: ', len(g), g)\n",
    "                continue\n",
    "                \n",
    "            if len(g)<= limit: # length is below limit\n",
    "                where_gapOI[np.array(g)]=True\n",
    "#                 print('interp: ', len(g), g)\n",
    "            else:\n",
    "                where_othergaps[np.array(g)]=True\n",
    "#                 print('remove: ', len(g), g)\n",
    "    return where_gapOI, where_othergaps\n",
    "\n",
    "\n",
    "def interpolate_filter_tracking_df(x, ant_part, conf_cutoff, jump_limit, nan_gap_limit):\n",
    "#     print('TRIAL: ', x.name, ' -- substrate: ', x.substrate)\n",
    "    all_frames = x['frames']\n",
    "    frames_OI = x['frames_final']\n",
    "    frames_OI_idcs = np.isin(all_frames, frames_OI)\n",
    "    \n",
    "    joint={'x': x[ant_part+'_x'] , 'y': x[ant_part+'_y']}\n",
    "    conf = x[ant_part + '_conf']\n",
    "    if 'thorax_x_filt' in df:\n",
    "        thorax = {'x': x['thorax_x_filt'], 'y': x['thorax_y_filt']} \n",
    "    else:\n",
    "        thorax = {'x': x['thorax_x'], 'y': x['thorax_y']} \n",
    "\n",
    "    #initialize new dicts\n",
    "    joint_highconf = {}\n",
    "    joint_no_outliers = {}\n",
    "    joint_interp = {}\n",
    "    joint_filt = {}\n",
    "\n",
    "    for coord in ['x','y']:\n",
    "        if 'thorax' not in ant_part: # account for inaccurate initial guess of body center, make relative to LEAP tracked thorax\n",
    "            joint[coord] = joint[coord] - thorax[coord]\n",
    "\n",
    "        joint_highconf[coord] = remove_lowconf_pts(joint[coord], conf, conf_cutoff, jump_limit)\n",
    "        joint_highconf[coord] = remove_jumps(joint_highconf[coord], jump_limit)\n",
    "    joint_no_outliers['x'], joint_no_outliers['y'] = remove_outliers2d(joint_highconf['x'], joint_highconf['y'])   \n",
    "    for coord in ['x','y']:\n",
    "        where_interpolate, where_remove = find_nan_gaps(joint_no_outliers[coord], nan_gap_limit)\n",
    "        if np.sum(where_interpolate==True)>0: # only interpolate if needed\n",
    "            joint_interp[coord] = interp_vals(joint_no_outliers[coord], find_interp_idcs(where_interpolate))\n",
    "        else:\n",
    "            joint_interp[coord] = joint_no_outliers[coord]\n",
    "        joint_filt[coord] = lowpass_filt_sections(joint_interp[coord])\n",
    "    \n",
    "        if 'thorax' not in ant_part: # account for inaccurate initial guess of body center, make relative to LEAP tracked thorax\n",
    "            joint_filt[coord] = joint_filt[coord] + thorax[coord]\n",
    "\n",
    "    if np.sum(np.logical_not(np.isnan(joint_filt['x']))) < 50: # if fewer than 50 non-nan points in trial, remove\n",
    "        joint_filt['x'][np.logical_not(np.isnan(joint_filt['x']))]=np.nan\n",
    "        joint_filt['y'][np.logical_not(np.isnan(joint_filt['y']))]=np.nan\n",
    "        \n",
    "    if np.nanmax(np.linalg.norm([np.diff(joint_filt['x']), np.diff(joint_filt['y'])],axis=0))> 30 : # if unreasonably high velocities\n",
    "        joint_filt['x'][np.logical_not(np.isnan(joint_filt['x']))]=np.nan\n",
    "        joint_filt['y'][np.logical_not(np.isnan(joint_filt['y']))]=np.nan\n",
    "        \n",
    "     \n",
    "    return joint_filt['x'], joint_filt['y'] #joint_x_filt, joint_y_filt;\n",
    "\n",
    "\n",
    "def WRTant_to_WRTframe_df(df, ant_part):\n",
    "    frame_idcs = np.isin(df['frames'], df['frames_final'])\n",
    "    ant_x = np.array(df['x_raw'])#[frame_idcs]\n",
    "    ant_y = np.array(df['y_raw'])#[frame_idcs]\n",
    "    ang = np.array(df['angle_improved'])*-1#[frame_idcs]*-1\n",
    "    val_x = df['%s_x_filt'%ant_part]\n",
    "    val_y = df['%s_y_filt'%ant_part]\n",
    "\n",
    "    ant_ang = ang *np.pi/180\n",
    "    R = np.array([[np.cos(ant_ang), -1*np.sin(ant_ang)],\n",
    "                  [np.sin(ant_ang),    np.cos(ant_ang)]])\n",
    "    \n",
    "    if R.ndim == 3:\n",
    "        rotated_vals = np.einsum('ijk, ki->kj', R, (np.array([val_x,val_y])-100).T).T\n",
    "        translated_vals = rotated_vals + np.array([ant_x, ant_y])\n",
    "        xs = translated_vals[0,:]\n",
    "        ys = translated_vals[1,:]\n",
    "    elif R.ndim == 2:\n",
    "        rotated_vals = np.einsum('ij, i->j', R, (np.array([val_x,val_y])-100).T).T\n",
    "        translated_vals = rotated_vals + np.array([ant_x, ant_y]) \n",
    "        xs = translated_vals[0]\n",
    "        ys = translated_vals[1]    \n",
    "    else:\n",
    "        print('something went wrong with R dimensions')\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    # remove any crazy rotated points that result from slight diff in rotation angle +180/-180\n",
    "    fast_velocity_pts = np.linalg.norm([np.diff(xs), np.diff(ys)],axis=0)> 30\n",
    "    xs[1:][fast_velocity_pts] = np.nan\n",
    "    ys[1:][fast_velocity_pts] = np.nan\n",
    "    \n",
    "    # remove any points close to edge of frame\n",
    "    buffer = 60\n",
    "    wid = 1000\n",
    "    hei = 500\n",
    "    edgeidcs = ((xs < buffer) | (xs > wid-(buffer)) | (ys < buffer) | (ys > hei-buffer))\n",
    "    xs[edgeidcs]=np.nan\n",
    "    ys[edgeidcs]=np.nan\n",
    "\n",
    "    return xs,ys\n",
    "    \n",
    "\n",
    "def WRTant_to_WRTneck_df(df, ant_part):\n",
    "    x = df['%s_x_filt'%ant_part]\n",
    "    y = df['%s_y_filt'%ant_part]\n",
    "    thorax_x = df['thorax_x_filt']\n",
    "    thorax_y = df['thorax_y_filt']\n",
    "    neck_x = df['neck_x_filt']\n",
    "    neck_y = df['neck_y_filt']\n",
    "    \n",
    "    val_coord = np.array([x,y])-np.array([thorax_x,thorax_y])\n",
    "    neck_coord = np.array([neck_x-thorax_x,neck_y-thorax_y])\n",
    "    ang = np.arctan( (neck_y-thorax_y)/(neck_x-thorax_x))\n",
    "    c, s = np.cos(ang), np.sin(ang)\n",
    "    Rx = np.array([c,s])\n",
    "    Ry = np.array([-s,c])\n",
    "    newx = np.einsum('mn,mn->n', val_coord, Rx)\n",
    "    newy = np.einsum('mn,mn->n', val_coord, Ry)\n",
    "    return newx, newy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For whole dataframe: filter x,y wrt ant and calc filtered x,y wrt lab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in greater\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: All-NaN slice encountered\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in less\n",
      "  \n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:101: RuntimeWarning: invalid value encountered in greater\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:109: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thorax analyzed\n",
      "neck analyzed\n",
      "antennae analyzed\n",
      "joint 0\n",
      "joint 1\n",
      "joint 2\n",
      "joint 3\n",
      "joint 4\n",
      "joint 5\n",
      "legs analyzed\n",
      "\n",
      "Rotate leg and antennae point WRT tracked neck direction:\n",
      "antennae analyzed\n",
      "legs analyzed\n",
      "\n",
      "all donezo\n"
     ]
    }
   ],
   "source": [
    "# APPLY INTERPOLATION AND LOWPASS FILTERING TO DATAFRAME\n",
    "# removes points with low confidence or large jumps in tracking (likely errors), replaces with nan\n",
    "# interpolates nan gaps less than specified size\n",
    "# low pass filters (butterworth) and saves\n",
    "\n",
    "print('For whole dataframe: filter x,y wrt ant and calc filtered x,y wrt lab')\n",
    "conf_cutoff = 0.6\n",
    "jump_cutoff = 10\n",
    "nan_gap_limit = 5\n",
    "\n",
    "# # thorax\n",
    "df['thorax_x_filt'], df['thorax_y_filt'] = zip(*df.apply(\n",
    "    interpolate_filter_tracking_df, args = ('thorax', conf_cutoff, jump_cutoff, nan_gap_limit), axis=1))\n",
    "df['thorax_x_filt_fullfr'], df['thorax_y_filt_fullfr'] = zip(*df.apply(\n",
    "        WRTant_to_WRTframe_df, args = ('thorax',), axis=1))\n",
    "print('thorax analyzed')\n",
    "\n",
    "# neck\n",
    "df['neck_x_filt'], df['neck_y_filt'] = zip(*df.apply(\n",
    "    interpolate_filter_tracking_df, args = ('neck', conf_cutoff, jump_cutoff, nan_gap_limit), axis=1))\n",
    "df['neck_x_filt_fullfr'], df['neck_y_filt_fullfr'] = zip(*df.apply(\n",
    "        WRTant_to_WRTframe_df, args = ('neck',), axis=1))\n",
    "print('neck analyzed')\n",
    "\n",
    "# antennae\n",
    "for joint_num in range(0,2):\n",
    "    df['antenna%i_x_filt'%joint_num], df['antenna%i_y_filt'%joint_num] = zip(*df.apply(\n",
    "        interpolate_filter_tracking_df, args = ('antenna%i'%joint_num, conf_cutoff, jump_cutoff, nan_gap_limit), axis=1))\n",
    "    df['antenna%i_x_filt_fullfr'%joint_num], df['antenna%i_y_filt_fullfr'%joint_num] = zip(*df.apply(\n",
    "        WRTant_to_WRTframe_df, args = ('antenna%i'%joint_num,), axis=1))\n",
    "print('antennae analyzed')\n",
    "\n",
    "# legs\n",
    "for joint_num in range(0,6):\n",
    "    print('joint %i'%joint_num)\n",
    "    df['joint%i_x_filt'%joint_num], df['joint%i_y_filt'%joint_num] = zip(*df.apply(\n",
    "        interpolate_filter_tracking_df, args = ('joint%i'%joint_num, conf_cutoff, jump_cutoff, nan_gap_limit), axis=1))\n",
    "    df['joint%i_x_filt_fullfr'%joint_num], df['joint%i_y_filt_fullfr'%joint_num] = zip(*df.apply(\n",
    "        WRTant_to_WRTframe_df, args = ('joint%i'%joint_num,), axis=1))\n",
    "    \n",
    "print('legs analyzed')\n",
    "\n",
    "\n",
    "# rotate relative to thorax and neck if exist\n",
    "print('\\nRotate leg and antennae point WRT tracked neck direction:')\n",
    "if ('thorax_x_filt' in df) and ('neck_x_filt' in df):\n",
    "    for joint_num in range(0,2):\n",
    "        df['antenna%i_x_filt_WRTneck'%joint_num], df['antenna%i_y_filt_WRTneck'%joint_num] = zip(*df.apply(\n",
    "            WRTant_to_WRTneck_df, args = ('antenna%i'%joint_num,), axis=1))\n",
    "    print('antennae analyzed')\n",
    "    for joint_num in range(0,6):\n",
    "        df['joint%i_x_filt_WRTneck'%joint_num], df['joint%i_y_filt_WRTneck'%joint_num] = zip(*df.apply(\n",
    "            WRTant_to_WRTneck_df, args = ('joint%i'%joint_num,), axis=1))\n",
    "    print('legs analyzed')\n",
    "    \n",
    "del conf_cutoff, jump_cutoff, nan_gap_limit\n",
    "\n",
    "\n",
    "# something there's a weird rotation resulting in a really high velocity \n",
    "\n",
    "print('\\nall donezo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out removing data when ant is close to wall or stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in less\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in greater\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: Mean of empty slice\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:29: RuntimeWarning: Mean of empty slice\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: Mean of empty slice\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: Mean of empty slice\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "# for single trial\n",
    "\n",
    "tr_num = 0\n",
    "for n_tr in np.arange(0,10):\n",
    "#     tr_num = 2279#\n",
    "    tr_num = random.randint(0,11000)\n",
    "    x = df['thorax_x_filt_fullfr'][tr_num]\n",
    "    y = df['thorax_y_filt_fullfr'][tr_num]\n",
    "    v = np.linalg.norm(np.array([np.diff(x), np.diff(y)]), axis =0)\n",
    "\n",
    "    # remove points close to edge\n",
    "    buffer = 60\n",
    "    wid = 1000\n",
    "    hei = 500\n",
    "    edgeidcs = ((x < buffer) | (x > wid-(buffer)) | (y < buffer) | (y > hei-buffer))\n",
    "    ROIidcs = ~edgeidcs\n",
    "\n",
    "    # find moving points based on distance traveled\n",
    "    b_wid = 10\n",
    "    b_sep = 40\n",
    "    dist_thres = 40 # pix/window - ~90 pix is 2 mm\n",
    "    \n",
    "    temp = np.add.outer(np.arange(len(x)), -np.arange(len(x)))\n",
    "    before_wid = np.logical_and(temp >= -1*b_sep - (b_wid/2),temp <= -1*b_sep + (b_wid/2)).astype(np.float)\n",
    "    before_wid[before_wid==0] = np.nan\n",
    "    after_wid = np.logical_and(temp >= b_sep - (b_wid/2),temp <= b_sep + (b_wid/2)).astype(np.float)\n",
    "    after_wid[after_wid==0] = np.nan\n",
    "    before_x = np.nanmean(before_wid*x[:,np.newaxis], axis=0)\n",
    "    after_x = np.nanmean(after_wid*x[:,np.newaxis], axis=0)\n",
    "    before_y = np.nanmean(before_wid*y[:,np.newaxis], axis=0)\n",
    "    after_y = np.nanmean(after_wid*y[:,np.newaxis], axis=0)\n",
    "    dist_traveled = np.linalg.norm([after_x-before_x, after_y-before_y], axis = 0)\n",
    "    slow_idcs = dist_traveled < dist_thres\n",
    "    \n",
    "\n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(6,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(x,y,'-k')\n",
    "    plt.plot(x[edgeidcs],y[edgeidcs], '.b')\n",
    "    plt.plot(x[slow_idcs],y[slow_idcs], '.r')\n",
    "    rect = patches.Rectangle([buffer, buffer], wid-2*buffer, hei-2*buffer, ec='k', fc = 'none', alpha = 0.2)\n",
    "    plt.gca().add_patch(rect)\n",
    "    plt.xlim(0,wid)\n",
    "    plt.ylim(0,hei)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Tr Num: %i, Sub: %s'%(tr_num, df['substrate'][tr_num]))\n",
    "    \n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(v,'-k')\n",
    "    plt.plot(dist_traveled/90, '--r')\n",
    "    plt.axhline(y=dist_thres/90, c='k', alpha = 0.3)\n",
    "\n",
    "#     #plt.axis('equal')\n",
    "    plt.pause(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIND TOUCHDOWN AND STRIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 1244, time 101212\n",
      "0.44 of velocity less than 2 -- vel_cutoff = 3.0\n",
      "0.62 of velocity less than 1.5 -- vel_cutoff = 1.5\n",
      "0.66 of velocity less than 2 -- vel_cutoff = 2.0\n",
      "0.29 of velocity less than 2 -- vel_cutoff = 3.0\n",
      "nan of velocity less than 2 -- vel_cutoff = 3.0\n",
      "0.08 of velocity less than 2 -- vel_cutoff = 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:166: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:170: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:174: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:179: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:184: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:173: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:176: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:166: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:170: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:174: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:179: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-450-890d9c2b73d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mTDs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_start_of_stance2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvel_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap_size_to_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mTDs_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mTDs_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_TD_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# general guess of where stance is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mTDs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_TD_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mTDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_close_TDs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_TD_separation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove TDs that are close to eachother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-450-890d9c2b73d9>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mTDs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_start_of_stance2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvel_cutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgap_size_to_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mTDs_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mTDs_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_TD_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m# general guess of where stance is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mTDs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfind_TD_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_stance_fr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTDs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0mTDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_close_TDs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTDs_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_TD_separation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove TDs that are close to eachother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-450-890d9c2b73d9>\u001b[0m in \u001b[0;36mfind_TD_position\u001b[0;34m(df, joint, TDs, x_or_y, tr_num, window_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0midcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTDs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#idcs = np.clip(idcs, 0, len(df['%s_%s_filt_fullfr'%(joint, x_or_y)][tr_num])-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'%s_%s_filt_fullfr'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_or_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midcs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "# FOR A GIVEN TRIAL, FIND TOUCHDOWNS, STRIDE LENGTHS, AND STRIDE DURATIONS\n",
    "\n",
    "def find_start_of_stance(vel, vel_cutoff, win_size, n_slow_in_window):\n",
    "    where_slow = vel< vel_cutoff\n",
    "    first_slows = np.diff(np.insert(where_slow, len(where_slow), np.nan).astype(np.int8)) == 1\n",
    "    n = n_slow_in_window # how many nans must there be in window of w width after each first_slow\n",
    "    w = win_size\n",
    "    where_slow_cumsum = np.cumsum(np.insert(where_slow,len(where_slow),np.zeros(w)))\n",
    "    n_subsequent_slow = where_slow_cumsum[w:]-where_slow_cumsum[:-(w)]\n",
    "    starts = np.logical_and(first_slows, n_subsequent_slow>=n)\n",
    "    prior_starts = np.cumsum(np.insert(starts,0,np.zeros(10)))[10:] - np.cumsum(np.insert(starts,0,np.zeros(10)))[0:-10]\n",
    "    n_prior_slow = np.insert(where_slow_cumsum,0,0)-np.insert(where_slow_cumsum, 0, np.zeros(w+1))[:-(w)]\n",
    "    TDs = np.where(np.logical_and(np.logical_and(starts, n_prior_slow[:-(w+1)]<=n), prior_starts ==1))[0]\n",
    "#     TDs = np.where(np.logical_and(starts, prior_starts == 1))[0]\n",
    "    return TDs\n",
    "\n",
    "def find_start_of_stance2(vel, vel_cutoff, gaps_size_to_close, win_size, n_slow_in_window):\n",
    "    where_slow = vel < vel_cutoff\n",
    "    # interpolate gaps\n",
    "    where_slow[find_nan_gaps(np.logical_not(where_slow), gaps_size_to_close)] = True\n",
    "    \n",
    "    first_slows = np.diff(np.insert(where_slow, len(where_slow), False).astype(np.int8)) == 1\n",
    "    TDs = np.where(first_slows)[0]\n",
    "    \n",
    "    n = n_slow_in_window # how many nans must there be in window of w width after each first_slow\n",
    "    w = win_size\n",
    "    where_slow_cumsum = np.cumsum(np.insert(where_slow,len(where_slow),np.zeros(w)))\n",
    "    n_subsequent_slow = where_slow_cumsum[w:]-where_slow_cumsum[:-(w)]\n",
    "    starts = np.logical_and(first_slows, n_subsequent_slow>=n)\n",
    "    prior_starts = np.cumsum(np.insert(starts,0,np.zeros(w)))[w:] - np.cumsum(np.insert(starts,0,np.zeros(w)))[0:-w]\n",
    "#     n_prior_slow = np.insert(where_slow_cumsum,0,0)-np.insert(where_slow_cumsum, 0, np.zeros(w+1))[:-(w)]\n",
    "#     TDs = np.where(np.logical_and(np.logical_and(starts, n_prior_slow[:-(w+1)]<=n), prior_starts ==1))[0]\n",
    "    TDs = np.where(np.logical_and(starts, prior_starts == 1))[0] + 2\n",
    "    return TDs\n",
    "\n",
    "def find_nan_gaps(arr, limit):  \n",
    "    from itertools import groupby\n",
    "    yy = arr\n",
    "    xx = range(len(yy))\n",
    "    where_gapOI = np.full(arr.shape, False)\n",
    "    where_othergaps = np.full(arr.shape, False)\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == True: # if is a group of nan\n",
    "            g = list(g)\n",
    "            if any(x in g for x in [0, len(arr)-1]): # if first or last group\n",
    "                where_othergaps[np.array(g)]=True\n",
    "                continue       \n",
    "            if len(g)<= limit: # length is below limit\n",
    "                where_gapOI[np.array(g)]=True\n",
    "    return where_gapOI\n",
    "\n",
    "\n",
    "def find_TD_position(df, joint, TDs, x_or_y, tr_num, window_size):\n",
    "    idcs = (np.tile(TDs,(window_size,1))+np.arange(0,window_size)[:,np.newaxis])\n",
    "    #idcs = np.clip(idcs, 0, len(df['%s_%s_filt_fullfr'%(joint, x_or_y)][tr_num])-1)\n",
    "    positions = np.mean(df['%s_%s_filt_fullfr'%(joint, x_or_y)][tr_num][idcs],axis=0)\n",
    "    return positions\n",
    "\n",
    "\n",
    "def remove_close_TDs(TDs, TDs_x, TDs_y, cutoff):\n",
    "    for k in TDs.keys():\n",
    "        d_TDs = np.linalg.norm(np.diff(np.array([TDs_x[k], TDs_y[k]])), axis=0)\n",
    "        d_TDs = np.insert(d_TDs, 0, cutoff+2) # delete second TD, not first\n",
    "        TDs[k]= np.delete(TDs[k], np.where(d_TDs<cutoff))\n",
    "        TDs_x[k]= np.delete(TDs_x[k], np.where(d_TDs<cutoff))\n",
    "        TDs_y[k]= np.delete(TDs_y[k], np.where(d_TDs<cutoff))\n",
    "    return TDs, TDs_x, TDs_y\n",
    "\n",
    "    \n",
    "\n",
    "def find_TD_frames(df, tr_num, TDs_x, TDs_y, n_nearby_frs, pix_cutoff):\n",
    "    if n_nearby_frs%2 == 1: # make sure is even\n",
    "        n_nearby_frs = n_nearby_frs + 1\n",
    "    TDs_fr={}\n",
    "    TDs_fr_idcs = {}\n",
    "    for k in TDs_x.keys():\n",
    "        idcs = (np.tile(TDs[k],(n_nearby_frs+1,1))+np.arange(-n_nearby_frs/2,n_nearby_frs/2+1)[:,np.newaxis]).astype(np.int64)\n",
    "        idcs= np.clip(idcs, 0, len(df['%s_x_filt_fullfr'%(k)][tr_num])-1)\n",
    "        d_TDs_x = TDs_x[k][np.newaxis,:] - df['%s_x_filt_fullfr'%(k)][tr_num][idcs]\n",
    "        d_TDs_y = TDs_y[k][np.newaxis,:] - df['%s_y_filt_fullfr'%(k)][tr_num][idcs]\n",
    "        d_TDs_total = np.linalg.norm(np.array([d_TDs_x, d_TDs_y]), axis=0)\n",
    "        TDs_fr_idcs[k] = idcs[np.argmax(d_TDs_total<pix_cutoff, axis = 0), range(len(TDs_x[k]))]\n",
    "        TDs_fr[k] = df['frames'][tr_num][TDs_fr_idcs[k]]\n",
    "    return TDs_fr_idcs, TDs_fr\n",
    "\n",
    "\n",
    "def remove_uncertain_TD_frames(TDs_fr_idcs, vel, where_slow, min_n_fr_before_TD, max_slow_during_swing, fraction_track_cutoff): # remove any TD_frs that don't have at least __ non-nan frames before\n",
    "    good_TDs = {}\n",
    "    good_strides = {}\n",
    "    for k in vel.keys():\n",
    "        v_chunks = np.split(vel[k], TDs_fr_idcs[k])\n",
    "        ws_chunks = np.split(where_slow[k], TDs_fr_idcs[k])\n",
    "        wf_chunks = np.split(np.logical_not(where_slow[k]), TDs_fr_idcs[k])\n",
    "        n_finite_fr_before = np.array([0]+ [np.sum(np.isfinite(c[-min_n_fr_before_TD:])) for c in v_chunks][:-1])\n",
    "        fraction_tracked = np.array([np.sum(np.isfinite(c))/len(c) for c in v_chunks])\n",
    "        n_slow_in_center = np.array([np.sum(np.logical_not(np.trim_zeros(np.logical_not(np.trim_zeros(c,'f'))))) for c in ws_chunks ])\n",
    "        good_TDs[k] = (n_finite_fr_before == min_n_fr_before_TD)[1:]\n",
    "        tmp = np.logical_and(good_TDs[k][:-1], good_TDs[k][1:]) # good strides must be between two good TDs\n",
    "        tmp2 = np.logical_and.reduce((n_finite_fr_before==min_n_fr_before_TD, n_slow_in_center<=max_slow_during_swing, fraction_tracked > fraction_track_cutoff))[1:-1]\n",
    "        good_strides[k] = np.logical_and(tmp, tmp2)\n",
    "    return good_TDs, good_strides\n",
    "\n",
    "\n",
    "def find_stride_dur(TDs_fr_idcs, good_strides):\n",
    "    stride_durations = {}\n",
    "    stride_dur_sta = {}\n",
    "    stride_dur_sto = {}\n",
    "    for jj in range(0,6):\n",
    "        k = 'joint%i'%jj\n",
    "        stride_durations[k] = np.diff(TDs_fr_idcs[k])[good_strides[k]]\n",
    "        stride_dur_sta[k] = TDs_fr_idcs[k][0:-1][good_strides[k]]\n",
    "        stride_dur_sto[k] = TDs_fr_idcs[k][1:][good_strides[k]]-1\n",
    "    return stride_durations, stride_dur_sta, stride_dur_sto\n",
    "\n",
    "\n",
    "def find_stride_dist(df, tr_num, TDs_fr_idcs, good_strides):\n",
    "    stride_dists = {}\n",
    "    stride_dists_sta = {}\n",
    "    stride_dists_sto = {}\n",
    "    for jj in range(0,6):\n",
    "        k = 'joint%i'%jj\n",
    "        d_x = np.diff(df['%s_x_filt_fullfr'%k][tr_num][TDs_fr_idcs[k]])[good_strides[k]]\n",
    "        d_y = np.diff(df['%s_y_filt_fullfr'%k][tr_num][TDs_fr_idcs[k]])[good_strides[k]]\n",
    "        stride_dists[k] = np.linalg.norm(np.array([d_x, d_y]), axis = 0)\n",
    "        stride_dists_sta[k] = TDs_fr_idcs[k][0:-1][good_strides[k]]\n",
    "        stride_dists_sto[k] = TDs_fr_idcs[k][1:][good_strides[k]]-1\n",
    "    return stride_dists, stride_dists_sta, stride_dists_sto\n",
    "    \n",
    "\n",
    "def plot_TD_circles(TDs_x, TDs_y, rad):\n",
    "    for k in TDs_x.keys():\n",
    "        for ii in range(len(TDs_x[k])):\n",
    "            circ =Circle((TDs_x[k][ii] , TDs_y[k][ii]), radius=rad, ec = 'k' , fc= 'k', alpha = 0.4)\n",
    "            ax1.add_patch(circ)\n",
    "    return\n",
    "\n",
    "\n",
    "########################################################\n",
    "# user set parameters\n",
    "for tr_num in [1244]: # range(75,76):\n",
    "    print('trial: %s, time %s'%(tr_num, df['time'][tr_num]))\n",
    "#     tr_num = 410#310#18\n",
    "\n",
    "    # from df version below\n",
    "    vel_cutoff= 3 # what velocity cutoff for identifying stances\n",
    "    gap_size_to_close = 3 # interpolate where slow data\n",
    "    n_stance_fr = 5 # how many frames of \"stance\" for it to be a legit \"stance\"\n",
    "    min_TD_separation = 10 # how close can subsequent TDs be to each other\n",
    "    n_nearby_frs = 12 # how many frames around TD to look for TD frame (first fr when foot within __ pix of TD location)\n",
    "    pix_cutoff = 3 # how large of a radius around TD location to look for first TD frame\n",
    "    min_n_fr_before_TD = 3 # how many non-nan frames before TD to make sure you're getting the correct TD timing\n",
    "    max_slow_during_swing = 1 # how many slow points allowed outside of initial slow section\n",
    "    fraction_track_cutoff = 0.9 # percent of stride that needs to be tracked (not missing extra TD)\n",
    "\n",
    "    #########################################################\n",
    "\n",
    "\n",
    "\n",
    "    TDs = {}\n",
    "    vel = {}\n",
    "    where_slow = {}\n",
    "    for jj in range(0,6):\n",
    "        k = 'joint%i'%jj\n",
    "        vel[k] = np.linalg.norm(np.diff(np.array([df['joint%i_x_filt_fullfr'%jj][tr_num], df['joint%i_y_filt_fullfr'%jj][tr_num]])), axis=0)\n",
    "        # how much noise is there?\n",
    "        if np.sum(vel[k]<1)/np.sum(np.isfinite(vel[k]))>0.6:\n",
    "            vel_cutoff = 1\n",
    "            pix_cutoff = 2\n",
    "            print('%0.2f of velocity less than 1 -- vel_cutoff = %0.1f'%(np.sum(vel[k]<1)/np.sum(np.isfinite(vel[k])), vel_cutoff))\n",
    "        elif np.sum(vel[k]<1.5)/np.sum(np.isfinite(vel[k]))>0.6:\n",
    "            vel_cutoff = 1.5\n",
    "            pix_cutoff = 2\n",
    "            print('%0.2f of velocity less than 1.5 -- vel_cutoff = %0.1f'%(np.sum(vel[k]<1.5)/np.sum(np.isfinite(vel[k])), vel_cutoff))\n",
    "        elif np.sum(vel[k]<2)/np.sum(np.isfinite(vel[k]))>0.5:\n",
    "            vel_cutoff = 2\n",
    "            print('%0.2f of velocity less than 2 -- vel_cutoff = %0.1f'%(np.sum(vel[k]<2)/np.sum(np.isfinite(vel[k])), vel_cutoff))\n",
    "        else:\n",
    "            vel_cutoff = 3\n",
    "            print('%0.2f of velocity less than 2 -- vel_cutoff = %0.1f'%(np.sum(vel[k]<1.5)/np.sum(np.isfinite(vel[k])), vel_cutoff))\n",
    "\n",
    "        if not np.any(np.isfinite(vel[k])):\n",
    "            TDs[k] = np.nan\n",
    "            continue\n",
    "        where_slow[k] = vel[k]<vel_cutoff\n",
    "        where_slow[k][find_nan_gaps(np.logical_not(where_slow[k]), gap_size_to_close)] = True\n",
    "        TDs[k] = find_start_of_stance2(vel[k], vel_cutoff, gap_size_to_close, n_stance_fr, n_stance_fr)\n",
    "    TDs_raw = TDs.copy()\n",
    "    TDs_x = {k: find_TD_position(df, k, v, 'x', tr_num, n_stance_fr) for k, v in TDs.items()} # general guess of where stance is\n",
    "    TDs_y = {k: find_TD_position(df, k, v, 'y', tr_num, n_stance_fr) for k, v in TDs.items()}\n",
    "    TDs, TDs_x, TDs_y = remove_close_TDs(TDs, TDs_x, TDs_y, cutoff=min_TD_separation) # remove TDs that are close to eachother\n",
    "    TDs_fr_idcs, TDs_fr = find_TD_frames(df, tr_num, TDs_x, TDs_y, n_nearby_frs, pix_cutoff) # find frames of touchdown\n",
    "    good_TDs, good_strides = remove_uncertain_TD_frames(TDs_fr_idcs, vel, where_slow, min_n_fr_before_TD, max_slow_during_swing, fraction_track_cutoff)\n",
    "    stride_dur, stride_dur_sta, stride_dur_sto = find_stride_dur(TDs_fr_idcs, good_strides)\n",
    "    stride_dist, stride_dist_sta, stride_dist_sto = find_stride_dist(df, tr_num, TDs_fr_idcs, good_strides)\n",
    "\n",
    "\n",
    "    ##### PLOT THINGS\n",
    "    # plt.close('all')\n",
    "    cs = ['r','m', 'y', 'g','c','b']\n",
    "    ls = ['--', ':', '-','--',':','-']\n",
    "    fig=plt.figure(figsize=(22,12))\n",
    "    ax1=fig.add_axes([0.1,0.6, 0.8, 0.3])\n",
    "    plt.plot(df['thorax_x_filt_fullfr'][tr_num], df['thorax_y_filt_fullfr'][tr_num], 'k-', alpha = 0.2)\n",
    "    for jj in range(0,6,1):\n",
    "        plt.plot(df['joint%i_x_filt_fullfr'%jj][tr_num], df['joint%i_y_filt_fullfr'%jj][tr_num], '.', MarkerSize = 2, color = cs[jj])\n",
    "        plt.plot(df['joint%i_x_filt_fullfr'%jj][tr_num], df['joint%i_y_filt_fullfr'%jj][tr_num], '-', alpha = 0.1, color = cs[jj])\n",
    "        plt.text(600, 100+15*jj, 'joint%i'%jj, color = cs[jj])\n",
    "    plt.plot(df['joint0_x_filt_fullfr'][tr_num][TDs_raw['joint0'][0]] , df['joint0_y_filt_fullfr'][tr_num][TDs_raw['joint0'][0]], \n",
    "             'o', color = 'k' , fillstyle = 'none')\n",
    "    plt.plot(df['joint3_x_filt_fullfr'][tr_num][TDs_raw['joint3'][0]] , df['joint3_y_filt_fullfr'][tr_num][TDs_raw['joint3'][0]], \n",
    "             'o', color = 'k' , fillstyle = 'none')\n",
    "    plot_TD_circles(TDs_x, TDs_y, pix_cutoff)\n",
    "    plt.ylabel('y')\n",
    "    plt.xlabel('x')\n",
    "    plt.gca().axis('equal')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title((' - ').join(df.video[tr_num].split('/')[-2:]))\n",
    "\n",
    "\n",
    "    ax2=fig.add_axes([0.1,0.35, 0.8, 0.2])\n",
    "    plt.axhline(y = vel_cutoff, color = 'k', linestyle = ':', alpha=.3)\n",
    "    plt.ylabel('total vel (pix/fr)')\n",
    "    ax3=fig.add_axes([0.1,0.1, 0.8, 0.2])\n",
    "    plt.axhline(y = vel_cutoff, color = 'k', linestyle = ':', alpha=.3)\n",
    "    plt.ylabel('total vel (pix/fr)')\n",
    "\n",
    "    for jj in range(0,6):\n",
    "        k = 'joint%i'%jj\n",
    "\n",
    "        plt.sca(ax1)\n",
    "        # plot final TD locations\n",
    "        temp = TDs_fr_idcs[k][good_TDs[k]][np.logical_not(np.isnan(TDs_fr_idcs[k][good_TDs[k]]))].astype(np.int64)\n",
    "        plt.plot( df['%s_x_filt_fullfr'%(k)][tr_num][temp], df['%s_y_filt_fullfr'%(k)][tr_num][temp], '*', color = 'k', alpha = 0.8, MarkerSize = 8)\n",
    "        plt.plot( df['%s_x_filt_fullfr'%(k)][tr_num][temp], df['%s_y_filt_fullfr'%(k)][tr_num][temp], '.', color = cs[jj], alpha = 0.8, MarkerSize = 4)\n",
    "        # plot stride distances measured\n",
    "        temp = np.array([stride_dur_sta[k], stride_dur_sto[k]+1])\n",
    "        plt.plot(df['%s_x_filt_fullfr'%(k)][tr_num][temp.T].T, df['%s_y_filt_fullfr'%(k)][tr_num][temp.T].T, color = cs[jj], alpha = 0.4)\n",
    "\n",
    "        if jj%2 == 0:\n",
    "            plt.sca(ax2)\n",
    "        else:\n",
    "            plt.sca(ax3)\n",
    "\n",
    "        # plot velocity trace\n",
    "        plt.plot(df['frames'][tr_num][:-1], vel[k], '-', color = cs[jj])\n",
    "        # plot where velocity is slow (a potential \"stance\")\n",
    "        for sw in np.array(np.where(where_slow[k]))[0]:\n",
    "            rect = Rectangle((df['frames'][tr_num][sw]-0.5, -1*(jj+2)/4), 1, 1/3, alpha = 0.4, fc = cs[jj], ec = None)\n",
    "            plt.gca().add_patch(rect)\n",
    "        # plot initial guess of TD frame\n",
    "        plt.plot(df['frames'][tr_num][TDs_raw[k]] , np.ones(TDs_raw[k].shape)*(-1*(jj+2)/4)+(1/6), '.', color = cs[jj] , alpha = 1, MarkerSize = 3)\n",
    "        plt.plot(df['frames'][tr_num][TDs[k]] , np.ones(TDs[k].shape)*(-1*(jj+2)/4)+(1/6), '.', color = cs[jj] )\n",
    "        # plot final TD frames\n",
    "        for TD_fr in TDs_fr[k]:\n",
    "            plt.axvline(x = TD_fr, color = cs[jj], linestyle = ls[jj], alpha=.1)\n",
    "        for TD_fr in TDs_fr[k][good_TDs[k]]:\n",
    "            plt.axvline(x = TD_fr, color = cs[jj], linestyle = ls[jj], alpha=.4)\n",
    "        # plot final TD dist/durations\n",
    "        temp = np.array([stride_dur_sta[k]+1, stride_dur_sto[k]])\n",
    "        plt.plot(df['frames'][tr_num][temp], (20+jj)*np.ones(temp.shape), '-', color = cs[jj])\n",
    "\n",
    "\n",
    "    del TDs, TDs_x, TDs_y, TDs_raw, good_TDs, good_strides, stride_dur, stride_dur_sta, stride_dur_sto, stride_dist, stride_dist_sta, stride_dist_sto\n",
    "    del TDs_fr_idcs, TDs_fr, vel, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:123: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:126: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:129: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:133: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in less\n",
      "  \n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:123: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:126: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:129: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:76: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:80: RuntimeWarning: invalid value encountered in greater\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:51: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:52: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "# WHOLE DATAFRAME -- FIND TOUCHDOWNS, STRIDE LENGTHS, STRIDE DURATIONS, TRAVEL DIR., FACING ROTATIONS\n",
    "    \n",
    "def find_start_of_stance_df(vel, vel_cutoff, gaps_size_to_close, n_slow):\n",
    "    stance_cutoff = vel_cutoff\n",
    "    \n",
    "#     if not np.any(np.isfinite(vel)):\n",
    "#         return np.nan\n",
    "    where_slow = vel< stance_cutoff\n",
    "    \n",
    "    # interpolate gaps\n",
    "    where_slow[find_nan_gaps(np.logical_not(where_slow), gaps_size_to_close)] = True\n",
    "    \n",
    "    first_slows = np.diff(np.insert(where_slow, len(where_slow), False).astype(np.int8)) == 1\n",
    "    TDs = np.where(first_slows)[0]\n",
    "    \n",
    "    n = n_slow # how many nans must there be in window of w width after each first_slow\n",
    "    where_slow_cumsum = np.cumsum(np.insert(where_slow,len(where_slow),np.zeros(n)))\n",
    "    n_subsequent_slow = where_slow_cumsum[n:]-where_slow_cumsum[:-(n)]\n",
    "    starts = np.logical_and(first_slows, n_subsequent_slow>=n)\n",
    "    prior_starts = np.cumsum(np.insert(starts,0,np.zeros(n)))[n:] - np.cumsum(np.insert(starts,0,np.zeros(n)))[0:-n]\n",
    "    TDs = np.where(np.logical_and(starts, prior_starts == 1))[0] +1\n",
    "    return TDs\n",
    "\n",
    "def find_nan_gaps(arr, limit):  \n",
    "    from itertools import groupby\n",
    "    yy = arr\n",
    "    xx = range(len(yy))\n",
    "    where_gapOI = np.full(arr.shape, False)\n",
    "    where_othergaps = np.full(arr.shape, False)\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == True: # if is a group of nan\n",
    "            g = list(g)\n",
    "            if any(x in g for x in [0, len(arr)-1]): # if first or last group\n",
    "                where_othergaps[np.array(g)]=True\n",
    "                continue       \n",
    "            if len(g)<= limit: # length is below limit\n",
    "                where_gapOI[np.array(g)]=True\n",
    "    return where_gapOI\n",
    "\n",
    "\n",
    "def find_TD_position_df(df, joint_num, TDs, x_or_y, window_size):\n",
    "    idcs = (np.tile(TDs,(window_size,1))+np.arange(0,window_size)[:,np.newaxis])\n",
    "    positions = np.mean(df['joint%i_%s_filt_fullfr'%(joint_num, x_or_y)][idcs],axis=0)\n",
    "    return positions\n",
    "\n",
    "def remove_close_TDs_df(TDs, cutoff, df, jj, window_size):\n",
    "    TDs_x = find_TD_position_df(df, jj, TDs, 'x', window_size)\n",
    "    TDs_y = find_TD_position_df(df, jj, TDs, 'y', window_size)\n",
    "    d_TDs = np.linalg.norm(np.diff(np.array([TDs_x, TDs_y])), axis=0)\n",
    "    d_TDs = np.insert(d_TDs, 0, cutoff+2) # delete second TD, not first\n",
    "    TDs= np.delete(TDs, np.where(d_TDs<cutoff))\n",
    "    TDs_x = np.delete(TDs_x, np.where(d_TDs<cutoff))\n",
    "    TDs_y = np.delete(TDs_y, np.where(d_TDs<cutoff))\n",
    "    return TDs, TDs_x, TDs_y\n",
    "    \n",
    "\n",
    "def find_TD_frames_df(df, jj, TDs, TDs_x, TDs_y, n_nearby_frs, pix_cutoff):\n",
    "    if n_nearby_frs%2 == 1: # make sure is even\n",
    "        n_nearby_frs = n_nearby_frs + 1\n",
    "    idcs = (np.tile(TDs,(n_nearby_frs+1,1))+np.arange(-n_nearby_frs/2,n_nearby_frs/2+1)[:,np.newaxis]).astype(np.int64)\n",
    "#     idcs[idcs>= len(df['joint%i_x_filt_fullfr'%jj])] = len(df['joint%i_x_filt_fullfr'%jj])-1\n",
    "    idcs= np.clip(idcs, 0, len(df['joint%i_x_filt_fullfr'%(jj)])-1)\n",
    "    d_TDs_x = TDs_x[np.newaxis,:] - df['joint%i_x_filt_fullfr'%jj][idcs]\n",
    "    d_TDs_y = TDs_y[np.newaxis,:] - df['joint%i_y_filt_fullfr'%jj][idcs]\n",
    "    d_TDs_total = np.linalg.norm(np.array([d_TDs_x, d_TDs_y]), axis=0)\n",
    "    TDs_fr_idcs = idcs[np.argmax(d_TDs_total<pix_cutoff, axis = 0), range(len(TDs_x))]+1\n",
    "    TDs_fr = df['frames'][TDs_fr_idcs]\n",
    "    return TDs_fr_idcs, TDs_fr\n",
    "\n",
    "\n",
    "def remove_uncertain_TD_frames_df(TDs_fr_idcs, vel, where_slow, min_n_fr_before_TD, max_slow_during_swing, fraction_track_cutoff): # remove any TD_frs that don't have at least __ non-nan frames before\n",
    "    v_chunks = np.split(vel, TDs_fr_idcs-1)\n",
    "    ws_chunks = np.split(where_slow, TDs_fr_idcs-1)\n",
    "    wf_chunks = np.split(np.logical_not(where_slow), TDs_fr_idcs-1)\n",
    "    n_finite_fr_before = np.array([0]+ [np.sum(np.isfinite(c[-min_n_fr_before_TD:])) for c in v_chunks][:-1])\n",
    "    fraction_tracked = np.array([np.sum(np.isfinite(c))/len(c) for c in v_chunks])\n",
    "    n_slow_in_center = np.array([np.sum(np.logical_not(np.trim_zeros(np.logical_not(np.trim_zeros(c,'f'))))) for c in ws_chunks ])\n",
    "    good_TDs = (n_finite_fr_before == min_n_fr_before_TD)[1:]\n",
    "    tmp = np.logical_and(good_TDs[:-1], good_TDs[1:]) # good strides must be between two good TDs\n",
    "    tmp2 = np.logical_and.reduce((n_finite_fr_before==min_n_fr_before_TD, n_slow_in_center<=max_slow_during_swing, fraction_tracked > fraction_track_cutoff))[1:-1]\n",
    "    good_strides = np.logical_and(tmp, tmp2)\n",
    "    return good_TDs, good_strides\n",
    "\n",
    "\n",
    "def find_stride_dur_df(TDs_fr_idcs, TDs_fr, good_strides):\n",
    "    stride_durations = np.diff(TDs_fr_idcs)[good_strides]\n",
    "    stride_TDstart = TDs_fr[:-1][good_strides].astype(int)\n",
    "    stride_TDstop = TDs_fr[1:][good_strides].astype(int)\n",
    "    return stride_durations, stride_TDstart, stride_TDstop\n",
    "\n",
    "\n",
    "def find_stride_dist_df(df, jj, TDs_fr_idcs, good_strides):\n",
    "    k = 'joint%i'%jj\n",
    "    # stride length\n",
    "    d_x = np.diff(df['%s_x_filt_fullfr'%k][TDs_fr_idcs])\n",
    "    d_y = np.diff(df['%s_y_filt_fullfr'%k][TDs_fr_idcs])\n",
    "    stride_dists = np.linalg.norm(np.array([d_x, d_y]), axis = 0)[good_strides]\n",
    "    # stride thorax total distance\n",
    "    d_tx = np.diff(df['thorax_x_filt_fullfr'][TDs_fr_idcs])\n",
    "    d_ty = np.diff(df['thorax_y_filt_fullfr'][TDs_fr_idcs])\n",
    "    thorax_dists_total = np.linalg.norm(np.array([d_tx, d_ty]), axis = 0)[good_strides]\n",
    "    # stride thorax straight distance\n",
    "    d_nx = np.diff([df['thorax_x_filt_fullfr'][TDs_fr_idcs], df['neck_x_filt_fullfr'][TDs_fr_idcs]], axis = 0)[0]\n",
    "    d_ny = np.diff([df['thorax_y_filt_fullfr'][TDs_fr_idcs], df['neck_y_filt_fullfr'][TDs_fr_idcs]], axis = 0)[0]\n",
    "    a=[d_nx[:-1], d_ny[:-1]]\n",
    "    b=[d_tx, d_ty]\n",
    "    thorax_dists_straight = np.einsum('ik,ik->k', b, a/np.linalg.norm(a, axis =0))[good_strides]\n",
    "    # stride travel direction rotation\n",
    "    a=[d_nx[:-1], d_ny[:-1]]\n",
    "    b=[d_tx, d_ty]\n",
    "    travel_dir = np.rad2deg(np.arctan2(np.cross(a,b,axis=0),np.einsum('ik,ik->k',a,b)))[good_strides]\n",
    "    # stride facing rotation\n",
    "    a=[d_nx[:-1],d_ny[:-1]]\n",
    "    b=[d_nx[1:],d_ny[1:]]\n",
    "    rotations = np.rad2deg(np.arctan2(np.cross(a,b,axis=0),np.einsum('ik,ik->k',a,b)))[good_strides]\n",
    "    return stride_dists, thorax_dists_total, thorax_dists_straight, travel_dir, rotations\n",
    "    \n",
    "    \n",
    "def find_touchdowns_df(df, jj, vel_cutoff, gap_size_to_close, n_stance_fr, min_TD_separation, n_nearby_frs, pix_cutoff,\n",
    "                       min_n_fr_before_TD, max_slow_during_swing, fraction_track_cutoff): \n",
    "    vel = np.linalg.norm(np.diff(np.array([df['joint%i_x_filt_fullfr'%jj], df['joint%i_y_filt_fullfr'%jj]])), axis=0)\n",
    "    # how much noise is there?\n",
    "    if np.sum(vel<1)/np.sum(np.isfinite(vel))>0.6:\n",
    "        vel_cutoff = 1\n",
    "        pix_cutoff = 2\n",
    "    elif np.sum(vel<1.5)/np.sum(np.isfinite(vel))>0.6:\n",
    "        vel_cutoff = 1.5\n",
    "        pix_cutoff = 2\n",
    "    elif np.sum(vel<2)/np.sum(np.isfinite(vel))>0.5:\n",
    "        vel_cutoff = 2\n",
    "    else:\n",
    "        vel_cutoff = 3\n",
    "    where_slow = vel<vel_cutoff\n",
    "    where_slow[find_nan_gaps(np.logical_not(where_slow), gap_size_to_close)] = True\n",
    "    TDs = find_start_of_stance_df(vel, vel_cutoff, gap_size_to_close, n_stance_fr)\n",
    "    TDs, TDs_x, TDs_y = remove_close_TDs_df(TDs, min_TD_separation, df, jj, n_stance_fr) # remove TDs that are close to eachother\n",
    "    TDs_fr_idcs, TDs_fr = find_TD_frames_df(df, jj, TDs, TDs_x, TDs_y, n_nearby_frs, pix_cutoff) # find frames of touchdown\n",
    "    good_TDs, good_strides = remove_uncertain_TD_frames_df(TDs_fr_idcs, vel, where_slow, min_n_fr_before_TD, max_slow_during_swing, fraction_track_cutoff)\n",
    "    stride_dur, stride_TDstart, stride_TDstop = find_stride_dur_df(TDs_fr_idcs, TDs_fr, good_strides)\n",
    "    stride_dist, thorax_dists_total, thorax_dists_straight, travel_dir, rotations = find_stride_dist_df(df, jj, TDs_fr_idcs, good_strides)\n",
    "#     print(TDs.shape, TDs_f, r_raw.shape, stride_dur_idcs.shape, stride_dist_idcs.shape)\n",
    "    return vel, TDs_fr_idcs, stride_TDstart, stride_TDstop, stride_dur, stride_dist, thorax_dists_total, \\\n",
    "            thorax_dists_straight, travel_dir, rotations, good_TDs, good_strides\n",
    "\n",
    "\n",
    "# user set parameters\n",
    "vel_cutoff= 3 # what velocity cutoff for identifying stances\n",
    "gap_size_to_close = 3 # interpolate where slow data\n",
    "n_stance_fr = 5 # how many frames of \"stance\" for it to be a legit \"stance\"\n",
    "min_TD_separation = 10 # how close can subsequent TDs be to each other\n",
    "n_nearby_frs = 12 # how many frames around TD to look for TD frame (first fr when foot within __ pix of TD location)\n",
    "pix_cutoff = 3 # how large of a radius around TD location to look for first TD frame\n",
    "min_n_fr_before_TD = 3 # how many non-nan frames before TD to make sure you're getting the correct TD timing\n",
    "max_slow_during_swing = 1 # how many slow points allowed outside of initial slow section\n",
    "fraction_track_cutoff = 0.8 # percent of stride that needs to be tracked (not missing extra TD)\n",
    "\n",
    "\n",
    "for joint_num in range(0,6):\n",
    "    print(joint_num)\n",
    "#     shapeOI = df['frames'].shape\n",
    "    \n",
    "    columns_to_drop = ['joint%i_vel'%joint_num, 'joint%i_TD_idcs'%joint_num, 'joint%i_St_start'%joint_num, 'joint%i_St_stop'%joint_num,\n",
    "                       'joint%i_St_Len'%joint_num, 'joint%i_St_Dur'%joint_num,\n",
    "                      'joint%i_St_tdist_total'%joint_num, 'joint%i_St_tdist_straight'%joint_num, 'joint%i_St_rotation'%joint_num,\n",
    "                      'joint%i_good_TDs'%joint_num, 'joint%i_good_strides'%joint_num, 'joint%i_St_travel_dir'%joint_num,\n",
    "                      'St_Len_all', 'St_Dur_all', 'St_tdist_total', 'St_tdist_straight', 'St_rotation', 'St_travel_dir',\n",
    "                      'joint%i_TD_x'%joint_num, 'joint%i_TD_y'%joint_num]\n",
    "    for colmn in columns_to_drop:\n",
    "        if colmn in df: # remove columns if already exist\n",
    "            df = df.drop(colmn, axis = 1)\n",
    "\n",
    "    df = df.reindex( columns = df.columns.tolist() + ['joint%i_vel'%joint_num, 'joint%i_TD_idcs'%joint_num, 'joint%i_St_Len'%joint_num,  \n",
    "        'joint%i_St_tdist_total'%joint_num, 'joint%i_St_start'%joint_num, 'joint%i_St_stop'%joint_num,\n",
    "        'joint%i_St_tdist_straight'%joint_num, 'joint%i_St_rotation'%joint_num, 'joint%i_St_travel_dir'%joint_num,\n",
    "        'joint%i_St_Dur'%joint_num, 'joint%i_good_TDs'%joint_num, 'joint%i_good_strides'%joint_num] )\n",
    "    df['joint%i_vel'%joint_num], df['joint%i_TD_idcs'%joint_num],  df['joint%i_St_start'%joint_num],  df['joint%i_St_stop'%joint_num], \\\n",
    "        df['joint%i_St_Dur'%joint_num], df['joint%i_St_Len'%joint_num], \\\n",
    "        df['joint%i_St_tdist_total'%joint_num], df['joint%i_St_tdist_straight'%joint_num], df['joint%i_St_travel_dir'%joint_num], \\\n",
    "        df['joint%i_St_rotation'%joint_num], df['joint%i_good_TDs'%joint_num], df['joint%i_good_strides'%joint_num] = zip(*df.apply(\n",
    "        find_touchdowns_df, args = (joint_num, vel_cutoff, gap_size_to_close, n_stance_fr, min_TD_separation, n_nearby_frs, pix_cutoff, \n",
    "                                    min_n_fr_before_TD, max_slow_during_swing, fraction_track_cutoff), axis=1))\n",
    "    \n",
    "del colmn, columns_to_drop\n",
    "\n",
    "print('all done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make images and video of raw tracked & analyzed data on background subtract and raw footage\n",
    "-- for user given trackway number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/3mm/20180314_094259_16276718-0000.mp4\n",
      "** Deleted LEAPtracking_filter_PAPER.mp4 file\n",
      "saving LEAPtracking_filter_PAPER.mp4 file\n"
     ]
    }
   ],
   "source": [
    "# plot images with tracked data and lowpass filtered data\n",
    "tr_num = 1007 #105 #91 #105 # 1662\n",
    "\n",
    "\n",
    "def load_video(raw_video_path, frame_range, verbose):\n",
    "    \"\"\"\n",
    "    Independent of the frame range loaded, background has to be computed over total video or else can run into\n",
    "    tracking problems\n",
    "    \"\"\"\n",
    "    vid = cv2.VideoCapture(raw_video_path)\n",
    "    Height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    NumFrames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if not (NumFrames > 0):\n",
    "        raise IOError('Codec issue: cannot read number of frames.')\n",
    "\n",
    "    # restrict to desired range of frames\n",
    "    if frame_range is None:\n",
    "        frame_range = (0, int(NumFrames))\n",
    "    else:\n",
    "        # check doesn't exceed number of frames\n",
    "        if frame_range[0] + frame_range[1] > NumFrames:\n",
    "            frame_range = (int(frame_range[0]), int(NumFrames - frame_range[0]))\n",
    "\n",
    "    # initialize blank frames\n",
    "    frames = np.zeros((frame_range[1], Height, Width), np.uint8)\n",
    "\n",
    "    # set the first frame to read in\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for kk in range(frame_range[0]):\n",
    "        tru, ret = self.vid.read(1)\n",
    "    # vid.set(cv.CAP_PROP_POS_FRAMES, frame) # this way of setting the frame doesn't work on all cv versions\n",
    "\n",
    "    # read in all frames\n",
    "    for kk in range(frame_range[1]):\n",
    "        tru, ret = vid.read(1)\n",
    "\n",
    "        # check if video frames are being loaded\n",
    "        if not tru:\n",
    "            raise IOError('Codec issue: cannot load frames.')\n",
    "        frames[kk, :, :] = ret[:, :, 0]  # assumes loading color\n",
    "        if ((kk % 100) == 0) and verbose:\n",
    "            print(kk)\n",
    "    return frames, NumFrames, frame_range, vid\n",
    "\n",
    "\n",
    "def remove_background(raw_video_path, frame_range, bkg_method, bkg_sep, verbose):\n",
    "\n",
    "    # load in video, get video features\n",
    "    frames, NumFrames, frame_range, vid = load_video(raw_video_path, frame_range, verbose)\n",
    "\n",
    "    # if all frames loaded, do as normal\n",
    "    if frame_range[1] == NumFrames:\n",
    "        background = np.float32(np.median(frames[0::bkg_sep,:,:], axis = 0))\n",
    "        if verbose:\n",
    "            print('all_loaded!')\n",
    "    else: # still use full video for background, not just desired output range\n",
    "        background = []\n",
    "        for kk in range(0, NumFrames, bkg_sep):\n",
    "            vid.set(cv2.CAP_PROP_POS_FRAMES, kk)\n",
    "            tru, ret = vid.read(1)\n",
    "\n",
    "            # check if video frames are being loaded\n",
    "            if not tru:\n",
    "                raise IOError('Codec issue: cannot load frames.')\n",
    "\n",
    "            background.append(ret[:,:,0])  # assumes loading color\n",
    "        background = np.array(background, dtype='float32')\n",
    "        background = np.float32(np.median(background, axis=0))\n",
    "\n",
    "    # add a small number to background to not have divide by zeros for division\n",
    "    background = background + np.float32(1E-6)\n",
    "    if verbose:\n",
    "        print('Background calculated')\n",
    "    if bkg_method == 'div':\n",
    "        norm_bkg = np.mean(background[:])  # normalize for mean intensity of image\n",
    "        # norm_frm = np.mean(frames, axis=(1,2)) # normalize for mean intensity of current frame. For flicker\n",
    "        frames_normed = (frames / norm_bkg) / (background / norm_bkg)  # broadcasting\n",
    "    elif bkg_method == 'sub':\n",
    "        raise IOError('Code does not currently support background subtraction, only division')\n",
    "    else:\n",
    "        raise IOError('Background divsion/subtraction method not recognized. Use div.')\n",
    "    if verbose:\n",
    "        print('Background removed')\n",
    "    return frames_normed\n",
    "\n",
    "def augment_contrast(frames, invert, cutoff, verbose):\n",
    "\n",
    "    # center around 0 (neg = darker than background, pos = lighter than background)\n",
    "    frames = frames-1\n",
    "\n",
    "    # if there is a light backgroud, invert images\n",
    "    if invert:\n",
    "        frames = -1*frames\n",
    "        if verbose:\n",
    "            print('Inverted frames')\n",
    "\n",
    "    # find max pixel value for each frame\n",
    "    max_pixel_vals = frames.max(1).max(1)\n",
    "\n",
    "    # divide by max so that all darker than background pixels are from -1 to 0 and lighter pixels are from 0 to 1\n",
    "    frames_maxone = frames / max_pixel_vals[:,None,None]\n",
    "    if frames_maxone.max(1).max(1).max(0) > 1:\n",
    "        raise IOError('Error in normalized image. Did you background divide?')\n",
    "\n",
    "    # shift pixel values to determine how dark the background should be\n",
    "    frames_contrast = (255-cutoff)*frames_maxone + cutoff\n",
    "    frames_contrast[frames_contrast<0]=0\n",
    "\n",
    "    return frames_contrast\n",
    "\n",
    "\n",
    "def WRTant_to_WRTframe(val_x, val_y, frame_center_x, frame_center_y, ant_ang_deg):\n",
    "    ant_ang = ant_ang_deg *np.pi/180\n",
    "    R = np.array([[np.cos(ant_ang), -1*np.sin(ant_ang)],\n",
    "                  [np.sin(ant_ang),    np.cos(ant_ang)]])\n",
    "    rotated_vals = np.dot(R,np.array([val_x-100,val_y-100]))\n",
    "    translated_vals = rotated_vals*np.array([1,1]) + np.array([frame_center_x, frame_center_y])  \n",
    "    return translated_vals[0], translated_vals[1];\n",
    "\n",
    "def plot_ant_pt(ant_part, ant_part_num, filt, df, tr_num, idx, ant_x, ant_y, ant_ang_deg, buffer): #filt = '' if want raw data\n",
    "    x = df['%s%s_x%s'%(ant_part,str(ant_part_num),filt)][tr_num][idx]\n",
    "    y = df['%s%s_y%s'%(ant_part,str(ant_part_num),filt)][tr_num][idx]\n",
    "    conf = df['%s%s_conf'%(ant_part,str(ant_part_num))][tr_num][idx]\n",
    "#     (newx, newy)= (x,y)\n",
    "    (newx, newy) = WRTant_to_WRTframe(x, y, ant_x, ant_y, ant_ang_deg)\n",
    "#     print('old vals: %i, %i  TO %0.1f, %0.1f'%(x,y,newx, newy))\n",
    "\n",
    "    if ('joint' in ant_part) or ('antenna' in ant_part):\n",
    "        if '_filt' in filt:\n",
    "            \n",
    "            # plot strides and touchdowns\n",
    "            if 'joint%i_TD_idcs'%ant_part_num in df:\n",
    "                if idx in df['joint%i_TD_idcs'%ant_part_num][tr_num][df['joint%i_good_TDs'%ant_part_num][tr_num]]:\n",
    "#                     print('Joint %i -- Fr %i'%(ant_part_num, idx))\n",
    "                    sca = plt.scatter(newx+buffer, newy+buffer, s = 10, facecolor = 'none', edgecolor = 'w')\n",
    "                dur_starts = df['joint%i_TD_idcs'%ant_part_num][tr_num][:-1][df['joint%i_good_strides'%ant_part_num][tr_num]]\n",
    "                dur_stops = df['joint%i_TD_idcs'%ant_part_num][tr_num][1:][df['joint%i_good_strides'%ant_part_num][tr_num]]\n",
    "                if np.any(np.logical_and( ff>dur_starts, ff<dur_stops)):\n",
    "                    str_OI = dur_starts[ np.logical_and( ff>dur_starts, ff<dur_stops)]\n",
    "                    plt.plot([df['joint%i_x_filt_fullfr'%ant_part_num][tr_num][str_OI]+buffer, newx+buffer],\n",
    "                             [df['joint%i_y_filt_fullfr'%ant_part_num][tr_num][str_OI]+buffer, newy+buffer], '-w', alpha = 0.2)\n",
    "                \n",
    "            # plot actual feet points\n",
    "            if ant_part_num < 3:\n",
    "                sca = plt.scatter(newx+buffer, newy+buffer, c = 'c', s = 10, edgecolor = 'none')# '.g')\n",
    "            else:\n",
    "                sca = plt.scatter(newx+buffer, newy+buffer, c = 'm', s = 10, edgecolor = 'none')\n",
    "#             if ('joint' in ant_part):\n",
    "#                 if df['frames_final'][tr_num][fr_num] in df['%s%i_TD_frs'%(ant_part, ant_part_num)][tr_num]:\n",
    "#                     sca.set_edgecolor('w')\n",
    "        else:\n",
    "            # define colormap to show confidence\n",
    "            norm2 = colors.Normalize(vmin=0, vmax=1)\n",
    "            plt.scatter(newx+buffer, newy+buffer, c = conf, s = 10, cmap = cm.bwr,\n",
    "                       edgecolor = 'none', norm=norm2)# '.g')\n",
    "    else:\n",
    "        plt.scatter(newx+buffer, newy+buffer, c = 'w', s = 10, edgecolor = 'none')\n",
    "        \n",
    "    return;\n",
    "\n",
    "\n",
    "def crop_to_view(variable_to_use, tr_num, fr, x_dim, y_dim, buffer, axisOI):\n",
    "    x = df[variable_to_use%'x'][tr_num][ff]\n",
    "    y = df[variable_to_use%'y'][tr_num][ff]\n",
    "    xrange = range(int(round(x)), int(round(x+2*buffer)))\n",
    "    yrange = range(int(round(y)), int(round(y+2*buffer)))\n",
    "    # account for if range goes outside of video frame\n",
    "    xrange_actual = np.array(sorted(list( set(xrange) & set(range(0, x_dim+2*buffer) ) )))[[0,-1]]\n",
    "    yrange_actual = np.array(sorted(list( set(yrange) & set(range(0, y_dim+2*buffer) ) )))[[0,-1]]\n",
    "    plt.sca(axisOI)\n",
    "    plt.xlim(xrange_actual)\n",
    "    plt.ylim(yrange_actual)\n",
    "    \n",
    "    return xrange_actual, yrange_actual\n",
    "\n",
    "\n",
    "def save_image(vlocation, nfig, name_base):\n",
    "    pname = os.path.join(vlocation, '%s%d.png'%(name_base,nfig))\n",
    "    plt.savefig(pname)\n",
    "    nfig = nfig + 1\n",
    "    plt.pause(0.2)\n",
    "#     plt.close('all')\n",
    "    return nfig\n",
    "\n",
    "\n",
    "def save_video(vlocation, name_base):\n",
    "    # save images as movie\n",
    "    if os.path.isfile((vlocation+'/%s.mp4'%name_base)):\n",
    "        os.remove(vlocation + \"/%s.mp4\"%name_base)\n",
    "        print('** Deleted %s.mp4 file'%name_base)\n",
    "    print('saving %s.mp4 file'%name_base)\n",
    "    command_p1 = \"ffmpeg -r 10 -i '%s/%s\"%(vlocation, name_base)\n",
    "    command_p2 = \" -vcodec libx264 '%s/%s.mp4'\"%(vlocation, name_base)\n",
    "    command = command_p1 + \"%01d.png'\" + command_p2\n",
    "#     print(command)\n",
    "    os.system(command)\n",
    "    plt.pause(10)\n",
    "\n",
    "    # delete all trackway vids\n",
    "    pics2delete = glob.glob(os.path.join(vlocation, '%s*.png'%name_base))\n",
    "    for pic in pics2delete:\n",
    "        os.remove(pic)\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DO THE THINGS\n",
    "videofile = df.video[tr_num]\n",
    "print(videofile)\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "plt.close('all')\n",
    "# calc bkgd sub\n",
    "frames_normed = remove_background(videofile, None, 'div', 50, verbose = False)\n",
    "\n",
    "fig = plt.figure(figsize=(19.8,10.8))\n",
    "\n",
    "plt.gcf().text(0.05, 0.7, 'Rough substrates constrain walking speed in ants but not due to large limb perturbations', fontsize = 24)\n",
    "plt.gcf().text(0.05, 0.62, 'G. T. Clifton, D. Holway, N. Gravish', fontsize = 18)\n",
    "plt.gcf().text(0.05, 0.54, 'University of California, San Diego', fontsize = 18)\n",
    "plt.gcf().text(0.05, 0.2, '2019', fontsize = 18)\n",
    "for title_fr in range(0,10*2):\n",
    "    save_image(vlocation, title_fr, 'LEAPtracking_filter_PAPER')\n",
    "\n",
    "\n",
    "limbs = ['LH','LM','LF', 'RH', 'RM', 'RF']\n",
    "for im_n, fr_OI in enumerate( range(310,510)):# df.frames[tr_num][:]):\n",
    "#     fr_id = np.where(df.frames_final[tr_num] == fr_OI)[0][0]\n",
    "    plt.clf()\n",
    "    # load frame\n",
    "    ff=np.where(df.frames[tr_num]==fr_OI)[0][0]\n",
    "    cap.set(1,int(fr_OI))\n",
    "    ret, frame = cap.read()\n",
    "    x_dim = frame.shape[1]\n",
    "    y_dim = frame.shape[0]\n",
    "    bkgdframe = np.stack((frames_normed[int(fr_OI),:,:],)*3,-1)\n",
    "    \n",
    "    # load ant x, y and angle\n",
    "    x = df.x_raw[tr_num][ff]\n",
    "    y = df.y_raw[tr_num][ff]\n",
    "    ang = df.angle_improved[tr_num][ff]\n",
    "    (thorax_x, thorax_y) = WRTant_to_WRTframe(df.thorax_x[tr_num][ff], df.thorax_y[tr_num][ff], x, y, ang)\n",
    "    (neck_x, neck_y) = WRTant_to_WRTframe(df.neck_x[tr_num][ff], df.neck_y[tr_num][ff], x, y, ang)\n",
    "#     print(x,y,ang)\n",
    "\n",
    "    # PLOT THINGS\n",
    "    \n",
    "    # BCKGD SUB IMAGE WITH TRACKED DATA & CONFIDENCE\n",
    "    ax2=fig.add_axes([0.02,0.1, 0.35, 0.7]) #plt.axes()\n",
    "    # zoom into around ant\n",
    "    buffer = 150\n",
    "    white_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer,3),dtype=np.float32)\n",
    "    wframe = white_frame.copy()\n",
    "    wframe[buffer:-buffer, buffer:-buffer,:] = bkgdframe\n",
    "    wframe = wframe/np.max(wframe)\n",
    "    plt.imshow(wframe)\n",
    "    \n",
    "    xrange_actual, yrange_actual = crop_to_view('%s_raw', tr_num, ff, x_dim, y_dim, buffer, ax2)\n",
    "#     plt.text(xrange_actual[0]+20, yrange_actual[0]+20, 'Fr: %i'%fr_OI, color='k')\n",
    "    plt.imshow(wframe)\n",
    "    cmap = cm.bwr\n",
    "    plt.scatter(x+buffer, y+buffer, s=20, c=np.array(0.5), norm = colors.Normalize(vmin=0, vmax=1), marker= 'o')\n",
    "    plt.scatter(x+10, y+2*buffer-10, s=20, c=np.array(0.5), norm = colors.Normalize(vmin=0, vmax=1), marker= 'o')\n",
    "    plt.text(x+15, y+2*buffer-10, 'estimated ant location from full body tracking', color = 'k', verticalalignment = \"center\")\n",
    "    \n",
    "    if not np.isnan(ang):\n",
    "        plt.scatter(thorax_x+buffer, thorax_y+buffer, c = df.thorax_conf[tr_num][ff], s = 10, \n",
    "                cmap = cmap, norm = colors.Normalize(vmin=0, vmax=1))\n",
    "        plt.scatter(neck_x+buffer, neck_y+buffer, c = df.neck_conf[tr_num][ff], s = 10, \n",
    "                cmap = cmap, norm = colors.Normalize(vmin=0, vmax=1))\n",
    "        for jj in range(0,6):\n",
    "            plot_ant_pt('joint',jj, '', df, tr_num, ff, x, y, ang, buffer)\n",
    "            #plot_ant_pt('joint',jj,'_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "        for aa in range(0,2):\n",
    "            plot_ant_pt('antenna',aa, '', df, tr_num, ff, x, y, ang, buffer)\n",
    "#     plt.plot(df['joint0_x_filt'][tr_num][ff],df['joint0_y_filt'][tr_num][ff], '.g')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.gcf().text(0.02, 0.82, 'Raw LEAP output on background-subtracted, cropped view', color='k', FontSize = 12)\n",
    "    plt.gcf().text(0.02, 0.79, 'frame: %i'%fr_OI, color='k', FontSize = 12)\n",
    "    \n",
    "    # COLORBAR\n",
    "    cax = plt.axes([0.02,0.08,0.35, 0.03])\n",
    "    plt.colorbar(cax=cax, label = 'confidence', orientation = 'horizontal')\n",
    "    plt.clim(0,1)\n",
    "    plt.set_cmap(cm.bwr)\n",
    "    \n",
    "    # RAW IMAGE WITH FILTERED DATA\n",
    "    ax3=fig.add_axes([0.40,0.1, 0.35, 0.7]) #plt.axes()\n",
    "    black_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer,3),dtype=np.uint8)* 1# 1.001# np.max(temp) # gray background  1.0001#\n",
    "    bframe = black_frame.copy()\n",
    "    bframe[buffer:-buffer, buffer:-buffer,:] = frame\n",
    "    plt.imshow(bframe)\n",
    "    plt.text(xrange_actual[0]+10, yrange_actual[1]-30, 'Trusted Strides: ', color= 'w')\n",
    "    for jj in range(0,6):\n",
    "            plot_ant_pt('joint',jj,'_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "            if 'joint%i_TD_idcs'%jj in df:\n",
    "    \n",
    "                # plot duration info\n",
    "                dur_starts = df['joint%i_TD_idcs'%jj][tr_num][:-1][df['joint%i_good_strides'%jj][tr_num]]\n",
    "                dur_stops = df['joint%i_TD_idcs'%jj][tr_num][1:][df['joint%i_good_strides'%jj][tr_num]]\n",
    "                if ff in dur_starts:\n",
    "                    plt.text( xrange_actual[0]+65+jj*15, yrange_actual[1]-30, limbs[jj], color = [1,1,1])\n",
    "                elif np.any(np.logical_and( ff>dur_starts, ff<dur_stops)):\n",
    "                    plt.text( xrange_actual[0]+65+jj*15, yrange_actual[1]-30, limbs[jj], color=  ['c','m'][int(jj/3)])\n",
    "        \n",
    "    plot_ant_pt('thorax', '', '_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "    plot_ant_pt('neck', '', '_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "    plt.xlim(xrange_actual)\n",
    "    plt.ylim(yrange_actual)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.scatter(xrange_actual[0]+10, yrange_actual[1]-20, s = 10, facecolor = 'none', edgecolor = 'w')\n",
    "    plt.text( xrange_actual[0]+17, yrange_actual[1]-20, 'touchdown', color = [1,1,1], verticalalignment = \"center\")\n",
    "    plt.plot([xrange_actual[0]+10, xrange_actual[0]+14],[yrange_actual[1]-10, yrange_actual[1]-10], '-w', alpha = 0.2)\n",
    "    plt.text( xrange_actual[0]+17, yrange_actual[1]-10, 'swing trajectory', color = [1,1,1], verticalalignment = \"center\")\n",
    "    plt.gcf().text(0.4, 0.82, 'Post-processed body and limb tracking', color='k', FontSize = 12)\n",
    "    plt.gcf().text(0.4, 0.79, 'low confidence removed, lowpass filtered', color='k', FontSize = 12)\n",
    "    \n",
    "    # FULL FRAME\n",
    "    ax1=fig.add_axes([0.78,0.77, 0.2, 0.23])\n",
    "    ax1.set_position([0.78,0.77, 0.2, 0.23])\n",
    "    plt.imshow(frame)\n",
    "    plt.plot(x, y, '.w')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # VELOCITY TRACES OF LEGS\n",
    "    ax4=fig.add_axes([0.78,0.14, 0.2, 0.60])#plt.axes()\n",
    "    for jj in range(0,6):\n",
    "#         plt.plot(range(1,ff),df['joint%i_x_filt'%jj][tr_num][1:ff]-df.thorax_x_filt[tr_num][1:ff], '-', color= col)\n",
    "        plt.plot(range(1,ff),df['joint%i_vel'%jj][tr_num][1:ff]+jj%3*20, '-', color = ['c','m'][int(jj/3)], alpha = 0.3)\n",
    "        if 'joint%i_TD_idcs'%jj in df:\n",
    "            TDs = df['joint%i_TD_idcs'%jj][tr_num][df['joint%i_good_TDs'%jj][tr_num]]\n",
    "            idcs_OI = TDs[TDs<=ff]\n",
    "#                 plt.plot(idcs_OI,df['joint%i_x_filt'%jj][tr_num][idcs_OI]-df.thorax_x_filt[tr_num][idcs_OI], '.', color = col)\n",
    "            plt.plot(idcs_OI,df['joint%i_vel'%jj][tr_num][idcs_OI]+jj%3*20, '.', color = ['c','m'][int(jj/3)])              \n",
    "    plt.xlim((-10,len(df['frames'][tr_num])))\n",
    "    plt.ylim((0,60))\n",
    "    plt.text(-10,51,'forelimbs')\n",
    "    plt.text(-10,31,'midlimbs')\n",
    "    plt.text(-10,11,'hindlimbs')\n",
    "    plt.text(-10,57,'limbs:')\n",
    "    plt.text(70,57,'left', color = 'c')\n",
    "    plt.text(120,57,'right', color = 'm')\n",
    "    plt.text(-10,55,'identified touchdowns:')\n",
    "    plt.plot(250,55.4,'.', color = 'c')\n",
    "    plt.plot(272,55.4,'.', color = 'm')\n",
    "    plt.plot([500,500],[50,50-10/v_multiplier],'-k')\n",
    "    plt.text(490,50-5/v_multiplier,'10 mm/s', color ='k', horizontalalignment='right', verticalalignment='center')\n",
    "    plt.gcf().text(0.78, 0.74, 'limb velocities', color='k', FontSize = 12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    titleparts = videofile.split('/')\n",
    "    plt.suptitle( '%s -- %s -- %s'\n",
    "                  %(titleparts[-2], titleparts[-1].split('_')[0], titleparts[-1].split('_')[1]),x=0.02, y=.95, horizontalalignment = 'left')\n",
    "    plt.pause(0.1)\n",
    "    \n",
    "    vlocation = '/media/gravishlab/SeagateExpansionDrive/AntTrack'\n",
    "    save_image(vlocation, im_n+10*2, 'LEAPtracking_filter_PAPER')\n",
    "save_video(vlocation, 'LEAPtracking_filter_PAPER')\n",
    "    \n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run through all tracks and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot images with tracked data and lowpass filtered data\n",
    "print('running data visualization')\n",
    "\n",
    "def load_video(raw_video_path, frame_range, verbose):\n",
    "    \"\"\"\n",
    "    Independent of the frame range loaded, background has to be computed over total video or else can run into\n",
    "    tracking problems\n",
    "    \"\"\"\n",
    "    vid = cv2.VideoCapture(raw_video_path)\n",
    "    Height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    NumFrames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if not (NumFrames > 0):\n",
    "        raise IOError('Codec issue: cannot read number of frames.')\n",
    "\n",
    "    # restrict to desired range of frames\n",
    "    if frame_range is None:\n",
    "        frame_range = (0, int(NumFrames))\n",
    "    else:\n",
    "        # check doesn't exceed number of frames\n",
    "        if frame_range[0] + frame_range[1] > NumFrames:\n",
    "            frame_range = (int(frame_range[0]), int(NumFrames - frame_range[0]))\n",
    "\n",
    "    # initialize blank frames\n",
    "    frames = np.zeros((frame_range[1], Height, Width), np.uint8)\n",
    "\n",
    "    # set the first frame to read in\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for kk in range(frame_range[0]):\n",
    "        tru, ret = self.vid.read(1)\n",
    "    # vid.set(cv.CAP_PROP_POS_FRAMES, frame) # this way of setting the frame doesn't work on all cv versions\n",
    "\n",
    "    # read in all frames\n",
    "    for kk in range(frame_range[1]):\n",
    "        tru, ret = vid.read(1)\n",
    "\n",
    "        # check if video frames are being loaded\n",
    "        if not tru:\n",
    "            raise IOError('Codec issue: cannot load frames.')\n",
    "        frames[kk, :, :] = ret[:, :, 0]  # assumes loading color\n",
    "        if ((kk % 100) == 0) and verbose:\n",
    "            print(kk)\n",
    "    return frames, NumFrames, frame_range, vid\n",
    "\n",
    "\n",
    "def remove_background(frames, bkg_method, bkg_sep, verbose):\n",
    "\n",
    "    # load in video, get video features\n",
    "#     frames, NumFrames, frame_range, vid = load_video(raw_video_path, frame_range, verbose)\n",
    "\n",
    "    # if all frames loaded, do as normal\n",
    "    background = np.float32(np.median(frames[0::bkg_sep,:,:], axis = 0))\n",
    "    if verbose:\n",
    "        print('all_loaded!')\n",
    "    background = np.array(background, dtype='float32')\n",
    "    background = np.float32(np.median(background, axis=0))\n",
    "\n",
    "    # add a small number to background to not have divide by zeros for division\n",
    "    background = background + np.float32(1E-6)\n",
    "    if verbose:\n",
    "        print('Background calculated')\n",
    "    if bkg_method == 'div':\n",
    "        norm_bkg = np.mean(background[:])  # normalize for mean intensity of image\n",
    "        # norm_frm = np.mean(frames, axis=(1,2)) # normalize for mean intensity of current frame. For flicker\n",
    "        frames_normed = (frames / norm_bkg) / (background / norm_bkg)  # broadcasting\n",
    "    elif bkg_method == 'sub':\n",
    "        raise IOError('Code does not currently support background subtraction, only division')\n",
    "    else:\n",
    "        raise IOError('Background divsion/subtraction method not recognized. Use div.')\n",
    "    if verbose:\n",
    "        print('Background removed')\n",
    "    return frames_normed\n",
    "\n",
    "def augment_contrast(frames, invert, cutoff, verbose):\n",
    "\n",
    "    # center around 0 (neg = darker than background, pos = lighter than background)\n",
    "    frames = frames-1\n",
    "\n",
    "    # if there is a light backgroud, invert images\n",
    "    if invert:\n",
    "        frames = -1*frames\n",
    "        if verbose:\n",
    "            print('Inverted frames')\n",
    "\n",
    "    # find max pixel value for each frame\n",
    "    max_pixel_vals = frames.max(1).max(1)\n",
    "\n",
    "    # divide by max so that all darker than background pixels are from -1 to 0 and lighter pixels are from 0 to 1\n",
    "    frames_maxone = frames / max_pixel_vals[:,None,None]\n",
    "    if frames_maxone.max(1).max(1).max(0) > 1:\n",
    "        raise IOError('Error in normalized image. Did you background divide?')\n",
    "\n",
    "    # shift pixel values to determine how dark the background should be\n",
    "    frames_contrast = (255-cutoff)*frames_maxone + cutoff\n",
    "    frames_contrast[frames_contrast<0]=0\n",
    "\n",
    "    return frames_contrast\n",
    "\n",
    "\n",
    "def WRTant_to_WRTframe(val_x, val_y, frame_center_x, frame_center_y, ant_ang_deg):\n",
    "    ant_ang = ant_ang_deg *np.pi/180\n",
    "    R = np.array([[np.cos(ant_ang), -1*np.sin(ant_ang)],\n",
    "                  [np.sin(ant_ang),    np.cos(ant_ang)]])\n",
    "    rotated_vals = np.dot(R,np.array([val_x-100,val_y-100]))\n",
    "    translated_vals = rotated_vals*np.array([1,1]) + np.array([frame_center_x, frame_center_y])  \n",
    "    return translated_vals[0], translated_vals[1];\n",
    "\n",
    "def plot_full_frame(fr_OI, x, y):\n",
    "    plt.sca(ax1)\n",
    "    frame_toshow = np.stack((frames[int(fr_OI),:,:],)*3,-1)\n",
    "#     ff=np.where(df.frames[tr_num]==fr_OI)[0][0]\n",
    "#     x = df.x_raw[tr_num][ff]\n",
    "#     y = df.y_raw[tr_num][ff]\n",
    "    \n",
    "    ax1.cla()\n",
    "    plt.imshow(frame_toshow)\n",
    "    plt.plot(x, y, '.w')\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def plot_raw_tracking(fr_OI, x, y, ff, ang):\n",
    "    plt.sca(ax2)\n",
    "    ax2.cla()\n",
    "    # BCKGD SUB IMAGE WITH TRACKED DATA & CONFIDENCE\n",
    "    bkgdframe = np.stack((frames_normed[int(fr_OI),:,:],)*3,-1)\n",
    "\n",
    "    # zoom into around ant\n",
    "    buffer = 150\n",
    "    white_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer,3),dtype=np.float32)\n",
    "    wframe = white_frame.copy()\n",
    "    wframe[buffer:-buffer, buffer:-buffer,:] = bkgdframe\n",
    "    wframe = wframe/np.max(wframe)\n",
    "    \n",
    "    plt.imshow(wframe)\n",
    "    xrange_actual, yrange_actual = crop_to_view('%s_raw', tr_num, ff, x_dim, y_dim, buffer, ax2)\n",
    "    plt.text(xrange_actual[0]+20, yrange_actual[0]+20, 'Fr: %i'%fr_OI, color='k')\n",
    "    cmap = cm.bwr\n",
    "\n",
    "    if not np.isnan(ang):\n",
    "        plot_ant_pt('neck','', '', df, tr_num, ff, x, y, ang, buffer)\n",
    "        plot_ant_pt('thorax', '', '', df, tr_num, ff, x, y, ang, buffer)\n",
    "        for jj in range(0,6):\n",
    "            plot_ant_pt('joint',jj, '', df, tr_num, ff, x, y, ang, buffer)\n",
    "        for aa in range(0,2):\n",
    "            plot_ant_pt('antenna',aa, '', df, tr_num, ff, x, y, ang, buffer)\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    return\n",
    "\n",
    "def plot_final_tracking(fr_OI, x, y, ff, ang):\n",
    "    plt.sca(ax3)\n",
    "    ax3.cla()\n",
    "    buffer = 150\n",
    "    frame = np.stack((frames[int(fr_OI),:,:],)*3,-1)\n",
    "    black_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer,3),dtype=np.uint8)* 1# 1.001# np.max(temp) # gray background  1.0001#\n",
    "    bframe = black_frame.copy()\n",
    "    bframe[buffer:-buffer, buffer:-buffer,:] = frame\n",
    "    plt.imshow(bframe)\n",
    "    if fr_OI in df.frames_final[tr_num]:\n",
    "        fr_id = np.where(df.frames_final[tr_num] == fr_OI)[0][0]\n",
    "        for jj in range(0,6):\n",
    "                plot_ant_pt('joint',jj,'_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "        plot_ant_pt('thorax', '', '_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "        plot_ant_pt('neck', '', '_filt', df, tr_num, ff, x, y, ang, buffer)\n",
    "    xrange_actual, yrange_actual = crop_to_view('%s_raw', tr_num, ff, x_dim, y_dim, buffer, ax3)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.text(xrange_actual[0]+20, yrange_actual[0]+20, 'Low conf removed, lowpass filtered', color='w')\n",
    "    return\n",
    "\n",
    "def plot_ant_pt(ant_part, ant_part_num, filt, df, tr_num, fr_num, ant_x, ant_y, ant_ang_deg, buffer): #filt = '' if want raw data\n",
    "    x = df['%s%s_x%s'%(ant_part,str(ant_part_num),filt)][tr_num][fr_num]\n",
    "    y = df['%s%s_y%s'%(ant_part,str(ant_part_num),filt)][tr_num][fr_num]\n",
    "    conf = df['%s%s_conf'%(ant_part,str(ant_part_num))][tr_num][fr_num]\n",
    "#     (newx, newy)= (x,y)\n",
    "    (newx, newy) = WRTant_to_WRTframe(x, y, ant_x, ant_y, ant_ang_deg)\n",
    "#     print('old vals: %i, %i  TO %0.1f, %0.1f'%(x,y,newx, newy))\n",
    "\n",
    "    if ('joint' in ant_part) or ('antenna' in ant_part):\n",
    "        if '_filt' in filt:\n",
    "            if ant_part_num < 3:\n",
    "                sca = plt.scatter(newx+buffer, newy+buffer, c='c', s = 10, edgecolor = 'none')\n",
    "            else:\n",
    "                sca = plt.scatter(newx+buffer, newy+buffer, c = 'm', s = 10, edgecolor = 'none')\n",
    "                \n",
    "#             if ('joint' in ant_part):\n",
    "#                 if df['frames_final'][tr_num][fr_num] in df['%s%i_TD_frs'%(ant_part, ant_part_num)][tr_num]:\n",
    "#                     sca.set_edgecolor('w')\n",
    "        else:\n",
    "            # define colormap to show confidence\n",
    "            norm2 = colors.Normalize(vmin=0, vmax=1)\n",
    "            plt.scatter(newx+buffer, newy+buffer, c = conf, s = 10, cmap = cm.bwr,\n",
    "                       edgecolor = 'none', norm=norm2)# '.g')\n",
    "    else:\n",
    "        plt.scatter(newx+buffer, newy+buffer, c = 'w', s = 10, edgecolor = 'none')\n",
    "        \n",
    "    return;\n",
    "\n",
    "\n",
    "def crop_to_view(variable_to_use, tr_num, ff, x_dim, y_dim, buffer, axisOI):\n",
    "    x = df[variable_to_use%'x'][tr_num][ff]\n",
    "    y = df[variable_to_use%'y'][tr_num][ff]\n",
    "    xrange = range(int(round(x)), int(round(x+2*buffer)))\n",
    "    yrange = range(int(round(y)), int(round(y+2*buffer)))\n",
    "    # account for if range goes outside of video frame\n",
    "    xrange_actual = np.array(sorted(list( set(xrange) & set(range(0, x_dim+2*buffer) ) )))[[0,-1]]\n",
    "    yrange_actual = np.array(sorted(list( set(yrange) & set(range(0, y_dim+2*buffer) ) )))[[0,-1]]\n",
    "    plt.sca(axisOI)\n",
    "    plt.xlim(xrange_actual)\n",
    "    plt.ylim(yrange_actual)\n",
    "    return xrange_actual, yrange_actual\n",
    "\n",
    "\n",
    "def key_event(e):\n",
    "    global fr_OI\n",
    "    global close_fig\n",
    "\n",
    "    if e.key == \"right\":\n",
    "        fr_OI = fr_OI + 1\n",
    "    elif e.key == \"left\":\n",
    "        fr_OI = fr_OI - 1\n",
    "    elif e.key == \"w\":\n",
    "        close_fig = True\n",
    "        return\n",
    "    else:\n",
    "        return\n",
    "    fr_OI = int(\n",
    "        (fr_OI-df.frames_final[tr_num][0]) % (df.frames_final[tr_num][-1]-df.frames_final[tr_num][0]+1) \n",
    "        + df.frames_final[tr_num][0])\n",
    "    ff=np.where(df.frames[tr_num]==fr_OI)[0][0]\n",
    "    x = df.x_raw[tr_num][ff]\n",
    "    y = df.y_raw[tr_num][ff]\n",
    "    ang = df.angle_improved[tr_num][ff]\n",
    "    (thorax_x, thorax_y) = WRTant_to_WRTframe(df.thorax_x[tr_num][ff], df.thorax_y[tr_num][ff], x, y, ang)\n",
    "    (neck_x, neck_y) = WRTant_to_WRTframe(df.neck_x[tr_num][ff], df.neck_y[tr_num][ff], x, y, ang)\n",
    "    \n",
    "#     plt.plot(x, y, '.w')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plot_full_frame(fr_OI, x, y)\n",
    "    plot_raw_tracking(fr_OI, x, y, ff, ang)\n",
    "    plot_final_tracking(fr_OI, x, y, ff, ang)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#     plt.title('%s -- %s -- %s'%(folder_bits[-2], ('_').join(folder_bits[-1].split('_')[0:2]), h_path.split('/')[-1][:-3]), loc = 'left')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "def close_out_of_program():\n",
    "    continueon = input('Press any key to exit:  ')\n",
    "    print('\\nClosing down viewer...')\n",
    "    return #close_up_shop\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "i=threading.Thread(target=close_out_of_program, args = ())\n",
    "i.start()\n",
    "print('*** PRESS \"w\" TO CLOSE A FIGURE AND MOVE TO THE NEXT ANT H5 ***')\n",
    "for kk, tr_num in enumerate(range(45,49)):\n",
    "    close_fig = False\n",
    "    videofile = df.video[tr_num]\n",
    "    print(videofile)\n",
    "    cap = cv2.VideoCapture(videofile)\n",
    "    plt.close('all')\n",
    "    # calc bkgd sub\n",
    "    frames, NumFrames, frame_range, vid = load_video(videofile, None, verbose=False)\n",
    "    frames_normed = remove_background(frames, 'div', 50, verbose = False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,6))\n",
    "    fr_OI = int(df.frames_final[tr_num][0])\n",
    "    ff=np.where(df.frames[tr_num]==fr_OI)[0][0]\n",
    "\n",
    "    fr_id = np.where(df.frames_final[tr_num] == fr_OI)[0][0]\n",
    "    frame = frames[fr_OI]\n",
    "    x_dim = frame.shape[1]\n",
    "    y_dim = frame.shape[0]\n",
    "    bkgdframe = np.stack((frames_normed[int(fr_OI),:,:],)*3,-1)\n",
    "\n",
    "    # load ant x, y and angle\n",
    "    x = df.x_raw[tr_num][ff]\n",
    "    y = df.y_raw[tr_num][ff]\n",
    "    ang = df.angle_improved[tr_num][ff]\n",
    "    (thorax_x, thorax_y) = WRTant_to_WRTframe(df.thorax_x[tr_num][ff], df.thorax_y[tr_num][ff], x, y, ang)\n",
    "    (neck_x, neck_y) = WRTant_to_WRTframe(df.neck_x[tr_num][ff], df.neck_y[tr_num][ff], x, y, ang)\n",
    "    \n",
    "    \n",
    "    mngr = plt.get_current_fig_manager()\n",
    "    mngr.window.setGeometry(1550,300,1000,400)\n",
    "    \n",
    "    ax1=fig.add_axes([0.03,0.1, 0.2, 0.3])\n",
    "    plot_full_frame(fr_OI,x , y)\n",
    "    \n",
    "    ax2=fig.add_axes([0.25,0.1, 0.3, 0.8]) \n",
    "    plot_raw_tracking(fr_OI, x, y, ff, ang)\n",
    "    \n",
    "    # COLORBAR\n",
    "    cax = plt.axes([0.58,0.1,0.02,0.8])\n",
    "    plt.colorbar(cax=cax, label = 'confidence')\n",
    "    plt.clim(0,1)\n",
    "    plt.set_cmap(cm.bwr)\n",
    "    \n",
    "    ax3=fig.add_axes([0.65,0.1, 0.3, 0.8]) \n",
    "    plot_final_tracking(fr_OI, x, y, ff, ang)\n",
    "    \n",
    "    \n",
    "    fig.canvas.mpl_connect('key_press_event', key_event)\n",
    "    plt.show(block=False)\n",
    "\n",
    "    fig_open = plt.fignum_exists(fig.number)\n",
    "    while (not close_fig) and fig_open:\n",
    "        plt.pause(3)\n",
    "        if not i.isAlive():\n",
    "#                 print('User input has ended. Closing...')\n",
    "            break\n",
    "    plt.close(fig)\n",
    "\n",
    "    if not i.isAlive():\n",
    "#             print('User input has ended. Closing...')\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#     # POSITION TRACES OF LEGS\n",
    "#     ax4=fig.add_axes([0.03,0.35, 0.2, 0.6])#plt.axes()\n",
    "\n",
    "#     for jj in range(0,6):\n",
    "#         if jj <3 :\n",
    "#             plt.plot(range(1,fr_id),df['joint%i_x_filt'%jj][tr_num][1:fr_id]-df.thorax_x_filt[tr_num][1:fr_id], '.c')\n",
    "#             plt.plot(range(1,fr_id),df['joint%i_x_filt'%jj][tr_num][1:fr_id]-df.thorax_x_filt[tr_num][1:fr_id], '-c')\n",
    "#         else:\n",
    "#             plt.plot(range(1,fr_id),df['joint%i_x_filt'%jj][tr_num][1:fr_id]-df.thorax_x_filt[tr_num][1:fr_id], '-m')\n",
    "#     plt.xlim((-10,len(df['frames_final'][tr_num])))\n",
    "#     plt.ylim((-100,70))\n",
    "#     plt.text(-10,30,'fore')\n",
    "#     plt.text(-10,-20,'mid')\n",
    "#     plt.text(-10,-70,'hind')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     titleparts = videofile.split('/')\n",
    "#     plt.suptitle( '%s -- %s -- %s'\n",
    "#                   %(titleparts[-2], titleparts[-1].split('_')[0], titleparts[-1].split('_')[1]),x=0.03, y=.95, horizontalalignment = 'left')\n",
    "#     plt.pause(0.1)\n",
    "    \n",
    "    \n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT FULLFRAME\n",
    "tr_num = 46#105 #91 #105\n",
    "videofile = df.video[tr_num]\n",
    "print(videofile)\n",
    "cap = cv2.VideoCapture(videofile)\n",
    "plt.close('all')\n",
    "# calc bkgd sub\n",
    "frames_normed = remove_background(videofile, None, 'div', 50, verbose = False)\n",
    "\n",
    "\n",
    "# def plot_ant_pt(ant_part, ant_part_num, filt, df, tr_num, fr_num, ant_x, ant_y, ant_ang_deg, buffer): #filt = '' if want raw data\n",
    "#     x = df['%s%s_x%s'%(ant_part,str(ant_part_num),filt)][tr_num][fr_num]\n",
    "#     y = df['%s%s_y%s'%(ant_part,str(ant_part_num),filt)][tr_num][fr_num]\n",
    "#     conf = df['%s%s_conf'%(ant_part,str(ant_part_num))][tr_num][fr_num]\n",
    "#     (newx, newy)= (x,y)\n",
    "# #     print('%s%s_x%s'%(ant_part,str(ant_part_num),filt), tr_num, fr_num, newx,newy)\n",
    "# #     (newx, newy) = WRTant_to_WRTframe(x, y, ant_x, ant_y, ant_ang_deg)\n",
    "# #     print('old vals: %i, %i  TO %0.1f, %0.1f'%(x,y,newx, newy))\n",
    "\n",
    "#     if ('joint' in ant_part) or ('antenna' in ant_part):\n",
    "#         if '_filt' in filt:\n",
    "#             if ant_part_num < 3:\n",
    "#                 sca = plt.scatter(newx+buffer, newy+buffer, c = 'c', s = 10, edgecolor = 'none')# '.g')\n",
    "#             else:\n",
    "#                 sca = plt.scatter(newx+buffer, newy+buffer, c = 'm', s = 10, edgecolor = 'none')\n",
    "                \n",
    "#             if ('joint' in ant_part):\n",
    "#                 if df['frames_final'][tr_num][fr_num] in df['%s%i_TD_frs'%(ant_part, ant_part_num)][tr_num]:\n",
    "#                     sca.set_edgecolor('w')\n",
    "#         else:\n",
    "#             # define colormap to show confidence\n",
    "#             norm2 = colors.Normalize(vmin=0, vmax=1)\n",
    "#             plt.scatter(newx+buffer, newy+buffer, c = conf, s = 10, cmap = cm.bwr,\n",
    "#                        edgecolor = 'none', norm=norm2)# '.g')\n",
    "#     else:\n",
    "#         plt.scatter(newx+buffer, newy+buffer, c = 'w', s = 10, edgecolor = 'none')\n",
    "        \n",
    "#     return;\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "for im_n, fr_OI in enumerate( df.frames_final[tr_num][20:]):\n",
    "    fr_id = np.where(np.isin( df.frames_final[tr_num], fr_OI))\n",
    "    plt.clf()\n",
    "    # load frame\n",
    "    ff=np.where(df.frames[tr_num]==fr_OI)[0][0]\n",
    "    cap.set(1,int(fr_OI))\n",
    "    ret, frame = cap.read()\n",
    "    x_dim = frame.shape[1]\n",
    "    y_dim = frame.shape[0]\n",
    "    bkgdframe = np.stack((frames_normed[int(fr_OI),:,:],)*3,-1)\n",
    "    \n",
    "    # load ant x, y and angle\n",
    "    x = df.x_raw[tr_num][ff]\n",
    "    y = df.y_raw[tr_num][ff]\n",
    "    ang = df.angle_improved[tr_num][ff]\n",
    "    (thorax_x, thorax_y) = WRTant_to_WRTframe(df.thorax_x[tr_num][ff], df.thorax_y[tr_num][ff], x, y, ang)\n",
    "    (neck_x, neck_y) = WRTant_to_WRTframe(df.neck_x[tr_num][ff], df.neck_y[tr_num][ff], x, y, ang)\n",
    "#     print(x,y,ang)\n",
    "    \n",
    "    \n",
    "\n",
    "    # PLOT THINGS\n",
    "#     ax1=fig.add_axes([0.03,0.1, 0.2, 0.3])\n",
    "#     ax1.set_position([0.03,0.1, 0.2, 0.3])\n",
    "    plt.imshow(frame)\n",
    "#     plt.plot(x, y, '.w')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "    for jj in range(0,6):\n",
    "            plot_ant_pt('joint',jj,'_filt_fullfr', df, tr_num, fr_id, x, y, ang, buffer=0)\n",
    "    plot_ant_pt('thorax', '', '_filt_fullfr', df, tr_num, fr_id, x, y, ang, buffer=0)\n",
    "    plot_ant_pt('neck', '', '_filt_fullfr', df, tr_num, fr_id, x, y, ang, buffer=0)\n",
    "    plt.text(10,30, 'Fr: %i'%fr_OI, color = 'w')\n",
    "    titleparts = df.video[tr_num].split('/')\n",
    "    plt.suptitle( 'TRIAL %i:  %s -- %s -- %s'%(tr_num, titleparts[-2], \n",
    "                        titleparts[-1].split('_')[0], titleparts[-1].split('_')[1]),x=0.03, y=.95, horizontalalignment = 'left')\n",
    "#     plt.pause(0.1)\n",
    "    vlocation = '/media/gravishlab/SeagateExpansionDrive/AntTrack'\n",
    "    save_image(vlocation, im_n, 'LEAPtracking_filter_fullframe')\n",
    "save_video(vlocation, 'LEAPtracking_filter_fullframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Touchdown heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate height of feet for whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Videos:  32\n",
      "\n",
      "calculating step heights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:63: RuntimeWarning: invalid value encountered in less\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done analyzing step locations and heights!\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE STEP HEIGHTS FOR WHOLE DATAFRAME\n",
    "\n",
    "\n",
    "# load in all step height profiles into dataframe based on colony and substrate\n",
    "vid_locations = '/media/gravishlab/SeagateExpansionDrive/AntTrack/'\n",
    "sh_folder_list = []\n",
    "sh_folder_list = glob.glob(os.path.join(vid_locations, '**/*[0-9]mm/'))\n",
    "sh_folder_list = sorted(sh_folder_list)\n",
    "print('Total Number of Videos: ',len(sh_folder_list))\n",
    "step_height_data = []\n",
    "for folder in sh_folder_list:\n",
    "    file = ('/').join(folder.split('/')[:-1])+'/'+('_').join(folder.split('/')[-3:])+'Step_Height.pkl'\n",
    "    colony = folder.split('/')[-3]\n",
    "    substrate = folder.split('/')[-2]\n",
    "#     print(file)\n",
    "    temp = {}\n",
    "    with open(file, 'rb') as f:\n",
    "        temp['hlines'], temp['vlines'], temp['height_profile'],_ = pickle.load(f)\n",
    "    f.close()\n",
    "    temp['colony']=colony\n",
    "    temp['substrate']=substrate\n",
    "    step_height_data.append(temp)\n",
    "    \n",
    "step_height_df = pd.DataFrame(step_height_data).copy()\n",
    "# del step_height_data\n",
    "          \n",
    "    \n",
    "# def get_TD_location_df(x, part):\n",
    "#     all_x = x['%s_x_filt_fullfr'%part]\n",
    "#     all_y = x['%s_y_filt_fullfr'%part]\n",
    "#     TD_x = all_x[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "#     TD_y = all_y[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]]\n",
    "#     TD_x = TD_x\n",
    "#     TD_y = TD_y\n",
    "#     return TD_x, TD_y\n",
    "\n",
    "def get_TD_height_df(x, part, step_height_df):\n",
    "    all_x = x['%s_x_filt_fullfr'%part]\n",
    "    all_y = x['%s_y_filt_fullfr'%part]\n",
    "    TD_x = all_x[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    TD_y = all_y[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]]\n",
    "    TD_x = TD_x\n",
    "    TD_y = TD_y\n",
    "    n_pts = len(TD_x)\n",
    "    \n",
    "    col_OI = x['colony']\n",
    "    sub_OI = x['substrate']\n",
    "    step_heights = np.ones(TD_x.shape)\n",
    "    if sub_OI == '0mm': # all steps are on top for flat substrate\n",
    "        return TD_x, TD_y, step_heights\n",
    "    \n",
    "    step_height_OI = step_height_df[\n",
    "        step_height_df['substrate'].str.contains(sub_OI) & step_height_df['colony'].str.contains(col_OI)]\n",
    "    hlines = step_height_OI['hlines'].values[0]\n",
    "    n_hlines = len(hlines)\n",
    "    vlines = step_height_OI['vlines'].values[0]\n",
    "    n_vlines = len(vlines)\n",
    "    height_profile = step_height_OI['height_profile'].values[0]\n",
    "    \n",
    "    y_pred = np.repeat(TD_x[np.newaxis,:],n_hlines, axis =0)*np.repeat(hlines[:,1][:,np.newaxis],n_pts,axis=1)+ \\\n",
    "        np.repeat(hlines[:,0][:,np.newaxis],n_pts,axis=1)\n",
    "    y_idcs = np.sum(y_pred<TD_y,axis =0)-1\n",
    "    x_pred = np.repeat(TD_y[np.newaxis,:],n_vlines, axis =0)*1/(np.repeat(vlines[:,1][:,np.newaxis],n_pts,axis=1))- \\\n",
    "        np.repeat((vlines[:,0]/vlines[:,1])[:,np.newaxis],n_pts,axis=1)\n",
    "    x_idcs = np.sum(x_pred<TD_x,axis =0)-1\n",
    "    \n",
    "    off_substrate = np.logical_or(np.logical_or(x_idcs<0,x_idcs>=(n_vlines-1)), np.logical_or(y_idcs<0,y_idcs>=(n_hlines-1)))\n",
    "    on_substrate = np.logical_not(off_substrate)\n",
    "    step_heights[on_substrate]  = height_profile[y_idcs[on_substrate], x_idcs[on_substrate]]\n",
    "#     print(col_OI, sub_OI, TD_y, y_idcs)\n",
    "    return TD_x, TD_y, step_heights\n",
    "\n",
    "\n",
    "# compile data of TD locations and heights\n",
    "print('\\ncalculating step heights')\n",
    "for joint_num in range(0,6):\n",
    "#     df = df.drop(['joint%i_St_Heights'%joint_num], axis = 1)\n",
    "    df['joint%i_St_TD_x'%joint_num], df['joint%i_St_TD_y'%joint_num], df['joint%i_St_Heights'%joint_num] = zip(*\n",
    "                                                        df.apply(get_TD_height_df, args = ('joint%i'%joint_num, step_height_df), axis=1))\n",
    "\n",
    "    #     df = df.drop(['joint%i_TD_x'%joint_num, 'joint%i_TD_y'%joint_num], axis = 1)\n",
    "#     df['joint%i_St_TD_x'%joint_num], df['joint%i_St_TD_y'%joint_num] = zip(*df.apply(get_TD_location_df, args = ('joint%i'%joint_num,), axis=1))\n",
    "print('\\nDone analyzing step locations and heights!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out step height calculations for given trackway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try calculating joint height for a given trial to see what's going wrong\n",
    "part = 'joint0'\n",
    "tr = 10763\n",
    "all_x = df['%s_x_filt_fullfr'%part][tr]\n",
    "all_y = df['%s_y_filt_fullfr'%part][tr]\n",
    "TD_x = all_x[df['%s_TD_idcs'%part][tr][:-1][df['%s_good_strides'%part][tr]]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "TD_y = all_y[df['%s_TD_idcs'%part][tr][:-1][df['%s_good_strides'%part][tr]]]\n",
    "TD_x = TD_x\n",
    "TD_y = TD_y\n",
    "n_pts = len(TD_x)\n",
    "print(TD_x, TD_y)\n",
    "\n",
    "step_heights = np.ones(TD_x.shape)\n",
    "\n",
    "col_OI = df['colony'][tr]\n",
    "sub_OI = df['substrate'][tr]\n",
    "if sub_OI == '0mm': # all steps are on top for flat substrate\n",
    "    step_heights = np.ones(TD_x.shape)\n",
    "\n",
    "print(col_OI, sub_OI, df['datetime'][tr])\n",
    "\n",
    "step_height_OI = step_height_df[\n",
    "    step_height_df['substrate'].str.contains(sub_OI) & step_height_df['colony'].str.contains(col_OI)]\n",
    "hlines = step_height_OI['hlines'].values[0]\n",
    "n_hlines = len(hlines)\n",
    "vlines = step_height_OI['vlines'].values[0]\n",
    "n_vlines = len(vlines)\n",
    "height_profile = step_height_OI['height_profile'].values[0]\n",
    "\n",
    "y_pred = np.repeat(TD_x[np.newaxis,:],n_hlines, axis =0)*np.repeat(hlines[:,1][:,np.newaxis],n_pts,axis=1)+ \\\n",
    "    np.repeat(hlines[:,0][:,np.newaxis],n_pts,axis=1)\n",
    "y_idcs = np.sum(y_pred<TD_y,axis =0)-1\n",
    "\n",
    "x_pred = np.repeat(TD_y[np.newaxis,:],n_vlines, axis =0)*1/(np.repeat(vlines[:,1][:,np.newaxis],n_pts,axis=1))- \\\n",
    "    np.repeat((vlines[:,0]/vlines[:,1])[:,np.newaxis],n_pts,axis=1)\n",
    "x_idcs = np.sum(x_pred<TD_x,axis =0)-1\n",
    "off_substrate = np.logical_or(np.logical_or(x_idcs<0,x_idcs>=(n_vlines-1)), np.logical_or(y_idcs<0,y_idcs>=(n_hlines-1)))\n",
    "on_substrate = np.logical_not(off_substrate)\n",
    "print(x_idcs, y_idcs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(col_OI, sub_OI, y_idcs, TD_x)\n",
    "step_heights[on_substrate]  = height_profile[y_idcs[on_substrate], x_idcs[on_substrate]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate % of touchdowns that are on peak vs. valley for each substrate/colony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETERMINE % OF STEPS ON PEAKS VS. VALLEYS\n",
    "\n",
    "# Calculate stride heights\n",
    "df['St_Heights'] = df.filter(regex='_St_Heights$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "pix2mm = 959.7563/30\n",
    "fps = 240\n",
    "df['St_Len_all'] = df.filter(regex='_St_Len$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1) # in mm\n",
    "df['St_Dur_all'] = df.filter(regex='St_Dur$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/fps, axis = 1) # in sec\n",
    "df['St_tdist_total'] = df.filter(regex='_St_tdist_total$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_tdist_straight'] = df.filter(regex='_St_tdist_straight$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_rotation'] = df.filter(regex='_St_rotation$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_travel_dir'] = df.filter(regex='_St_travel_dir$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_jointID'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "df['St_TD_x'] = df.filter(regex='_St_TD_x$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_TD_y'] = df.filter(regex='_St_TD_y$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "lens = [len(item) for item in df['St_Heights']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values), \n",
    "                        \"St_Heights\" : np.concatenate(df['St_Heights'].values),\n",
    "                        \"St_TD_x\" : np.concatenate(df['St_TD_x'].values), \"St_TD_y\" : np.concatenate(df['St_TD_y'].values)})\n",
    "\n",
    "\n",
    "# # plot distribution of all analyzed TDS to make sure no weirdness\n",
    "# allsubs = [tr['substrate'] for tr in trial_info]\n",
    "# subtypes = sorted(list(set(allsubs)))\n",
    "# plt.close('all')\n",
    "# plt.figure(figsize=(17,3))\n",
    "# for ss,subtype in enumerate(subtypes[0:4]):\n",
    "#     plt.subplot(1,4,ss+1)\n",
    "#     xs = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_TD_x'].values\n",
    "#     ys = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_TD_y'].values\n",
    "#     plt.plot(xs,ys,'.k', alpha = 0.01, MarkerSize = 2)\n",
    "#     rect = Rectangle((0,0),1000,550, linewidth =1, edgecolor = 'k', facecolor = 'none')\n",
    "#     plt.gca().add_patch(rect)\n",
    "#     plt.title('%s'%subtype, horizontalalignment='left', loc = 'left')\n",
    "#     plt.axis('equal')\n",
    "#     plt.axis('off')\n",
    "\n",
    "\n",
    "# # plot distribution of all analyzed TDs for each colony to make sure no weirdness\n",
    "# allsubs = [tr['substrate'] for tr in trial_info]\n",
    "# subtypes = sorted(list(set(allsubs)))\n",
    "# coltypes = sorted(list(set(df['colony'].values)))\n",
    "# plt.close('all')\n",
    "# plt.figure(figsize=(12,12))\n",
    "# for cc,coltype in enumerate(coltypes[:-1]):\n",
    "#     for ss,subtype in enumerate(subtypes[0:4]):\n",
    "#         plt.subplot(7,4,ss+1+(cc*4))\n",
    "#         xs = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']==coltype)]['St_TD_x'].values\n",
    "#         ys = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']==coltype)]['St_TD_y'].values\n",
    "#         plt.plot(xs,ys,'.k', alpha = 0.015, MarkerSize = 2)\n",
    "#         rect = Rectangle((0,0),1000,550, linewidth =1, edgecolor = 'k', facecolor = 'none')\n",
    "#         plt.gca().add_patch(rect)\n",
    "#         plt.axis('equal')\n",
    "#         plt.axis('off')\n",
    "#         if cc==0:\n",
    "#             plt.title('%s'%subtype, horizontalalignment='left', loc = 'left')\n",
    "\n",
    "\n",
    "\n",
    "# how much of ground is peak vs. valley\n",
    "allsubs = [tr['substrate'] for tr in trial_info]\n",
    "subtypes = sorted(list(set(allsubs)))\n",
    "percent_of_substrate_peak = np.full(4,np.nan)\n",
    "percent_of_substrate_peak[0]=100\n",
    "for kk in range(1,4):\n",
    "    idx = subtypes.index(step_height_data[kk]['substrate'])\n",
    "    profile = step_height_data[kk]['height_profile']\n",
    "    box_size = (idx-1)*2+1\n",
    "    total_peak_area = np.sum(\n",
    "        profile*np.repeat(np.concatenate([np.full(profile.shape[0]-1, box_size),[1]])[:,np.newaxis], profile.shape[1],axis=1)*box_size)\n",
    "    total_area = 16*30\n",
    "    percent_of_substrate_peak[idx] = total_peak_area/total_area*100\n",
    "\n",
    "\n",
    "# what percentage of all recorded strides is on a peak for each substrate & colony\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "coltypes = sorted(list(set(df['colony'].values)))\n",
    "TD_height_data = np.full((4,6,3),np.nan)\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    print('\\nSUBSTRATE: %s, %0.2f percent of substrate is peaks'%(subtype, percent_of_substrate_peak[ss]))\n",
    "    for cc,coltype in enumerate(coltypes[:-2]):\n",
    "        xvals = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']==coltype)]['St_Heights'].values\n",
    "        TD_height_data[ss,cc,:]=[np.sum(xvals), len(xvals)-np.sum(np.sum(xvals)), len(xvals)]\n",
    "        print('  %s: n = %i --- %0.2f percent on peaks'%(coltype, len(xvals), np.sum(xvals)/len(xvals)*100))\n",
    "plt.figure()\n",
    "percent_TD_peaks = TD_height_data[:,:,0]/TD_height_data[:,:,2]*100\n",
    "yerrs = np.abs([np.min(percent_TD_peaks,axis=1), np.max(percent_TD_peaks,axis=1)]-np.mean(percent_TD_peaks, axis=1))\n",
    "plt.bar(np.arange(4), np.mean(percent_TD_peaks, axis =1), width=1, yerr = yerrs, color = pltcolors)\n",
    "plt.plot(np.vstack([np.arange(0,4)-.5, np.arange(0,4)+0.5]), np.repeat(percent_of_substrate_peak[:,np.newaxis],2, axis =1).T, ':k')\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([-0.5,3.5])\n",
    "plt.xticks(np.arange(4),['0','1','3','5'])\n",
    "plt.title('% of TDs that are on peaks', loc= 'left')\n",
    "plt.xlabel('substrate size (mm)')\n",
    "\n",
    "# is there a preference for a given foot to be on peak vs. valley\n",
    "print('\\n')\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    print('\\nSUBSTRATE: %s, %0.2f percent of substrate is peaks'%(subtype, percent_of_substrate_peak[ss]))\n",
    "    xvals = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony'] != coltypes[-1])]['St_Heights'].values\n",
    "    print('SUB TOTAL n TDs: %i'%len(xvals))\n",
    "    print('p-value: ', stats.ttest_1samp(percent_TD_peaks[ss,:], percent_of_substrate_peak[ss])[1]) # two-sided t-test for each substrate\n",
    "     \n",
    "    for jj in range(0,6):\n",
    "        xvals = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['Joints_all']!='joint%s'%jj)]['St_Heights'].values\n",
    "        print('  %s: n = %i --- %0.2f percent on peaks'%('Joint%i'%jj, len(xvals), np.sum(xvals)/len(xvals)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOK AT PROPORTION OF STRIDES WITH ANT ON UNEVEN GROUND VS. LEVEL FOOTSTEPS\n",
    "\n",
    "\n",
    "# ######### CALCULATE UNEVENESS OF CONCURRENT STEPS\n",
    "# df['St_jointnum'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "#     lambda x: np.concatenate([x]), axis = 1).map(\n",
    "#     lambda x: np.repeat([0,1,2,3,4,5], x))\n",
    "\n",
    "\n",
    "# def find_concurrent_eveness_df(x, cutoff = 5):\n",
    "#     TD_idcs = np.concatenate(x.filter(regex='_TD_idcs$').map(lambda x: x[:-1]).tolist())\n",
    "#     good_strides = np.concatenate(x.filter(regex='_good_strides$').tolist())\n",
    "    \n",
    "#     St_idcs_unsorted = TD_idcs[good_strides]\n",
    "#     sort_idcs = np.argsort(St_idcs_unsorted)\n",
    "#     St_idcs = St_idcs_unsorted[sort_idcs]\n",
    "#     St_jointnum = x['St_jointnum'][sort_idcs]\n",
    "#     St_heights = np.concatenate(x.filter(regex='_St_Heights$').tolist())[sort_idcs]\n",
    "    \n",
    "#     where_split = np.where( np.insert(np.diff(St_idcs)>cutoff,0,False))[0]\n",
    "#     clumped_heights =np.split(St_heights, where_split)\n",
    "#     n_concurrent_feet = np.array([np.sum(c) for c in clumped_heights])\n",
    "#     frac_peak = np.array([np.sum(c)/len(c) for c in clumped_heights])\n",
    "#     n_3even =np.sum(np.logical_and(n_concurrent_feet>2, frac_peak%1==0))\n",
    "#     n_3uneven = np.sum(np.logical_and(n_concurrent_feet>2, frac_peak%1>0))\n",
    "#     n_2even = np.sum(np.logical_and(n_concurrent_feet==2, frac_peak%1==0))\n",
    "#     n_2uneven = np.sum(np.logical_and(n_concurrent_feet==2, frac_peak%1>0))\n",
    "#     n_strides = len(clumped_heights)\n",
    "#     return np.array([n_3even, n_3uneven, n_2even, n_2uneven, n_strides])\n",
    "\n",
    "\n",
    "# concurrent_cutoff = 5 #how many frames to determine if stances are concurrent\n",
    "# df['St_concurrent_eveness'] = df.apply(find_concurrent_eveness_df, args = (concurrent_cutoff,), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### ANALYZE\n",
    "plt.close('all')\n",
    "uneveness_data = np.full((4,7,5),np.nan)\n",
    "for ss,subtype in enumerate(subtypes[0:4]):\n",
    "    print('\\n%s'%subtype)\n",
    "    for cc,coltype in enumerate(coltypes[:-1]):\n",
    "        xs = np.vstack(df.loc[(df['substrate']==subtype) & (df['colony']==coltype)]['St_concurrent_eveness'].values)\n",
    "        print(np.sum(xs, axis =0))\n",
    "        uneveness_data[ss,cc,:]=np.sum(xs, axis =0)\n",
    "    print('sums: ', np.sum(uneveness_data[ss,:,:], axis =1))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "\n",
    "# % concurrent strides identified\n",
    "plt.subplot(1,3,1)\n",
    "n_concurrent_strides  = np.sum(uneveness_data[:,:,:-1],axis=2)\n",
    "percent_concurrent_strides = n_concurrent_strides/uneveness_data[:,:,-1]*100\n",
    "percent_tripod_strides = np.sum(uneveness_data[:,:,0:2],axis=2)/uneveness_data[:,:,-1]*100\n",
    "percent_duo_strides = np.sum(uneveness_data[:,:,2:4],axis=2)/uneveness_data[:,:,-1]*100\n",
    "\n",
    "yerrs = np.abs([np.min(percent_concurrent_strides,axis=1), np.max(percent_concurrent_strides,axis=1)]\n",
    "               -np.mean(percent_concurrent_strides, axis=1))\n",
    "plt.bar(np.arange(4), np.mean(percent_concurrent_strides, axis =1), width=1, yerr = yerrs, color = pltcolors, alpha = 0.4)\n",
    "yerrs = np.abs([np.min(percent_tripod_strides,axis=1), np.max(percent_tripod_strides,axis=1)]\n",
    "               -np.mean(percent_tripod_strides, axis=1))\n",
    "plt.bar(np.arange(4), np.mean(percent_tripod_strides, axis =1),\n",
    "        width=1, yerr = yerrs, color = pltcolors)\n",
    "plt.text(2, 95, 'total n strides:', color = 'k')\n",
    "for ss in range(0,4):\n",
    "    plt.text(2, 90-ss*5, '%i'%np.sum(uneveness_data[:,:,-1], axis = 1)[ss], color=pltcolors[ss])\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([-0.5,3.5])\n",
    "plt.xticks(np.arange(4),['0','1','3','5'])\n",
    "plt.title('% of identified strides concurrent', loc= 'left')\n",
    "\n",
    "# % of identified tripods that are even\n",
    "plt.subplot(1,3,2)\n",
    "percent_even_tripods = uneveness_data[:,:,0]/np.sum(uneveness_data[:,:,0:2],axis=2)*100\n",
    "yerrs = np.abs([np.min(percent_even_tripods,axis=1), np.max(percent_even_tripods,axis=1)]\n",
    "               -np.mean(percent_even_tripods, axis=1))\n",
    "plt.bar(np.arange(4), np.mean(percent_even_tripods, axis =1), width=1, yerr = yerrs, color = pltcolors)\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([-0.5,3.5])\n",
    "plt.xticks(np.arange(4),['0','1','3','5'])\n",
    "plt.title('% of identified tripods that are even', loc= 'left')\n",
    "plt.xlabel('substrate size (mm)')\n",
    "\n",
    "# % of identified duos that are even\n",
    "plt.subplot(1,3,3)\n",
    "percent_even_duos = uneveness_data[:,:,2]/np.sum(uneveness_data[:,:,2:4],axis=2)*100\n",
    "yerrs = np.abs([np.min(percent_even_duos,axis=1), np.max(percent_even_duos,axis=1)]\n",
    "               -np.mean(percent_even_duos, axis=1))\n",
    "plt.bar(np.arange(4), np.mean(percent_even_duos, axis =1), width=1, yerr = yerrs, color = pltcolors, alpha = 0.4)\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([-0.5,3.5])\n",
    "plt.xticks(np.arange(4),['0','1','3','5'])\n",
    "plt.title('% of identified duos that are even', loc= 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at transitions in step height during sequential strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sequential_strides_df(x, joint_num, parameter): #'rotation', 'Len', 'Dur', 'travel_dir'\n",
    "    arr = x['joint%s_St_%s'%(joint_num, parameter)]\n",
    "    good_st = x['joint%s_good_strides'%joint_num]\n",
    "    idcs = range(len(good_st))\n",
    "    st_idcs = np.cumsum(good_st)-1\n",
    "    st_len_groups  = [arr[st_idcs[np.array(list(g))]] for k,g in groupby(iter(idcs), lambda x: good_st[x]) if k == True]\n",
    "    arr_0 = [g[:-1] for g in st_len_groups if len(g)>1]\n",
    "    arr_1 = [g[1:] for g in st_len_groups if len(g)>1]\n",
    "    if len(arr_0)>0:\n",
    "        arr_0 = np.concatenate(arr_0)\n",
    "        arr_1 = np.concatenate(arr_1)\n",
    "    return arr_0, arr_1\n",
    "\n",
    "for parameter  in ['Len', 'Dur', 'tdist_total', 'travel_dir', 'rotation', 'Heights']:\n",
    "    print(parameter)\n",
    "    if 'SeqSt0_%s'%(parameter) in df.columns:\n",
    "        df = df.drop(['SeqSt0_%s'%(parameter), 'SeqSt1_%s'%(parameter)], axis =1)\n",
    "    # for each joint, find the 1st (0) and 2nd (1) parameter values for sequential strides\n",
    "    for joint_num in range(0,6):\n",
    "        df['joint%s_SeqSt0_%s'%(joint_num, parameter)], df['joint%s_SeqSt1_%s'%(joint_num, parameter)]= \\\n",
    "            zip(*df.apply(find_sequential_strides_df, args = (joint_num, parameter), axis=1))\n",
    "    # combine all joints\n",
    "    df['SeqSt0_%s'%parameter] = df.filter(regex='_SeqSt0_%s$'%parameter, axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "    df['SeqSt1_%s'%parameter] = df.filter(regex='_SeqSt1_%s$'%parameter, axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "\n",
    "# find joints used for each sequential stride pair\n",
    "df['SeqSt_Joints'] = df.filter(regex='_SeqSt0_Len$', axis=1).applymap(lambda x: len(x)).apply(lambda x: np.concatenate([x]), axis = 1).map(lambda x: np.repeat([0,1,2,3,4,5], x))\n",
    "    \n",
    "# remove colulmns for individual joint sequential stride info\n",
    "for parameter  in ['Len', 'Dur', 'tdist_total', 'travel_dir', 'rotation', 'Heights']:\n",
    "    for joint_num in range(0,6):\n",
    "        df = df.drop(['joint%s_SeqSt0_%s'%(joint_num, parameter), 'joint%s_SeqSt1_%s'%(joint_num, parameter)], axis =1)\n",
    "    \n",
    "    \n",
    "    \n",
    "# new df with just sequential stride info of interest\n",
    "lens = [len(item) for item in df['SeqSt0_travel_dir']]\n",
    "seq_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['SeqSt_Joints'].values),\n",
    "                        \"Len_0\" : np.concatenate(df['SeqSt0_Len'].values/pix2mm), \"Len_1\" : np.concatenate(df['SeqSt1_Len'].values/pix2mm),\n",
    "                        \"Dur_0\" : np.concatenate(df['SeqSt0_Dur'].values/fps), \"Dur_1\" : np.concatenate(df['SeqSt1_Dur'].values/fps),\n",
    "                        \"travel_dist_0\" : np.concatenate(df['SeqSt0_tdist_total'].values/pix2mm), \n",
    "                        \"travel_dist_1\" : np.concatenate(df['SeqSt1_tdist_total'].values/pix2mm),\n",
    "                        \"speed_0\" : np.concatenate(df['SeqSt0_tdist_total'].values/pix2mm)/np.concatenate(df['SeqSt0_Dur'].values/fps), \n",
    "                        \"speed_1\" : np.concatenate(df['SeqSt1_tdist_total'].values/pix2mm)/np.concatenate(df['SeqSt1_Dur'].values/fps),\n",
    "                        \"travel_dir_0\" : np.concatenate(df['SeqSt0_travel_dir'].values), \"travel_dir_1\" : np.concatenate(df['SeqSt1_travel_dir'].values),\n",
    "                        \"rotation_0\" : np.concatenate(df['SeqSt0_rotation'].values), \"rotation_1\" : np.concatenate(df['SeqSt1_rotation'].values),\n",
    "                        \"height_0\" : np.concatenate(df['SeqSt0_Heights'].values), \"height_1\" : np.concatenate(df['SeqSt1_Heights'].values)    })\n",
    "\n",
    "print('\\ndone analyzing')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # plot step transition type vased on travel distance of previous and current strides\n",
    "# # percent of same level sequential strides that are peaks vs. valleys\n",
    "# # plt.close('all')\n",
    "# plt.figure(figsize=(15,4))\n",
    "# clrs = np.array([[0,0,1],[0,0,0],[1,0,0]])\n",
    "# for ss,subtype in enumerate(subtypes[0:4]):\n",
    "#     print('\\n%s'%subtype)\n",
    "#     plt.subplot(1,4,ss+1)\n",
    "#     seq_strides_OI = seq_strides.loc[(seq_strides['substrate']==subtype) & (seq_strides['colony']!=coltypes[-1])]\n",
    "#     xs = seq_strides_OI['travel_dist_0'].values\n",
    "#     ys = seq_strides_OI['travel_dist_1'].values\n",
    "    \n",
    "#     step_type = (seq_strides_OI['height_1'].values-seq_strides_OI['height_0'].values+1).astype(np.uint8)\n",
    "#     colors = clrs[step_type]\n",
    "    \n",
    "#     # plot all points at once\n",
    "# #     plt.scatter(xs,ys, s=2, c =colors, alpha = 0.01)\n",
    "        \n",
    "#     # plot each step type one at a time\n",
    "#     for st_OI in [1]:#range(0,3):\n",
    "#         plt.scatter(xs[step_type==st_OI],ys[step_type==st_OI], s=2, c =clrs[st_OI], alpha = 0.01)\n",
    "    \n",
    "#     plt.xlim(0,5)\n",
    "#     plt.ylim(0,5)\n",
    "    \n",
    "#     print('-- same level: %i'%np.sum(step_type==1))\n",
    "#     print('---- valley: %i'%np.sum(np.logical_and(step_type==1, seq_strides_OI['height_0'].values==0)))\n",
    "#     print('---- peak: %i'%np.sum(np.logical_and(step_type==1, seq_strides_OI['height_0'].values==1)))\n",
    "#     print('-- step down: %i'%np.sum(step_type==0))\n",
    "#     print('-- step up: %i'%np.sum(step_type==2))\n",
    "    \n",
    "    \n",
    "# PLOT % OF SAME LEVEL SEQUENTIAL STEPS ON PEAKS VS. VALLEYS\n",
    "sequential_data = np.full( (4,7,3),np.nan)\n",
    "for ss,subtype in enumerate(subtypes[0:4]):\n",
    "    print('\\n%s'%subtype)\n",
    "    for cc,coltype in enumerate(coltypes[:-1]):\n",
    "        seq_strides_OI = seq_strides.loc[(seq_strides['substrate']==subtype) & (seq_strides['colony']==coltype)]\n",
    "        step_type = (seq_strides_OI['height_1'].values-seq_strides_OI['height_0'].values+1).astype(np.uint8)\n",
    "        sequential_data[ss,cc,-1] = len(step_type)\n",
    "        sequential_data[ss,cc,0] = np.sum(np.logical_and(step_type==1,seq_strides_OI['height_0'].values==0) )\n",
    "        sequential_data[ss,cc,1] = np.sum(np.logical_and(step_type==1,seq_strides_OI['height_0'].values==1) )\n",
    "        \n",
    "plt.close('all')\n",
    "plt.figure(figsize=(7,5))\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "percent_samelevel_peaks = sequential_data[:,:,1]/(np.sum(sequential_data[:,:,0:2],axis=2))*100\n",
    "means = np.mean(percent_samelevel_peaks,axis = 1)\n",
    "# yerrs = np.std(percent_samelevel_peaks,axis = 1)\n",
    "yerrs = np.abs([np.min(percent_samelevel_peaks,axis=1), np.max(percent_samelevel_peaks,axis=1)]\n",
    "               -means)\n",
    "# plt.bar(np.arange(4), np.mean(percent_concurrent_strides, axis =1), width=1, yerr = yerrs, color = pltcolors, alpha = 0.4)\n",
    "# yerrs = np.abs([np.min(percent_tripod_strides,axis=1), np.max(percent_tripod_strides,axis=1)]\n",
    "#                -np.mean(percent_tripod_strides, axis=1))\n",
    "plt.bar(np.arange(4), means,width=1, yerr = yerrs, color = pltcolors)\n",
    "# plt.text(2, 95, 'total n strides:', color = 'k')\n",
    "for ss in range(0,4):\n",
    "    plt.text(ss, 90, 'n: %i'%np.sum(np.sum(sequential_data[:,:,0:2],axis=2),axis =1)[ss], horizontalalignment='center')\n",
    "plt.ylim([0,100])\n",
    "plt.xlim([-0.5,3.5])\n",
    "plt.xticks(np.arange(4),['0','1','3','5'])\n",
    "plt.title('% peak to peak vs. valley to valley sequential strides', loc= 'left', FontSize = 10)\n",
    "plt.ylabel('% of strides that are peak to peak')\n",
    "plt.xlabel('substrate box size (mm)')\n",
    "\n",
    "for ss in range(1,4):\n",
    "    print('p-value: ', stats.ttest_1samp(percent_samelevel_peaks[ss,:], 50)) # two-sided t-test for each substrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point clouds of leg positions WRT ant on diff substrates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 vs. 1 p-value:  1.922176162363998e-07\n",
      "0 vs. 2 p-value:  1.129346043889994e-09\n",
      "0 vs. 3 p-value:  4.972621229642762e-08\n",
      "1 vs. 2 p-value:  0.033132177957727306\n",
      "1 vs. 3 p-value:  0.0037536989395684215\n",
      "2 vs. 3 p-value:  3.646206995063139e-07\n"
     ]
    }
   ],
   "source": [
    "# Point cloud of TDs based on whether it's a straight/turning stride - convex hull + PCA\n",
    "\n",
    "def get_TD_location_df(x, part):\n",
    "    all_x = x['%s_x_filt_WRTneck'%part]\n",
    "    all_y = x['%s_y_filt_WRTneck'%part]\n",
    "    TD_x = all_x[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    TD_y = all_y[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]]\n",
    "    TD_x = TD_x\n",
    "    TD_y = TD_y\n",
    "    return TD_x, TD_y\n",
    "\n",
    "def plot_convex_hull(points, pltcolors, joint_num):\n",
    "    hull = ConvexHull(points)\n",
    "    cent =np.mean(points, 0)\n",
    "    pts = []\n",
    "    for pt in points[hull.simplices]:\n",
    "        pts.append(pt[0].tolist())\n",
    "        pts.append(pt[1].tolist())\n",
    "    pts.sort(key=lambda p: np.arctan2(p[1]-cent[1], p[0] - cent[0]))\n",
    "    pts = pts[0::2]\n",
    "    pts.insert(len(pts), pts[0])\n",
    "    k= 1.0\n",
    "    poly = Polygon(k*(np.array(pts)-cent) + cent, closed = True, facecolor = pltcolors[joint_num], alpha = 0.05)\n",
    "    poly.set_capstyle('round')\n",
    "    plt.gca().add_patch(poly)\n",
    "    plt.plot(cent[0],cent[1],'.', color = pltcolors[joint_num])\n",
    "    return \n",
    "\n",
    "def plt_pca_ellipse(points, pltcolors, joint_num, trial_type):\n",
    "    \n",
    "    cent =np.mean(points, axis = 0)\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit_transform(points)\n",
    "    projected = pca.transform(points)\n",
    "    a = np.linalg.norm(pca.inverse_transform([np.std(projected, axis =0)[0],0])-cent)\n",
    "    b = np.linalg.norm(pca.inverse_transform([np.std(projected, axis =0)[1],0])-cent)\n",
    "    new_unit =pca.inverse_transform([1,0])-cent\n",
    "    el_angle = np.rad2deg(np.arctan2(new_unit[1], new_unit[0]))\n",
    "    \n",
    "    if trial_type == 'straight':\n",
    "        lstyle = '-'\n",
    "        xoffset = 0\n",
    "    else:\n",
    "        lstyle = '--'\n",
    "        xoffset = 100\n",
    "    el = Ellipse(cent, 2*a, 2*b, angle = el_angle, ec = pltcolors[joint_num], fc = 'None', LineStyle = lstyle)\n",
    "    plt.gca().add_patch(el)\n",
    "    el = Ellipse(cent, 2*1.96*a, 2*1.96*b, angle = el_angle, ec = pltcolors[joint_num], fc = 'None', LineStyle = lstyle)\n",
    "    plt.gca().add_patch(el)\n",
    "    plt.text(-100 + xoffset, -115 + 10*joint_num, '%i'%len(points), color = pltcolors[joint_num])\n",
    "    SD = np.sqrt(a*b) # radius of circle with same area as ellipse\n",
    "    plt.text(-60 + xoffset, -115 + 10*joint_num, '%0.1f'%SD, color = pltcolors[joint_num])\n",
    "    return SD\n",
    "\n",
    "# combine all values from all joints into one column of dataframe\n",
    "for joint_num in range(0,6):\n",
    "    #     df = df.drop(['joint%i_TD_x'%joint_num, 'joint%i_TD_y'%joint_num], axis = 1)\n",
    "    df['joint%i_St_TD_x_WRTant'%joint_num], df['joint%i_St_TD_y_WRTant'%joint_num] = zip(*df.apply(get_TD_location_df, args = ('joint%i'%joint_num,), axis=1))\n",
    "df['St_Len_all'] = df.filter(regex='_St_Len$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1) # in mm\n",
    "df['St_Dur_all'] = df.filter(regex='St_Dur$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/fps, axis = 1) # in sec\n",
    "df['St_tdist_total'] = df.filter(regex='_St_tdist_total$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_tdist_straight'] = df.filter(regex='_St_tdist_straight$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_rotation'] = df.filter(regex='_St_rotation$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_travel_dir'] = df.filter(regex='_St_travel_dir$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_TD_x_WRTant'] = df.filter(regex='_St_TD_x_WRTant$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_TD_y_WRTant'] = df.filter(regex='_St_TD_y_WRTant$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_Heights'] = df.filter(regex='_St_Heights$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_jointID'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "    \n",
    "# make a dataframe where each row is its own stride\n",
    "lens = [len(item) for item in df['St_Len_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values), \n",
    "                        \"St_heights\" : np.concatenate(df['St_Heights'].values),\n",
    "                        \"St_TD_x_WRTant\" : np.concatenate(df['St_TD_x_WRTant'].values), \"St_TD_y_WRTant\" : np.concatenate(df['St_TD_y_WRTant'].values) })\n",
    "        \n",
    "plt.close('all')\n",
    "subtypes = sorted(list(set(df['substrate'].values)))\n",
    "plt.figure(figsize = (18,6))\n",
    "\n",
    "\n",
    "\n",
    "stddev = np.empty((2,4,6))\n",
    "flat_XY = np.empty((2,6))\n",
    "footX = np.empty((2,4,6))\n",
    "footY = np.empty((2,4,6))\n",
    "for ss,subtype in enumerate(subtypes[0:4]): \n",
    "    sub_TD = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!='Tunnel_20180329-30')]\n",
    "    \n",
    "    plt.subplot(1,4,ss+1)\n",
    "    plt.title('%s'%subtype, loc = 'left')\n",
    "    plt.plot(0,0,'+k')\n",
    "    plt.text(-100, -125, 'n:', color = 'k')\n",
    "    plt.text(-60, -125, 'SD:', color = 'k')\n",
    "    plt.axis('off')\n",
    "\n",
    "    if ss == 3:\n",
    "        plt.plot([-50, -50+2*pix2mm],[0,0], '-k')\n",
    "        plt.plot([0,0],[-50, -50+2*pix2mm], '-k')\n",
    "        plt.text(-50+1*pix2mm+5, 5, '2 mm', horizontalalignment = 'center', color = 'k')\n",
    "    \n",
    "    # PLOT STRAIGHT STRIDES\n",
    "    sub_TD_OI = sub_TD.loc[np.abs(sub_TD['St_travel_dir']) < 15]\n",
    "    pltcolors = ['xkcd:aqua', 'xkcd:azure', 'xkcd:crimson', 'xkcd:fuchsia', 'xkcd:goldenrod', 'xkcd:green']\n",
    "    \n",
    "    for joint_num in range(0,6):\n",
    "        # PLOT CONVEX HULL\n",
    "        joint_df = sub_TD_OI.loc[sub_TD_OI['Joints_all'] == 'joint%i'%joint_num]\n",
    "        points = np.array([joint_df['St_TD_x_WRTant'].values, joint_df['St_TD_y_WRTant'].values]).T\n",
    "        plot_convex_hull(points, pltcolors, joint_num)\n",
    "        # PLOT PCA ELIPSE\n",
    "        stddev[0, ss, joint_num] = plt_pca_ellipse(points, pltcolors, joint_num, 'straight')\n",
    "        # SAVE OR PLOT \"NORMAL\" POINT ON FLAT GROUND\n",
    "        if subtype == '0mm':\n",
    "                flat_XY[:,joint_num] = np.mean(points, axis = 0)\n",
    "        else:\n",
    "            plt.plot(flat_XY[0],flat_XY[1],'.k', alpha=1)\n",
    "            footX[0, ss, joint_num] =np.mean(points, axis = 0)[0]\n",
    "            footY[0, ss, joint_num] =np.mean(points, axis = 0)[1]\n",
    "        del joint_df\n",
    "    del sub_TD_OI\n",
    "        \n",
    "        \n",
    "#     # PLOT UNICYCLE STRIDES\n",
    "#     sub_TD_OI = sub_TD.loc[(np.abs(sub_TD['St_travel_dir']) > 15) & ( np.abs(sub_TD['St_rotation']-sub_TD['St_travel_dir']) < 15) ]\n",
    "#     pltcolors = ['c', 'b', 'r', 'm', 'y', 'g']\n",
    "#     for joint_num in range(0,6):\n",
    "#         # PLOT CONVEX HULL\n",
    "#         joint_df = sub_TD_OI.loc[(np.isin(sub_TD_OI['Joints_all'], ['joint%i'%(joint_num%3), 'joint%i'%(joint_num%3 + 3)])) & # it's a hind, mid, or fore limb\n",
    "#                                 (sub_TD_OI['Joints_all'].map( # same side or opp side of turn\n",
    "#                                     lambda x: np.sign(int(x[-1])//3*2-1)) == np.sign(sub_TD_OI['St_travel_dir'])*(joint_num//3*-2+1) )] \n",
    "#         points = np.array([joint_df['St_TD_x'].values, joint_df['St_TD_y'].values*-1*np.sign(joint_df['St_travel_dir'].values)]).T\n",
    "#         plot_convex_hull(points, pltcolors, joint_num)\n",
    "#         # PLOT PCA ELIPSE\n",
    "#         plt_pca_ellipse(points, pltcolors, joint_num, 'turns')\n",
    "#         del joint_df\n",
    "        \n",
    "\n",
    "    \n",
    "#     # PLOT PEAK AND VALLEY TDs SEPARATELY\n",
    "#     pltcolors = ['xkcd:goldenrod','xkcd:crimson', 'xkcd:fuchsia',  'xkcd:green', 'xkcd:azure', 'xkcd:aqua']\n",
    "#     trial_types = ['valleys','straight']\n",
    "#     for step_height in [1,0]:\n",
    "#         sub_TD_OI = sub_TD.loc[(np.abs(sub_TD['St_travel_dir']) < 15) & (sub_TD['St_heights']==step_height)]\n",
    "#         if len(sub_TD_OI)==0:\n",
    "#             continue\n",
    "\n",
    "#         for joint_num in range(0,6):\n",
    "#             # PLOT CONVEX HULL\n",
    "#             joint_df = sub_TD_OI.loc[sub_TD_OI['Joints_all'] == 'joint%i'%joint_num]\n",
    "#             points = np.array([joint_df['St_TD_x_WRTant'].values, joint_df['St_TD_y_WRTant'].values]).T\n",
    "#             plot_convex_hull(points, pltcolors, joint_num)\n",
    "#             # PLOT PCA ELIPSE\n",
    "#             if (step_height == 1) & (ss==0):\n",
    "#                 flat_XY[:,joint_num] = np.mean(points, axis = 0)\n",
    "#             else:\n",
    "#                 plt.plot(flat_XY[0],flat_XY[1],'.k', alpha=0.05)\n",
    "#             stddev[step_height, ss, joint_num] = plt_pca_ellipse(points, pltcolors, joint_num, trial_types[step_height])\n",
    "#             footX[step_height, ss, joint_num] =np.mean(points, axis = 0)[0]\n",
    "#             footY[step_height, ss, joint_num] =np.mean(points, axis = 0)[1]\n",
    "#             del joint_df\n",
    "#         del sub_TD_OI\n",
    "        \n",
    "    plt.axis('equal')\n",
    "    plt.xlim((-100,75))\n",
    "    plt.ylim((-110,100))\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "        \n",
    "    # PLOT SIDESTEP STRIDES\n",
    "#     sub_TD_OI = sub_TD.loc[(np.abs(sub_TD['St_travel_dir']) > 15) & ( np.abs(sub_TD['St_travel_dir'])-np.abs(sub_TD['St_rotation']) > 15) &\n",
    "#                          ( np.sign(sub_TD['St_rotation']-15) == np.sign(sub_TD['St_travel_dir']) ) ]\n",
    "\n",
    "\n",
    "# bar plot of standard deviations\n",
    "plt.figure()\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "jjs = [0,3,1,4,2,5]\n",
    "for step_height in [0]:# range(0,2): # if both peak and valley\n",
    "    for jj in np.arange(0,6):\n",
    "        joint_num = jjs[jj]\n",
    "#         print(joint_num)\n",
    "        xs = (step_height*4) + np.arange(0,4) + jj*0.1\n",
    "        ys = stddev[step_height, :,joint_num]/pix2mm\n",
    "        plt.bar(xs,ys, color = pltcolors, width = 0.1, alpha = 0.3, align = 'edge')\n",
    "    plt.bar((step_height*4)+np.linspace(0,3,4),np.mean(stddev[step_height,:,:],axis = 1)/pix2mm, \n",
    "            yerr = np.std(stddev[step_height,:,:]/pix2mm, axis =1 ), edgecolor = pltcolors, align = 'edge',\n",
    "           width = 0.6, alpha = 0.4, facecolor= 'none')\n",
    "plt.ylim((0,0.3))\n",
    "\n",
    "# # find p-values for comparisons amongst substrates\n",
    "for ss in range(0,3):\n",
    "    for ss2 in range(ss+1,4):\n",
    "        print('%i vs. %i p-value: '%(ss,ss2), stats.f_oneway(stddev[0,ss,:],stddev[0,ss2,:])[1])\n",
    "#     print('p-value: ', stats.ttest_ind(stddev[0,ss,:],stddev[1,ss,:])[1]) # give same result as above\n",
    "    \n",
    "# # find p-values for if variance is diff on peaks vs. valleys\n",
    "# for ss in range(1,4):\n",
    "#     print('p-value: ', stats.f_oneway(stddev[0,ss,:],stddev[1,ss,:])[1])\n",
    "# #     print('p-value: ', stats.ttest_ind(stddev[0,ss,:],stddev[1,ss,:])[1]) # give same result as above\n",
    "    \n",
    "del sub_TD, all_strides\n",
    "with open('%sAnt_Straight_Foot_Placement.pkl'%vid_locations, 'wb') as f:\n",
    "    pickle.dump([footX, footY], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plots of average foot placement shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.04184733 -0.02367528 -0.00821908]\n",
      "3 [ 0.03401038 -0.02273975 -0.031048  ]\n",
      "1 [0.13012102 0.04032828 0.02972958]\n",
      "4 [0.13177092 0.04378043 0.02719511]\n",
      "2 [ 0.01198763 -0.03550424 -0.00862545]\n",
      "5 [ 0.0118878  -0.02710736 -0.01349742]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'lateral <--> medial')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bar plot of ave foot placement shift\n",
    "pltcolors = ['#BA4246', '#087E8B', '#701C6F']\n",
    "jjs = [0,3,1,4,2,5]\n",
    "\n",
    "# anterior-posterior\n",
    "plt.figure()\n",
    "for step_height in [0]:# range(0,2): # if both peak and valley\n",
    "    for jj in np.arange(0,6):\n",
    "        joint_num = jjs[jj]\n",
    "#         print(joint_num)\n",
    "        xs = (step_height*3) + np.arange(0,3) + jj*0.1\n",
    "        ys = (footX[0,1:,joint_num] - flat_XY[0,joint_num])/pix2mm \n",
    "        plt.bar(xs,ys, color = pltcolors, width = 0.1, alpha = 0.3, align = 'edge')\n",
    "\n",
    "plt.ylim((-0.15,0.15))\n",
    "plt.ylabel('posterior <--> anterior')\n",
    "\n",
    "# medial-lateral\n",
    "plt.figure()\n",
    "for step_height in [0]:# range(0,2): # if both peak and valley\n",
    "    for jj in np.arange(0,6):\n",
    "        joint_num = jjs[jj]\n",
    "#         print(joint_num)\n",
    "        xs = (step_height*3) + np.arange(0,3) + jj*0.1\n",
    "        ys = (footY[0,1:,joint_num] - flat_XY[1,joint_num])/pix2mm * (joint_num//3*2-1)*-1 # flip so that medial shifts are positive\n",
    "        plt.bar(xs,ys, color = pltcolors, width = 0.1, alpha = 0.3, align = 'edge')\n",
    "plt.ylim((-0.15,0.15))\n",
    "plt.ylabel('lateral <--> medial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point cloud of just TDs - imshow + transparent cmap - SHANNON ENTROPY CALC\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "def get_TD_location_df(x, part):\n",
    "    all_x = x['%s_x_filt_WRTneck'%part]\n",
    "    all_y = x['%s_y_filt_WRTneck'%part]\n",
    "    TD_x = all_x[x['%s_TD_idcs'%part][x['%s_good_TDs'%part]]]\n",
    "    TD_y = all_y[x['%s_TD_idcs'%part][x['%s_good_TDs'%part]]]\n",
    "    TD_x = TD_x[np.isfinite(TD_x)]\n",
    "    TD_y = TD_y[np.isfinite(TD_y)]\n",
    "    return TD_x, TD_y\n",
    "    \n",
    "allsubs = [tr['substrate'] for tr in trial_info]\n",
    "subtypes = sorted(list(set(allsubs)))\n",
    "allcols = [tr['colony'] for tr in trial_info]\n",
    "coltypes = sorted(list(set(allcols)))\n",
    "plt.close('all') \n",
    "for joint_num in range(0,6):\n",
    "    #     df = df.drop(['joint%i_TD_x'%joint_num, 'joint%i_TD_y'%joint_num], axis = 1)\n",
    "    df['joint%i_TD_x'%joint_num], df['joint%i_TD_y'%joint_num] = zip(*df.apply(get_TD_location_df, args = ('joint%i'%joint_num,), axis=1))\n",
    "        \n",
    "plt.close('all')\n",
    "plt.figure(figsize = (18,5))\n",
    "pltcolors = ['xkcd:aqua', 'xkcd:azure', 'xkcd:crimson', 'xkcd:fuchsia', 'xkcd:goldenrod', 'xkcd:green']\n",
    "for ss,subtype in enumerate(subtypes[0:4]): \n",
    "    plt.subplot(1,4,ss+1)\n",
    "    plt.text(0, 10, 'H: ', color = 'k')\n",
    "    plt.text(0, 195, 'n: ', color = 'k')\n",
    "    plt.title('%s'%subtype, loc = 'left')\n",
    "    plt.plot(100,100,'k+')\n",
    "    plt.axis('off')\n",
    "    for joint_num in range(0,6):\n",
    "        lens = [len(item) for item in df.loc[df['substrate'] == subtype]['joint%i_TD_x'%joint_num]]\n",
    "        sub_TD = pd.DataFrame( {\"substrate\" : np.repeat(df.loc[df['substrate'] == subtype]['substrate'].values, lens), \n",
    "                                \"colony\" : np.repeat(df.loc[df['substrate'] == subtype]['colony'].values, lens),\n",
    "                                \"TD_x\" : np.concatenate(df.loc[df['substrate'] == subtype]['joint%i_TD_x'%joint_num].values), \n",
    "                                \"TD_y\" : np.concatenate(df.loc[df['substrate'] == subtype]['joint%i_TD_y'%joint_num].values)})\n",
    "        \n",
    "        TD_hist, _, _ = np.histogram2d(sub_TD['TD_x'].values, sub_TD['TD_y'].values , bins=np.arange(-100,101,1), normed = True)\n",
    "        c_array = colors.ListedColormap(pltcolors[joint_num])(range(0,100))\n",
    "        c_array[:, -1]=np.arange(0,1,0.01)\n",
    "        new_cmap = LinearSegmentedColormap.from_list(name = '%s_alpha'%pltcolors[joint_num], colors = c_array)\n",
    "        plt.imshow(TD_hist.T, cmap = new_cmap, norm = colors.Normalize(vmin=0, vmax = 0.01))\n",
    "        \n",
    "        entropy = -1*np.nansum(np.multiply(TD_hist, np.log2(TD_hist)))\n",
    "        plt.text(20+30*joint_num, 10, '%0.2f'%entropy, color = pltcolors[joint_num], horizontalalignment = 'left')\n",
    "        plt.text(20+30*joint_num, 195, '%i'%len(sub_TD), color = pltcolors[joint_num], horizontalalignment = 'left', fontsize = 8)\n",
    "#         print( 'Sub: %s -- Joint: %i -- H = %0.2f'%(subtype, joint_num, entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION - JUST SCATTER PLOT\n",
    "\n",
    "allsubs = [tr['substrate'] for tr in trial_info]\n",
    "subtypes = sorted(list(set(allsubs)))\n",
    "allcols = [tr['colony'] for tr in trial_info]\n",
    "coltypes = sorted(list(set(allcols)))\n",
    "plt.close('all')\n",
    "\n",
    "def rotate_wrt_neck(x, y, thorax_x, thorax_y, neck_x, neck_y):\n",
    "    \n",
    "    val_coord = np.array([x,y])-np.array([thorax_x,thorax_y])\n",
    "    neck_coord = np.array([neck_x-thorax_x,neck_y-thorax_y])\n",
    "    ang = np.arctan( (neck_y-thorax_y)/(neck_x-thorax_x))\n",
    "    c, s = np.cos(ang), np.sin(ang)\n",
    "    Rx = np.array([c,s])\n",
    "    Ry = np.array([-s,c])\n",
    "    newx = np.einsum('mn,mn->n', val_coord, Rx)\n",
    "    newy = np.einsum('mn,mn->n', val_coord, Ry)\n",
    "#     R = np.array([[c,s],[-1*s,c]])\n",
    "#     newxy = np.einsum('mn,mqn->mn', val_coord, R)\n",
    "#     print('val: ', val_coord[0,:], val_coord[1,:])\n",
    "#     print('neck: ', neck_coord[0,:], neck_coord[1,:])\n",
    "#     print('ang: ', ang)\n",
    "#     print('newxy: ', newxy[0,0:10], newxy[1,0:10])\n",
    "#     print('Rx,Ry', Rx, Ry)\n",
    "#     print('newx: ', newx[0:10])\n",
    "#     print('newy: ', newy)\n",
    "    \n",
    "    return newx, newy\n",
    "\n",
    "def plot_joint_pointcloud(x, ant_part):\n",
    "#     print('%s_x_filt'%ant_part)\n",
    "    joint_x = x['%s_x_filt'%ant_part]\n",
    "    joint_y = x['%s_y_filt'%ant_part]\n",
    "    thorax_x = x['thorax_x_filt']\n",
    "    thorax_y = x['thorax_y_filt']\n",
    "    neck_x = x['neck_x_filt']\n",
    "    neck_y = x['neck_y_filt']\n",
    "    frames = x['frames']\n",
    "    frames_final = x['frames_final']\n",
    "    vals_OI = np.isin(frames, frames_final)\n",
    "    cs = plt.cm.get_cmap('viridis',6)\n",
    "    alpha = 0.1\n",
    "#     print('joint', len(joint_x), 'thorax', len(thorax_x), 'neck', len(neck_x), 'frames', len(vals_OI))\n",
    "    \n",
    "    if 'thorax' in ant_part:\n",
    "        plt.plot((joint_x-thorax_x), (joint_y-thorax_y), '.k', alpha=alpha, \n",
    "                 markeredgecolor = None, markeredgewidth = 0)\n",
    "    elif 'neck' in ant_part:\n",
    "        new_x, new_y = rotate_wrt_neck(joint_x, joint_y, thorax_x, thorax_y, neck_x, neck_y)\n",
    "        plt.plot(new_x, new_y, '.', alpha=alpha, c = 'r', \n",
    "                 markeredgecolor = None, markeredgewidth = 0)\n",
    "    elif 'anten' in ant_part:\n",
    "        new_x, new_y = rotate_wrt_neck(joint_x, joint_y, thorax_x, thorax_y, neck_x, neck_y)\n",
    "        plt.plot(new_x, new_y, '.', alpha=alpha, c = 'k', \n",
    "                 markeredgecolor = None, markeredgewidth = 0)\n",
    "    else:\n",
    "        new_x, new_y = rotate_wrt_neck(joint_x, joint_y, thorax_x, thorax_y, neck_x, neck_y)\n",
    "        plt.plot(new_x, new_y, '.', alpha=alpha, c = cs(int(ant_part[-1])), \n",
    "                 markeredgecolor = None, markeredgewidth = 0)\n",
    "        \n",
    "#     # neck not forced to be +x axis\n",
    "#     if 'neck' in ant_part:\n",
    "#         plt.plot((neck_x-thorax_x)[vals_OI], (neck_y-thorax_y)[vals_OI], '.r', alpha=alpha, \n",
    "#                  markeredgecolor = None, markeredgewidth = 0)\n",
    "#     elif 'joint' in ant_part:\n",
    "#         plt.plot((joint_x-thorax_x)[vals_OI], (joint_y-thorax_y)[vals_OI], \n",
    "#                  '.', alpha=alpha, c = cs(int(ant_part[-1])), \n",
    "#                  markeredgecolor = None, markeredgewidth = 0)\n",
    "\n",
    "    return #joint_x, joint_y, new_xaxis_unit\n",
    "\n",
    "\n",
    "for coltype in coltypes:\n",
    "    \n",
    "    col_data = df.loc[df['colony'] == coltype]\n",
    "    plt.figure(figsize = (14,4))\n",
    "    plt.clf()\n",
    "    for kk, subtype in enumerate(subtypes):\n",
    "        dataOI = col_data.loc[col_data['substrate'] == subtype]\n",
    "        \n",
    "        plt.subplot(1,len(subtypes),kk+1)\n",
    "        \n",
    "        if kk != 0:\n",
    "            plt.gca().get_yaxis().set_visible(False)\n",
    "    \n",
    "        plt.plot(0,0,'.k')\n",
    "#         dataOI.apply(plot_joint_pointcloud, args = ('thorax',), axis=1)\n",
    "#         dataOI.apply(plot_joint_pointcloud, args = ('neck',), axis=1)\n",
    "        \n",
    "        # antennae\n",
    "#         for joint_num in range(0,2):\n",
    "#             dataOI.apply(plot_joint_pointcloud, args = ('antenna%i'%joint_num,), axis=1)\n",
    "            \n",
    "        # legs\n",
    "        for joint_num in range(0,6):\n",
    "            dataOI.apply(plot_joint_pointcloud, args = ('joint%i'%joint_num,), axis=1)\n",
    "            \n",
    "            \n",
    "        plt.title('Substrate: %s'%subtype, loc='left')\n",
    "#         plt.ylim((-100,100))\n",
    "        plt.axis('equal')\n",
    "        plt.xlim((-100,100))\n",
    "#         plt.ylim((-100,100))\n",
    "        plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_df(x, part):\n",
    "    new_x = x['%s_x_filt'%part]\n",
    "    new_y = x['%s_y_filt'%part]\n",
    "#     print(np.nanmax(new_x))\n",
    "    return '*X* max: %0.0f, min: %0.0f  --  *Y* max: %0.0f, min: %0.0f'%(np.nanmax(new_x), np.nanmin(new_x), np.nanmax(new_y), np.nanmin(new_y))\n",
    "\n",
    "print('LEGS')\n",
    "for joint_num in [3]:#range(0,1):\n",
    "    df.apply(find_max_df, args = ('joint%i'%joint_num,), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMPARE TD SHIFT TO SIMPLE ANT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate shift of average TD location wrt flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distance from flat ave step down\n",
    "# footX[step_height, ss, joint_num]\n",
    "\n",
    "\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "jjs = [0,3,1,4,2,5]\n",
    "titles = ['hind','mid','fore']\n",
    "\n",
    "# bar plot\n",
    "# plt.figure()\n",
    "# for step_height in [0,1]:\n",
    "#     Xdif = (footX[step_height,1:,:]-footX[1,0,:])#*[1,-1,-1,1,-1,-1]\n",
    "#     Ydif = (footY[step_height,1:,:]-footY[1,0,:])*[1,1,1,-1,-1,-1]\n",
    "\n",
    "#     for jj in np.arange(0,3):\n",
    "#         joint_num = [jj,jj+3]\n",
    "        \n",
    "#         # medial/lateral shift\n",
    "#         plt.subplot(2,3,jj+1)\n",
    "#         xs = np.linspace(0,0.4,3)\n",
    "#         ys = np.mean(Ydif[:,joint_num]/pix2mm, axis =1)\n",
    "#         if step_height == 0:\n",
    "#             plt.bar(xs,ys, color = pltcolors[1:], alpha = 0.3, width = 0.2, align = 'edge', hatch=\"/\")\n",
    "#         else:\n",
    "#             plt.bar(xs,ys, color = pltcolors[1:], alpha = 0.7, width = 0.2, align = 'edge')\n",
    "        \n",
    "#         plt.gca().get_xaxis().set_visible(False)\n",
    "#         plt.axhline(y=0, linestyle = ':', color = pltcolors[0])\n",
    "#         plt.title(titles[jj]+'limb')\n",
    "#         if jj == 0:\n",
    "#             plt.ylabel('lateral <---> medial')\n",
    "#         else:\n",
    "#             plt.gca().get_yaxis().set_visible(False)\n",
    "#         plt.axis('equal')\n",
    "#         plt.ylim([-0.3,0.3])\n",
    "\n",
    "        \n",
    "#         # anterior/posterior shift\n",
    "#         plt.subplot(2,3,jj+4)\n",
    "#         xs = -1 * np.linspace(0,0.4,3)\n",
    "#         ys = np.mean(Xdif[:,joint_num]/pix2mm, axis =1)\n",
    "#         if step_height == 0:\n",
    "#             plt.barh(xs,ys, color = pltcolors[1:], alpha = 0.3, height = 0.2, align = 'edge', hatch=\"/\")\n",
    "#         else:\n",
    "#             plt.barh(xs,ys, color = pltcolors[1:], alpha = 0.7, height = 0.2, align = 'edge')\n",
    "        \n",
    "#         plt.gca().get_yaxis().set_visible(False)\n",
    "#         plt.axvline(x=0, linestyle = ':', color = pltcolors[0])\n",
    "#         plt.axis('equal')\n",
    "#         if jj ==1:\n",
    "#             plt.xlabel('posterior <---> anterior')\n",
    "#         plt.xlim([-0.3, 0.3])\n",
    "\n",
    "\n",
    "# plt.close('all')\n",
    "plt.figure()\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.prop_cycle'] = mpl.cycler(color = pltcolors[1:])\n",
    "c_x = np.array([-1,0,1]) #np.mean(footX[1,0,:].reshape((2,3)),axis=0)/pix2mm\n",
    "c_y = np.zeros(3) #np.mean(np.abs(footY[1,0,:]).reshape((2,3)),axis=0)/pix2mm\n",
    "plt.plot(c_x,c_y,'.k')\n",
    "linestyles=['--','-']\n",
    "for step_height in [0,1]:\n",
    "    Xdif = (footX[step_height,1:,:]-footX[1,0,:])#*[1,-1,-1,1,-1,-1]\n",
    "    Ydif = (footY[step_height,1:,:]-footY[1,0,:])*[1,1,1,-1,-1,-1]\n",
    "    for jj in np.arange(0,3):\n",
    "        joint_num = [jj,jj+3]\n",
    "        ys = np.mean(Ydif[:,joint_num]/pix2mm, axis =1)\n",
    "        xs = np.mean(Xdif[:,joint_num]/pix2mm, axis =1)\n",
    "        plt.plot(np.array([np.ones(3)*c_x[jj],c_x[jj]+xs]), np.array([np.ones(3)*c_y[jj],c_y[jj]+ys]),linestyle= linestyles[step_height], alpha = 0.8)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.axvline(x=-1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=-1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=1,color ='k',alpha = 0.2)\n",
    "# del fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for simple ant model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define important functions\n",
    "\n",
    "def plot_tripods(xs,ys,zs,col):\n",
    "#     ax.scatter(xs[1]-xs[1],ys[1]-ys[1],zs[1],s=20, c=col)\n",
    "    ax.scatter(xs[::4]-xs[1],ys[::4]-ys[1],zs[::4],s=4, c=col)\n",
    "    ax.scatter(xs[2::4]-xs[1],ys[2::4]-ys[1],zs[2::4],s=20, c=col)\n",
    "    ax.plot3D(xs-xs[1],ys-ys[1],zs, ':', color = col)\n",
    "    \n",
    "def rotate(xs, ys, x0, y0, ang): # angle in radians\n",
    "    new_xs = x0 + math.cos(ang) * (xs - x0) - math.sin(ang) * (ys - y0)\n",
    "    new_ys = y0 + math.sin(ang) * (xs - x0) + math.cos(ang) * (ys - y0)\n",
    "    return new_xs, new_ys\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "    ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    '''\n",
    "\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n",
    "    \n",
    "    \n",
    "def plot_cylinder(x0, x1, y, z0, z1, cyl_rad, col):\n",
    "\n",
    "    origin = np.array([0, 0, 0])\n",
    "    #axis and radius\n",
    "    p0 = np.array([x0, y, z0])\n",
    "    p1 = np.array([x1, y, z1])\n",
    "    R = cyl_rad\n",
    "    #vector in direction of axis\n",
    "    v = p1 - p0\n",
    "    #find magnitude of vector\n",
    "    mag = norm(v)\n",
    "    #unit vector in direction of axis\n",
    "    v = v / mag\n",
    "    #make some vector not in the same direction as v\n",
    "    not_v = np.array([1, 0, 0])\n",
    "    if (v == not_v).all():\n",
    "        not_v = np.array([0, 1, 0])\n",
    "    #make vector perpendicular to v\n",
    "    n1 = np.cross(v, not_v)\n",
    "    #normalize n1\n",
    "    n1 /= norm(n1)\n",
    "    #make unit vector perpendicular to v and n1\n",
    "    n2 = np.cross(v, n1)\n",
    "    #surface ranges over t from 0 to length of axis and 0 to 2*pi\n",
    "    t = np.linspace(0, mag, 100)\n",
    "    theta = np.linspace(0, 2 * np.pi, 100)\n",
    "    #use meshgrid to make 2d arrays\n",
    "    t, theta = np.meshgrid(t, theta)\n",
    "    #generate coordinates for surface\n",
    "    X, Y, Z = [p0[i] + v[i] * t + R * np.sin(theta) * n1[i] + R * np.cos(theta) * n2[i] for i in [0, 1, 2]]\n",
    "    ax.plot_surface(X, Y, Z, color = col)\n",
    "    plt.show()\n",
    "    \n",
    "# #plot axis\n",
    "# ax.plot(*zip(p0, p1), color = 'red')\n",
    "# ax.set_xlim(0, 10)\n",
    "# ax.set_ylim(0, 10)\n",
    "# ax.set_zlim(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate ant model around back limb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL FOOT PLACEMENT FOR DIFF BODY ORIENTATIONS - PLOT 3D - rotate around back stance foot\n",
    "plt.close('all')\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0]\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "body_height = 3/4#2/3\n",
    "angle_OI = 1/4\n",
    "\n",
    "# flat ground option\n",
    "xs = np.vstack([allX, np.zeros(6)]).flatten(order='F')\n",
    "ys = np.vstack([allY, np.zeros(6)]).flatten(order='F')\n",
    "zs = np.vstack([np.zeros(6), body_height*np.ones(6)]).flatten(order='F')\n",
    "\n",
    "# PITCH UP\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "ax = fig.add_subplot(1,2,1, projection = '3d')\n",
    "plot_tripods(xs,ys,zs,'k')\n",
    "p_angle = np.tan(angle_OI)\n",
    "p_xs, p_zs = rotate(xs,zs, xs[0],zs[0], p_angle)\n",
    "p_ys = ys\n",
    "plot_tripods(p_xs,p_ys,p_zs,'r')\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[0,0],[0,0]]), alpha = 0.1)\n",
    "ax.plot_surface(np.array([[0.5,0.5],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[1,1],[1,1]]), alpha = 0.1)\n",
    "\n",
    "# annotate\n",
    "# plt.gcf().text(0.4, 0.85, 'F:')\n",
    "# plt.gcf().text(0.4, 0.82, 'M:')\n",
    "# plt.gcf().text(0.4, 0.79, 'H:')\n",
    "\n",
    "# plt.gcf().text(0.43, 0.88, 'ant')\n",
    "# plt.gcf().text(0.43, 0.85, '%0.2f'%((p_xs[-2]-p_xs[1])-xs[-2]))\n",
    "# plt.gcf().text(0.43, 0.82, '%0.2f'%((p_xs[2]-p_xs[1])-xs[2]))\n",
    "# plt.gcf().text(0.43, 0.79, '%0.2f'%((p_xs[6]-p_xs[1])-xs[6]))\n",
    "\n",
    "# plt.gcf().text(0.47, 0.88, 'med')\n",
    "# plt.gcf().text(0.47, 0.85, '%0.2f'%(np.abs(ys[-2])-np.abs(p_ys[-2]-p_ys[1])))\n",
    "# plt.gcf().text(0.47, 0.82, '%0.2f'%(np.abs(ys[2])-np.abs(p_ys[2]-p_ys[1])))\n",
    "# plt.gcf().text(0.47, 0.79, '%0.2f'%(np.abs(ys[6])-np.abs(p_ys[6]-p_ys[1])))\n",
    "\n",
    "\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "plt.title('pitching up')\n",
    "\n",
    "\n",
    "print(p_xs)\n",
    "print(xs)\n",
    "\n",
    "\n",
    "# PITCH DOWN\n",
    "ax = fig.add_subplot(1,2,2, projection = '3d')\n",
    "plot_tripods(xs,ys,zs,'k')\n",
    "p_angle = -1*np.tan(angle_OI)\n",
    "p_xs, p_zs = rotate(xs,zs, xs[0],zs[0], p_angle)\n",
    "p_ys = ys\n",
    "plot_tripods(p_xs,p_ys,p_zs,'r')\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[0,0],[0,0]]), alpha = 0.1)\n",
    "ax.plot_surface(np.array([[0.5,0.5],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[-1,-1],[-1,-1]]), alpha = 0.1)\n",
    "\n",
    "# annotate\n",
    "plt.gcf().text(0.82, 0.85, 'F:')\n",
    "plt.gcf().text(0.82, 0.82, 'M:')\n",
    "plt.gcf().text(0.82, 0.79, 'H:')\n",
    "\n",
    "plt.gcf().text(0.85, 0.88, 'ant')\n",
    "plt.gcf().text(0.85, 0.85, '%0.2f'%((p_xs[-2]-p_xs[1])-xs[-2]))\n",
    "plt.gcf().text(0.85, 0.82, '%0.2f'%((p_xs[2]-p_xs[1])-xs[2]))\n",
    "plt.gcf().text(0.85, 0.79, '%0.2f'%((p_xs[6]-p_xs[1])-xs[6]))\n",
    "\n",
    "plt.gcf().text(0.9, 0.88, 'med')\n",
    "plt.gcf().text(0.9, 0.85, '%0.2f'%(np.abs(ys[-2])-np.abs(p_ys[-2]-p_ys[1])))\n",
    "plt.gcf().text(0.9, 0.82, '%0.2f'%(np.abs(ys[2])-np.abs(p_ys[2]-p_ys[1])))\n",
    "plt.gcf().text(0.9, 0.79, '%0.2f'%(np.abs(ys[6])-np.abs(p_ys[6]-p_ys[1])))\n",
    "\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "plt.title('pitching down')\n",
    "\n",
    "\n",
    "# # ROLL UP\n",
    "# fig = plt.figure(figsize = (12,6))\n",
    "# ax = fig.add_subplot(1,2,1, projection = '3d')\n",
    "# plot_tripods(xs,ys,zs,'k')\n",
    "# r_angle = np.tan(1/3)\n",
    "# p_ys, p_zs = rotate(ys,zs, ys[2],zs[2], r_angle)\n",
    "# p_xs = xs\n",
    "# plot_tripods(p_xs,p_ys,p_zs,'r')\n",
    "# ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[0,0],[0,0]]), alpha = 0.1)\n",
    "# ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[0.5,2],[0.5,2]]), np.array([[1,1],[1,1]]), alpha = 0.1)\n",
    "\n",
    "# # annotate\n",
    "# plt.gcf().text(0.4, 0.85, 'F:')\n",
    "# plt.gcf().text(0.4, 0.82, 'M:')\n",
    "# plt.gcf().text(0.4, 0.79, 'H:')\n",
    "\n",
    "# plt.gcf().text(0.43, 0.88, 'ant')\n",
    "# plt.gcf().text(0.43, 0.85, '%0.2f'%((p_xs[-2]-p_xs[1])-xs[-2]))\n",
    "# plt.gcf().text(0.43, 0.82, '%0.2f'%((p_xs[2]-p_xs[1])-xs[2]))\n",
    "# plt.gcf().text(0.43, 0.79, '%0.2f'%((p_xs[6]-p_xs[1])-xs[6]))\n",
    "\n",
    "# plt.gcf().text(0.47, 0.88, 'med')\n",
    "# plt.gcf().text(0.47, 0.85, '%0.2f'%(np.abs(ys[-2])-np.abs(p_ys[-2]-p_ys[1])))\n",
    "# plt.gcf().text(0.47, 0.82, '%0.2f'%(np.abs(ys[2])-np.abs(p_ys[2]-p_ys[1])))\n",
    "# plt.gcf().text(0.47, 0.79, '%0.2f'%(np.abs(ys[6])-np.abs(p_ys[6]-p_ys[1])))\n",
    "\n",
    "# ax.set_xlabel('post --> ant')\n",
    "# ax.set_ylabel('mediolateral')\n",
    "# set_axes_equal(ax)\n",
    "# plt.title('roll up')\n",
    "\n",
    "\n",
    "# # ROLL DOWN\n",
    "# ax = fig.add_subplot(1,2,2, projection = '3d')\n",
    "# plot_tripods(xs,ys,zs,'k')\n",
    "# r_angle = -1*np.tan(1/3)\n",
    "# p_ys, p_zs = rotate(ys,zs, ys[2],zs[2], r_angle)\n",
    "# p_xs = xs\n",
    "# plot_tripods(p_xs,p_ys,p_zs,'r')\n",
    "# ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[0,0],[0,0]]), alpha = 0.1)\n",
    "# ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[0.5,2],[0.5,2]]), -1*np.array([[1,1],[1,1]]), alpha = 0.1)\n",
    "\n",
    "# # annotate\n",
    "# plt.gcf().text(0.82, 0.85, 'F:')\n",
    "# plt.gcf().text(0.82, 0.82, 'M:')\n",
    "# plt.gcf().text(0.82, 0.79, 'H:')\n",
    "\n",
    "# plt.gcf().text(0.85, 0.88, 'ant')\n",
    "# plt.gcf().text(0.85, 0.85, '%0.2f'%((p_xs[-2]-p_xs[1])-xs[-2]))\n",
    "# plt.gcf().text(0.85, 0.82, '%0.2f'%((p_xs[2]-p_xs[1])-xs[2]))\n",
    "# plt.gcf().text(0.85, 0.79, '%0.2f'%((p_xs[6]-p_xs[1])-xs[6]))\n",
    "\n",
    "# plt.gcf().text(0.9, 0.88, 'med')\n",
    "# plt.gcf().text(0.9, 0.85, '%0.2f'%(np.abs(ys[-2])-np.abs(p_ys[-2]-p_ys[1])))\n",
    "# plt.gcf().text(0.9, 0.82, '%0.2f'%(np.abs(ys[2])-np.abs(p_ys[2]-p_ys[1])))\n",
    "# plt.gcf().text(0.9, 0.79, '%0.2f'%(np.abs(ys[6])-np.abs(p_ys[6]-p_ys[1])))\n",
    "\n",
    "# ax.set_xlabel('post --> ant')\n",
    "# ax.set_ylabel('mediolateral')\n",
    "# set_axes_equal(ax)\n",
    "# plt.title('roll down')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitch ant up/down around body center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL FOOT PLACEMENT FOR DIFF BODY ORIENTATIONS - PLOT 3D - rotate around body center\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0]\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "body_height = 2/3\n",
    "angle_OI = 1/3\n",
    "view_ang = -75\n",
    "view_ele = 20\n",
    "\n",
    "\n",
    "def plot_tripods(xs,ys,zs,col):\n",
    "#     ax.scatter(xs[1]-xs[1],ys[1]-ys[1],zs[1],s=20, c=col)\n",
    "#     ax.scatter(xs[::4]-xs[1],ys[::4]-ys[1],zs[::4],s=4, c=col)\n",
    "    ax.scatter(xs[2::4]-xs[1],ys[2::4]-ys[1],zs[2::4],s=20, c=col, alpha = 1)\n",
    "    ax.plot3D(xs-xs[1],ys-ys[1],zs, ':', color = col, alpha = 1)\n",
    "\n",
    "# flat ground option\n",
    "xs = np.vstack([allX, np.zeros(6)]).flatten(order='F')\n",
    "ys = np.vstack([allY, np.zeros(6)]).flatten(order='F')\n",
    "zs = np.vstack([np.zeros(6), body_height*np.ones(6)]).flatten(order='F')\n",
    "\n",
    "\n",
    "# PITCH UP\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "ax = fig.add_subplot(1,2,1, projection = '3d')\n",
    "ax.view_init(elev = view_ele, azim = view_ang)\n",
    "col = '#8B5E3C'\n",
    "# plot_tripods(xs,ys,zs,'k')\n",
    "p_angle = np.tan(angle_OI)\n",
    "p_xs, p_zs = rotate(xs,zs, 0, body_height, p_angle)\n",
    "p_zs = p_zs + (0.5-(p_zs[-2]+p_zs[6])/2)\n",
    "p_ys = ys\n",
    "plot_tripods(p_xs,p_ys,p_zs,col)\n",
    "ax.plot_surface(np.array([[-3,-3],[0.75,0.75]]), np.array([[-2,2],[-2,2]]), np.array([[0,0],[0,0]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[0.75,0.75],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[1,1],[1,1]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[0.75,0.75],[0.75,0.75]]), np.array([[-2,-2],[2,2]]), np.array([[0,1],[0,1]]), alpha = 0.2, color = 'k')\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "cyl_rad = 0.1\n",
    "plot_cylinder(p_xs[1]-1.5, p_xs[1]+1.5, p_ys[1], p_zs[1]-1.5*np.sin(p_angle), p_zs[1]+1.5*np.sin(p_angle), cyl_rad, col)\n",
    "plt.title('pitching up')\n",
    "ax._axis3don=False\n",
    "\n",
    "\n",
    "# PITCH DOWN\n",
    "ax = fig.add_subplot(1,2,2, projection = '3d')\n",
    "ax.view_init(elev = view_ele, azim = view_ang)\n",
    "col = 'k'\n",
    "# plot_tripods(xs,ys,zs,'k')\n",
    "p_angle = -1*np.tan(angle_OI)\n",
    "p_xs, p_zs = rotate(xs,zs, 0, body_height, p_angle)\n",
    "p_zs = p_zs + (-0.5-(p_zs[-2]+p_zs[6])/2)\n",
    "p_ys = ys\n",
    "plot_tripods(p_xs,p_ys,p_zs,col)\n",
    "ax.plot_surface(np.array([[-3,-3],[0.75,0.75]]), np.array([[-2,2],[-2,2]]), np.array([[0,0],[0,0]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[0.75,0.75],[2,2]]), np.array([[-2,2],[-2,2]]), np.array([[-1,-1],[-1,-1]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[0.75,0.75],[0.75,0.75]]), np.array([[-2,-2],[2,2]]), np.array([[-1,0],[-1,0]]), alpha = 0.2, color = 'k')\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "cyl_rad = 0.1\n",
    "plot_cylinder(p_xs[1]-1.5, p_xs[1]+1.5, p_ys[1], p_zs[1]-1.5*np.sin(p_angle), p_zs[1]+1.5*np.sin(p_angle), cyl_rad, col)\n",
    "plt.title('pitching down')\n",
    "ax._axis3don=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PITCH UP AND DOWN - 2D\n",
    "# plt.close('all')\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0] # stance feet move back 1 mm wrt body center\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "allZ = np.zeros(6)\n",
    "body_height = 2/3\n",
    "angle_OI = 1/3\n",
    "leg_lengths = np.linalg.norm(np.array([allX[1::2],allY[1::2],body_height*np.ones(3)]),axis=0)\n",
    "leg_lengths2 = np.linalg.norm(np.array([allX[0::2],allY[0::2],body_height*np.ones(3)]),axis=0)\n",
    "\n",
    "\n",
    "# PITCH UP\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(0,0,'+k')\n",
    "plt.plot(allX,allY,'.k')\n",
    "plt.plot([allX[::2], allX[::2]+1],[allY[::2],allY[::2]],':k')\n",
    "for start_idc in [1]:\n",
    "    tripod = plt.Polygon(np.array([allX[start_idc::2],allY[start_idc::2]]).T.reshape([3,2]),color = 'k', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "    \n",
    "p_angle = np.tan(angle_OI)\n",
    "## rotate around body center and adjust\n",
    "p_xs, p_zs = rotate(allX,allZ, 0, body_height, p_angle)\n",
    "c_x, c_y, c_z = (0, 0, body_height+(0.5-(p_zs[-1]+p_zs[3])/2))\n",
    "p_zs = p_zs + (0.5-(p_zs[-1]+p_zs[3])/2)\n",
    "p_ys = allY\n",
    "## rotate around back foot\n",
    "# p_xs, p_zs = rotate(allX,allZ, allX[0], allZ[0], p_angle)\n",
    "# p_ys = allY\n",
    "# c_x, c_z = rotate(0,body_height, allX[0], allZ[0], p_angle)\n",
    "# c_y = 0\n",
    "plt.plot(c_x-c_x,0,'+r')\n",
    "for start_idc in [1]:\n",
    "    plt.plot(p_xs[start_idc::2]-c_x, p_ys[start_idc::2],'.r')\n",
    "    tripod = plt.Polygon(np.array([p_xs[start_idc::2]-c_x,p_ys[start_idc::2]]).T.reshape([3,2]), color = 'r', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "\n",
    "# midlimb on valley and peak\n",
    "r = (leg_lengths[0]**2-(1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))+10 , color = 'r', linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "r = (leg_lengths[0]**2-(0-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))+10 , color = 'r', linestyle = '-', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "# hindlimb on valley\n",
    "r = (leg_lengths[1]**2-(0-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))+10 , color = 'r' , linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "# forelimb on peak\n",
    "r = (leg_lengths[2]**2-(1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))+10 , color = 'r', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('posterior --> anterior (mm)')\n",
    "plt.ylabel('mediolateral')\n",
    "plt.title('pitching up')\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "d_x = np.array([-1,0,1]) #np.mean(footX[1,0,:].reshape((2,3)),axis=0)/pix2mm\n",
    "d_y = np.zeros(3) #np.mean(np.abs(footY[1,0,:]).reshape((2,3)),axis=0)/pix2mm\n",
    "plt.plot(d_x,d_y,'.k')\n",
    "\n",
    "\n",
    "# PITCH UP\n",
    "pup = np.full((2,3,2),np.nan)\n",
    "joint_nums = [1,0,2]\n",
    "for jj in [1,3,5]:\n",
    "    angOI = np.arctan2(p_ys[jj],p_xs[jj])\n",
    "    for zz,z in enumerate([0,1]): # valley and peak vertical level\n",
    "        r= (leg_lengths[int((jj-1)/2)]**2-(z-c_z)**2)**(1/2) \n",
    "        pup[0,joint_nums[int((jj-1)/2)],zz] = np.cos(angOI)*r-allX[jj] # anterior posterior\n",
    "        pup[1,joint_nums[int((jj-1)/2)],zz] = (np.sin(angOI)*r-allY[jj])*-1*np.sign(p_ys[jj]) # mediolateral\n",
    "        pup[:,0,1]=np.nan\n",
    "        pup[:,2,0]=np.nan\n",
    "        plt.plot([d_x[joint_nums[int((jj-1)/2)]], d_x[joint_nums[int((jj-1)/2)]]+pup[0,joint_nums[int((jj-1)/2)],zz]],\n",
    "                [d_y[joint_nums[int((jj-1)/2)]], d_y[joint_nums[int((jj-1)/2)]]+pup[1,joint_nums[int((jj-1)/2)],zz]],\n",
    "                alpha = 0.8, color = 'g', linestyle=linestyles[zz])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(fig.number)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(0,0,'+k')\n",
    "plt.plot(allX,allY,'.k')\n",
    "plt.plot([allX[::2], allX[::2]+1],[allY[::2],allY[::2]],':k')\n",
    "for start_idc in [1]:\n",
    "    tripod = plt.Polygon(np.array([allX[start_idc::2],allY[start_idc::2]]).T.reshape([3,2]),color = 'k', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "    \n",
    "p_angle = -1*np.tan(angle_OI)\n",
    "## rotate around body center and adjust\n",
    "p_xs, p_zs = rotate(allX,allZ, 0, body_height, p_angle)\n",
    "c_x, c_y, c_z = (0, 0, body_height+ (-0.5-(p_zs[-1]+p_zs[3])/2))\n",
    "p_zs = p_zs + (-0.5-(p_zs[-1]+p_zs[3])/2)\n",
    "p_ys = allY\n",
    "\n",
    "plt.plot(c_x-c_x,0,'+r')\n",
    "for start_idc in [1]:\n",
    "    plt.plot(p_xs[start_idc::2]-c_x, p_ys[start_idc::2],'.r')\n",
    "    tripod = plt.Polygon(np.array([p_xs[start_idc::2]-c_x,p_ys[start_idc::2]]).T.reshape([3,2]), color = 'r', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "    \n",
    "\n",
    "# midlimb on valley and peak\n",
    "r = (leg_lengths[0]**2-(-1-c_z)**2)**(1/2) # valley\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))+10 , color = 'r', linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "r = (leg_lengths[0]**2-(0-c_z)**2)**(1/2) # peak\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))+10 , color = 'r', linestyle = '-', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "# hindlimb on peak\n",
    "r = (leg_lengths[1]**2-(0-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))+10 , color = 'r' , linestyle = '-', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "# forelimb on valley\n",
    "r = (leg_lengths[2]**2-(-1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))+10 , color = 'r', linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('posterior --> anterior (mm)')\n",
    "plt.ylabel('mediolateral')\n",
    "plt.title('pitching down')\n",
    "\n",
    "\n",
    "\n",
    "# calc x,y of peak and valley stances for each limb\n",
    "plt.figure(fig2.number)\n",
    "pdown = np.full((2,3,2),np.nan)\n",
    "joint_nums = [1,0,2]\n",
    "for jj in [1,3,5]:\n",
    "    angOI = np.arctan2(p_ys[jj],p_xs[jj])\n",
    "    for zz,z in enumerate([-1,0]): # valley and peak vertical level\n",
    "        r= (leg_lengths[int((jj-1)/2)]**2-(z-c_z)**2)**(1/2) \n",
    "        pdown[0,joint_nums[int((jj-1)/2)],zz] = np.cos(angOI)*r-allX[jj] # anterior posterior\n",
    "        pdown[1,joint_nums[int((jj-1)/2)],zz] = (np.sin(angOI)*r-allY[jj])*-1*np.sign(p_ys[jj]) # mediolateral\n",
    "        pdown[:,0,0]=np.nan\n",
    "        pdown[:,2,1]=np.nan\n",
    "        plt.plot([d_x[joint_nums[int((jj-1)/2)]], d_x[joint_nums[int((jj-1)/2)]]+pdown[0,joint_nums[int((jj-1)/2)],zz]],\n",
    "                [d_y[joint_nums[int((jj-1)/2)]], d_y[joint_nums[int((jj-1)/2)]]+pdown[1,joint_nums[int((jj-1)/2)],zz]],\n",
    "                alpha = 0.8, color = 'b', linestyle=linestyles[zz])\n",
    "plt.axis('equal')\n",
    "plt.axvline(x=-1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=-1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=1,color ='k',alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roll ant right/left around body center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL - ROLL - 3D - rotate around body center\n",
    "plt.close('all')\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0]\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "body_height = 2/3\n",
    "angle_OI = 1/2.5\n",
    "view_ang = -30\n",
    "view_ele = 20\n",
    "\n",
    "\n",
    "# flat ground option\n",
    "xs = np.vstack([allX, np.zeros(6)]).flatten(order='F')\n",
    "ys = np.vstack([allY, np.zeros(6)]).flatten(order='F')\n",
    "zs = np.vstack([np.zeros(6), body_height*np.ones(6)]).flatten(order='F')\n",
    "\n",
    "\n",
    "# ROLL RIGHT\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "ax = fig.add_subplot(1,2,1, projection = '3d')\n",
    "ax.view_init(elev = view_ele, azim = view_ang)\n",
    "col = '#8B5E3C'\n",
    "# plot_tripods(xs,ys,zs,pltcolors[0])\n",
    "p_angle = np.tan(angle_OI)\n",
    "p_ys, p_zs = rotate(ys,zs, 0, body_height, p_angle)\n",
    "p_zs = p_zs + (0.5-(p_zs[2]+p_zs[6])/2)\n",
    "p_xs = xs\n",
    "plot_tripods(p_xs,p_ys,p_zs,col)\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-2,0.1],[-2,0.1]]), np.array([[0,0],[0,0]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[0.1,2],[0.1,2]]), np.array([[1,1],[1,1]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[0.1,0.1],[0.1,0.1]]), np.array([[0,1],[0,1]]), alpha = 0.2, color = 'k')\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "cyl_rad = 0.1\n",
    "plot_cylinder(p_xs[1]-1.5, p_xs[1]+1.5, p_ys[1], p_zs[1], p_zs[1], cyl_rad, col)\n",
    "plt.title('roll right')\n",
    "ax._axis3don=False\n",
    "\n",
    "# ROLL LEFT\n",
    "ax = fig.add_subplot(1,2,2, projection = '3d')\n",
    "ax.view_init(elev = view_ele, azim = -1*view_ang)\n",
    "col = 'k'\n",
    "# plot_tripods(xs,ys,zs,pltcolors[0])\n",
    "p_angle = -1*np.tan(angle_OI)\n",
    "p_ys, p_zs = rotate(ys,zs, 0, body_height, p_angle)\n",
    "p_zs = p_zs + (-0.5-(p_zs[2]+p_zs[6])/2)\n",
    "p_xs = xs\n",
    "plot_tripods(p_xs,p_ys,p_zs, col)\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-2,-0.2],[-2,-0.2]]), np.array([[0,0],[0,0]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-0.2,2],[-0.2,2]]), np.array([[-1,-1],[-1,-1]]), alpha = 0.1, color = 'k')\n",
    "ax.plot_surface(np.array([[-3,-3],[2,2]]), np.array([[-0.2,-0.2],[-0.2,-0.2]]), np.array([[0,-1],[0,-1]]), alpha = 0.2, color = 'k')\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "cyl_rad = 0.1\n",
    "plot_cylinder(p_xs[1]-1.5, p_xs[1]+1.5, p_ys[1], p_zs[1], p_zs[1], cyl_rad, col)\n",
    "plt.title('roll left')\n",
    "ax._axis3don=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROLL - 2D\n",
    "# plt.close('all')\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0] # stance feet move back 1 mm wrt body center\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "allZ = np.zeros(6)\n",
    "body_height = 2/3\n",
    "angle_OI = 1/3\n",
    "leg_lengths = np.linalg.norm(np.array([allX[1::2],allY[1::2],body_height*np.ones(3)]),axis=0)\n",
    "leg_lengths2 = np.linalg.norm(np.array([allX[0::2],allY[0::2],body_height*np.ones(3)]),axis=0)\n",
    "\n",
    "\n",
    "# ROLL RIGHT\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(0,0,'+k')\n",
    "plt.plot(allX,allY,'.k')\n",
    "plt.plot([allX[::2], allX[::2]+1],[allY[::2],allY[::2]],':k')\n",
    "for start_idc in [1]:\n",
    "    tripod = plt.Polygon(np.array([allX[start_idc::2],allY[start_idc::2]]).T.reshape([3,2]),color = 'k', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "    \n",
    "p_angle = np.tan(angle_OI)\n",
    "## rotate around body center and adjust\n",
    "p_ys, p_zs = rotate(allY,allZ, 0, body_height, p_angle)\n",
    "c_x, c_y, c_z = (0, 0, body_height+(0.5-(p_zs[1]+p_zs[3])/2))\n",
    "p_zs = p_zs + (0.5-(p_zs[1]+p_zs[3])/2)\n",
    "p_xs = allX\n",
    "\n",
    "\n",
    "plt.plot(c_x-c_x,0,'+r')\n",
    "for start_idc in [1]:\n",
    "    plt.plot(p_xs[start_idc::2]-c_x, p_ys[start_idc::2],'.r')\n",
    "    tripod = plt.Polygon(np.array([p_xs[start_idc::2]-c_x,p_ys[start_idc::2]]).T.reshape([3,2]), color = 'r', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "\n",
    "# midlimb on valley \n",
    "r = (leg_lengths[0]**2-(0-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))+10 , color = 'r', linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "# hindlimb on peak\n",
    "r = (leg_lengths[1]**2-(1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))+10 , color = 'r' , linestyle = '-', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "# forelimb on peak\n",
    "r = (leg_lengths[2]**2-(1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))+10 , color = 'r', linestyle = '-', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('posterior --> anterior (mm)')\n",
    "plt.ylabel('mediolateral')\n",
    "plt.title('roll right')\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "d_x = np.array([-1,0,1]) #np.mean(footX[1,0,:].reshape((2,3)),axis=0)/pix2mm\n",
    "d_y = np.zeros(3) #np.mean(np.abs(footY[1,0,:]).reshape((2,3)),axis=0)/pix2mm\n",
    "plt.plot(d_x,d_y,'.k')\n",
    "pup = np.full((2,3,2),np.nan)\n",
    "joint_nums = [1,0,2]\n",
    "for jj in [1,3,5]:\n",
    "    angOI = np.arctan2(p_ys[jj],p_xs[jj])\n",
    "    for zz,z in enumerate([0,1]): # valley and peak vertical level\n",
    "        r= (leg_lengths[int((jj-1)/2)]**2-(z-c_z)**2)**(1/2) \n",
    "        pup[0,joint_nums[int((jj-1)/2)],zz] = np.cos(angOI)*r-allX[jj] # anterior posterior\n",
    "        pup[1,joint_nums[int((jj-1)/2)],zz] = (np.sin(angOI)*r-allY[jj])*-1*np.sign(p_ys[jj]) # mediolateral\n",
    "        pup[:,0,0]=np.nan\n",
    "        pup[:,2,0]=np.nan\n",
    "        pup[:,1,1]=np.nan\n",
    "        plt.plot([d_x[joint_nums[int((jj-1)/2)]], d_x[joint_nums[int((jj-1)/2)]]+pup[0,joint_nums[int((jj-1)/2)],zz]],\n",
    "                [d_y[joint_nums[int((jj-1)/2)]], d_y[joint_nums[int((jj-1)/2)]]+pup[1,joint_nums[int((jj-1)/2)],zz]],\n",
    "                alpha = 0.8, color = 'g', linestyle=linestyles[zz])\n",
    "plt.ylabel('lateral <--> medial')\n",
    "plt.xlabel('posterior <--> anterior')\n",
    "\n",
    "\n",
    "# ROLL LEFT\n",
    "plt.figure(fig.number)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(0,0,'+k')\n",
    "plt.plot(allX,allY,'.k')\n",
    "plt.plot([allX[::2], allX[::2]+1],[allY[::2],allY[::2]],':k')\n",
    "for start_idc in [1]:\n",
    "    tripod = plt.Polygon(np.array([allX[start_idc::2],allY[start_idc::2]]).T.reshape([3,2]),color = 'k', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "\n",
    "## rotate around body center and adjust\n",
    "p_angle = -1*np.tan(angle_OI)\n",
    "p_ys, p_zs = rotate(allY,allZ, 0, body_height, p_angle)\n",
    "c_x, c_y, c_z = (0, 0, body_height+(-0.5-(p_zs[1]+p_zs[3])/2))\n",
    "p_zs = p_zs + (-0.5-(p_zs[1]+p_zs[3])/2)\n",
    "p_xs = allX\n",
    "\n",
    "plt.plot(c_x-c_x,0,'+r')\n",
    "for start_idc in [1]:\n",
    "    plt.plot(p_xs[start_idc::2]-c_x, p_ys[start_idc::2],'.r')\n",
    "    tripod = plt.Polygon(np.array([p_xs[start_idc::2]-c_x,p_ys[start_idc::2]]).T.reshape([3,2]), color = 'r', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "    \n",
    "# midlimb on peak\n",
    "r = (leg_lengths[0]**2-(0-c_z)**2)**(1/2) # peak\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[1],p_xs[1]-c_x))+10 , color = 'r', linestyle = '-', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "# hindlimb on valley\n",
    "r = (leg_lengths[1]**2-(-1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[3],p_xs[3]-c_x))+10 , color = 'r' , linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "# forelimb on valley\n",
    "r = (leg_lengths[2]**2-(-1-c_z)**2)**(1/2)\n",
    "h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))-10, theta2=np.rad2deg(np.arctan2(p_ys[5],p_xs[5]-c_x))+10 , color = 'r', linestyle = '--', alpha = 0.4)\n",
    "plt.gca().add_patch(h_arc)\n",
    "\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('posterior --> anterior (mm)')\n",
    "plt.ylabel('mediolateral')\n",
    "plt.title('roll left')\n",
    "\n",
    "# calc x,y of peak and valley stances for each limb\n",
    "plt.figure(fig2.number)\n",
    "pdown = np.full((2,3,2),np.nan)\n",
    "joint_nums = [1,0,2]\n",
    "for jj in [1,3,5]:\n",
    "    angOI = np.arctan2(p_ys[jj],p_xs[jj])\n",
    "    for zz,z in enumerate([-1,0]): # valley and peak vertical level\n",
    "        r= (leg_lengths[int((jj-1)/2)]**2-(z-c_z)**2)**(1/2) \n",
    "        pdown[0,joint_nums[int((jj-1)/2)],zz] = np.cos(angOI)*r-allX[jj] # anterior posterior\n",
    "        pdown[1,joint_nums[int((jj-1)/2)],zz] = (np.sin(angOI)*r-allY[jj])*-1*np.sign(p_ys[jj]) # mediolateral\n",
    "        pdown[:,0,1]=np.nan\n",
    "        pdown[:,1,0]=np.nan\n",
    "        pdown[:,2,1]=np.nan\n",
    "        plt.plot([d_x[joint_nums[int((jj-1)/2)]], d_x[joint_nums[int((jj-1)/2)]]+pdown[0,joint_nums[int((jj-1)/2)],zz]],\n",
    "                [d_y[joint_nums[int((jj-1)/2)]], d_y[joint_nums[int((jj-1)/2)]]+pdown[1,joint_nums[int((jj-1)/2)],zz]],\n",
    "                alpha = 0.8, color = 'b', linestyle=linestyles[zz])\n",
    "plt.axis('equal')\n",
    "plt.axvline(x=-1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=-1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=1,color ='k',alpha = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ant steps in ditches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DITCH - 2D\n",
    "# plt.close('all')\n",
    "from matplotlib import patches\n",
    "\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0] # stance feet move back 1 mm wrt body center\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "allZ = np.zeros(6)\n",
    "body_height = 2/3\n",
    "angle_OI = 1/3\n",
    "leg_lengths = np.linalg.norm(np.array([allX[1::2],allY[1::2],body_height*np.ones(3)]),axis=0) # leg lengths from stance\n",
    "leg_lengths2 = np.linalg.norm(np.array([allX[0::2],allY[0::2],body_height*np.ones(3)]),axis=0) # long leg lengths from stance location\n",
    "\n",
    "\n",
    "# FORE UP\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(0,0,'+k')\n",
    "plt.plot(allX,allY,'.k')\n",
    "plt.plot([allX[::2], allX[::2]+1],[allY[::2],allY[::2]],':k')\n",
    "for start_idc in [1]:\n",
    "    tripod = plt.Polygon(np.array([allX[start_idc::2],allY[start_idc::2]]).T.reshape([3,2]),color = 'k', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "    \n",
    "\n",
    "# calc foot position on ground\n",
    "c_x, c_y, c_z = (0, 0, body_height*1/3)\n",
    "p_xs = np.full(3,np.nan)\n",
    "p_ys = np.full(3,np.nan)\n",
    "p_zs = np.array([-1,-1,0]) # hind, mid, fore\n",
    "line_styles = ['--','-']\n",
    "for j_idc, jj in enumerate([3, 1, 5]): # hind, mid, fore\n",
    "    \n",
    "    angOI = np.arctan2(allY[jj],allX[jj])\n",
    "    z=p_zs[j_idc]\n",
    "    print('joint %i, angle %0.1f, height %i'%(jj, angOI, z))\n",
    "    r= (leg_lengths[int((jj-1)/2)]**2-(z-c_z)**2)**(1/2) \n",
    "    p_xs[j_idc]= np.cos(angOI)*r\n",
    "    p_ys[j_idc] = (np.sin(angOI)*r)\n",
    "    h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(angOI)-10, theta2=np.rad2deg(angOI)+10 , color = 'r', \n",
    "                        linestyle = line_styles[z+1], alpha = 0.4)\n",
    "    plt.gca().add_patch(h_arc)\n",
    "plt.plot(p_xs, p_ys,'.r')\n",
    "tripod = plt.Polygon(np.array([p_xs,p_ys]).T.reshape([3,2]), color = 'r', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "plt.gca().add_patch(tripod)\n",
    "plt.plot(c_x-c_x,0,'+r')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('posterior --> anterior (mm)')\n",
    "plt.ylabel('mediolateral')\n",
    "plt.title('forelimb on peak')\n",
    "plt.axhline(y=-1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=0,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=-1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=0,color ='k',alpha = 0.2)\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "d_x = np.array([-1,0,1]) \n",
    "d_y = np.zeros(3) \n",
    "plt.plot(d_x,d_y,'.k')\n",
    "pup = np.full((2,3,2),np.nan)\n",
    "joint_nums = [3,1,5]\n",
    "for jj in range(3):\n",
    "    pup[0,jj,p_zs[jj]+1] = p_xs[jj]-allX[joint_nums[jj]] # anterior-posterior\n",
    "    pup[1,jj,p_zs[jj]+1] = (p_ys[jj]-allY[joint_nums[jj]])*-1*np.sign(p_ys[jj]) # mediolateral\n",
    "    plt.plot([d_x[jj], d_x[jj]+pup[0,jj,p_zs[jj]+1]],\n",
    "            [d_y[jj], d_y[jj]+pup[1,jj,p_zs[jj]+1]],\n",
    "            alpha = 0.8, color = 'g', linestyle=linestyles[p_zs[jj]+1])\n",
    "plt.ylabel('lateral <--> medial')\n",
    "plt.xlabel('posterior <--> anterior')\n",
    "\n",
    "\n",
    "# FORELIMB DOWN\n",
    "plt.figure(fig.number)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(0,0,'+k')\n",
    "plt.plot(allX,allY,'.k')\n",
    "plt.plot([allX[::2], allX[::2]+1],[allY[::2],allY[::2]],':k')\n",
    "for start_idc in [1]:\n",
    "    tripod = plt.Polygon(np.array([allX[start_idc::2],allY[start_idc::2]]).T.reshape([3,2]),color = 'k', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "    plt.gca().add_patch(tripod)\n",
    "\n",
    "# calc foot position on ground\n",
    "p_xs = np.full(3,np.nan)\n",
    "p_ys = np.full(3,np.nan)\n",
    "p_zs = np.array([0,0,-1]) # hind, mid, fore\n",
    "line_styles = ['--','-']\n",
    "for j_idc, jj in enumerate([3, 1, 5]): # hind, mid, fore\n",
    "    angOI = np.arctan2(allY[jj],allX[jj])\n",
    "    z=p_zs[j_idc]\n",
    "#     print('joint %i, angle %0.1f, height %i'%(jj, angOI, z))\n",
    "    r= (leg_lengths[int((jj-1)/2)]**2-(z-c_z)**2)**(1/2) \n",
    "    p_xs[j_idc]= np.cos(angOI)*r\n",
    "    p_ys[j_idc] = (np.sin(angOI)*r)\n",
    "    h_arc = patches.Arc((0,0), 2*r, 2*r, angle = 0, theta1=np.rad2deg(angOI)-10, theta2=np.rad2deg(angOI)+10 , color = 'r', \n",
    "                        linestyle = line_styles[z+1], alpha = 0.4)\n",
    "    plt.gca().add_patch(h_arc)\n",
    "plt.plot(p_xs, p_ys,'.r')\n",
    "tripod = plt.Polygon(np.array([p_xs,p_ys]).T.reshape([3,2]), color = 'r', alpha = 0.2, edgecolor = None, linestyle = None)\n",
    "plt.gca().add_patch(tripod)\n",
    "plt.plot(c_x-c_x,0,'+r')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.xlabel('posterior --> anterior (mm)')\n",
    "plt.ylabel('mediolateral')\n",
    "plt.title('forelimb on valley')\n",
    "plt.axhline(y=-1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=0,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=-1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=0,color ='k',alpha = 0.2)\n",
    "\n",
    "\n",
    "# calc x,y of peak and valley stances for each limb\n",
    "plt.figure(fig2.number)\n",
    "pdown = np.full((2,3,2),np.nan)\n",
    "joint_nums = [3,1,5]\n",
    "for jj in range(3):\n",
    "    pdown[0,jj,p_zs[jj]+1] = p_xs[jj]-allX[joint_nums[jj]] # anterior-posterior\n",
    "    pdown[1,jj,p_zs[jj]+1] = (p_ys[jj]-allY[joint_nums[jj]])*-1*np.sign(p_ys[jj]) # mediolateral\n",
    "    plt.plot([d_x[jj], d_x[jj]+pdown[0,jj,p_zs[jj]+1]],\n",
    "            [d_y[jj], d_y[jj]+pdown[1,jj,p_zs[jj]+1]],\n",
    "            alpha = 0.8, color = 'b', linestyle=linestyles[p_zs[jj]+1])\n",
    "plt.axis('equal')\n",
    "plt.axvline(x=-1,color ='k',alpha = 0.2)\n",
    "plt.axvline(x=1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=-1,color ='k',alpha = 0.2)\n",
    "plt.axhline(y=1,color ='k',alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL DITCH - 3D \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.close('all')\n",
    "\n",
    "flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical\n",
    "flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm\n",
    "allX = np.tile(flatX,2)-[1,0,1,0,1,0]\n",
    "allY = np.hstack([-1*flatY,flatY])\n",
    "body_height = 2/3\n",
    "angle_OI = 1/2.5\n",
    "view_ang = -70\n",
    "view_ele = 80\n",
    "\n",
    "\n",
    "# flat ground option\n",
    "xs = np.vstack([allX, np.zeros(6)]).flatten(order='F')\n",
    "ys = np.vstack([allY, np.zeros(6)]).flatten(order='F')\n",
    "zs = np.vstack([np.zeros(6), body_height*np.ones(6)]).flatten(order='F')\n",
    "\n",
    "\n",
    "# FORELIMB UP\n",
    "fig = plt.figure(figsize = (12,6))\n",
    "ax = fig.add_subplot(1,2,1, projection = '3d')\n",
    "ax.view_init(elev = view_ele, azim = view_ang)\n",
    "col = '#8B5E3C'\n",
    "p_xs = xs.copy()\n",
    "p_xs[2::4] = np.nanmean(pup[0,:,:],axis =1)+p_xs[2::4]\n",
    "p_ys = ys.copy()\n",
    "p_ys[2::4] = np.nanmean(pup[1,:,:],axis =1)+p_ys[2::4]\n",
    "p_zs = zs.copy()-(body_height-c_z)\n",
    "p_zs[2::4] = [-1,-1,0]\n",
    "\n",
    "ax.scatter(p_xs[2::4],p_ys[2::4],p_zs[2::4],s=20, c=col, alpha = 1)\n",
    "ax.plot3D(p_xs,p_ys,p_zs, ':', color = col, alpha = 1)\n",
    "heights = np.array([0, -1])\n",
    "y_offset = 0.5\n",
    "x_offset = -0.1\n",
    "for xb in range(-3,2):\n",
    "    for yb in range(-3,2):\n",
    "        if yb%2 == 1:\n",
    "            zz= heights[xb%2]\n",
    "        else:\n",
    "            zz=heights[np.where(np.array(heights) !=xb%2)[0][0]]\n",
    "        ax.plot_surface(np.array([[xb,xb],[xb+1,xb+1]])+x_offset, np.array([[yb,yb+1],[yb,yb+1]])+y_offset, np.ones([2,2])*zz, alpha = 1, color = ['beige','#D3D3D3'][-1*zz])#np.ones(3)*254/255)\n",
    "        ax.plot_surface(np.array([[xb,xb],[xb+1,xb+1]])+x_offset, np.array([[yb+1,yb+1],[yb+1,yb+1]])+y_offset, np.array([[-1,0],[-1,0]]), alpha = 1, color = 'grey')\n",
    "        ax.plot_surface(np.array([[xb+1,xb+1],[xb+1,xb+1]])+x_offset, np.array([[yb,yb],[yb+1,yb+1]])+y_offset, np.array([[-1,0],[-1,0]]), color = 'r')\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "cyl_rad = 0.1\n",
    "plot_cylinder(c_x-1.5, c_x+1.5, c_y, c_z, c_z, cyl_rad, col)\n",
    "plt.title('forelimb on peak')\n",
    "ax._axis3don=False\n",
    "\n",
    "# FORELIMB DOWN\n",
    "ax = fig.add_subplot(1,2,2, projection = '3d')\n",
    "ax.view_init(elev = view_ele, azim = view_ang)\n",
    "col = 'k'\n",
    "p_xs = xs.copy()\n",
    "p_xs[2::4] = np.nanmean(pdown[0,:,:],axis =1)+p_xs[2::4]\n",
    "p_ys = ys.copy()\n",
    "p_ys[2::4] = np.nanmean(pdown[1,:,:],axis =1)+p_ys[2::4]\n",
    "p_zs = zs.copy()-(body_height-c_z)\n",
    "p_zs[2::4] = [0,0,-1]\n",
    "\n",
    "ax.scatter(p_xs[2::4],p_ys[2::4],p_zs[2::4],s=20, c=col, alpha = 1)\n",
    "ax.plot3D(p_xs,p_ys,p_zs, ':', color = col, alpha = 1)\n",
    "heights = np.array([0, -1])\n",
    "y_offset = 0.5\n",
    "x_offset = -0.1\n",
    "for xb in range(-3,2):\n",
    "    for yb in range(-3,2):\n",
    "        if yb%2 == 0:\n",
    "            zz= heights[xb%2]\n",
    "        else:\n",
    "            zz=heights[np.where(np.array(heights) !=xb%2)[0][0]]a\n",
    "        ax.plot_surface(np.array([[xb,xb],[xb+1,xb+1]])+x_offset, np.array([[yb,yb+1],[yb,yb+1]])+y_offset, np.ones([2,2])*zz, alpha = 1, color = ['beige','#D3D3D3'][-1*zz])#np.ones(3)*254/255)\n",
    "        ax.plot_surface(np.array([[xb,xb],[xb+1,xb+1]])+x_offset, np.array([[yb+1,yb+1],[yb+1,yb+1]])+y_offset, np.array([[-1,0],[-1,0]]), alpha = 1, color = 'grey')\n",
    "        ax.plot_surface(np.array([[xb+1,xb+1],[xb+1,xb+1]])+x_offset, np.array([[yb,yb],[yb+1,yb+1]])+y_offset, np.array([[-1,0],[-1,0]]), color = 'r')\n",
    "ax.set_xlabel('post --> ant')\n",
    "ax.set_ylabel('mediolateral')\n",
    "set_axes_equal(ax)\n",
    "cyl_rad = 0.1\n",
    "plot_cylinder(c_x-1.5, c_x+1.5, c_y, c_z, c_z, cyl_rad, col)\n",
    "plt.title('forelimb on valley')\n",
    "ax._axis3don=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KINEMATIC LANDSCAPE: travel direction vs. heading rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d dist plot of body travel dir. vs. facing rotation for all trials\n",
    "from scipy.stats import kurtosis, skew\n",
    "plt.close('all')\n",
    "pix2mm = 1000/32\n",
    "fps = 240\n",
    "df['St_Len_all'] = df.filter(regex='_St_Len$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1) # in mm\n",
    "df['St_Dur_all'] = df.filter(regex='St_Dur$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/fps, axis = 1) # in sec\n",
    "df['St_tdist_total'] = df.filter(regex='_St_tdist_total$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_tdist_straight'] = df.filter(regex='_St_tdist_straight$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_rotation'] = df.filter(regex='_St_rotation$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_travel_dir'] = df.filter(regex='_St_travel_dir$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_jointID'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "\n",
    "lens = [len(item) for item in df['St_Len_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values) })\n",
    "\n",
    "print(len(all_strides))\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "subtypes = sorted(list(set(df['substrate'].values)))\n",
    "coltypes = sorted(list(set(df['substrate'].values)))\n",
    "\n",
    "# ROTATION\n",
    "# plt.figure(figsize = (15,5))\n",
    "# for ss, subtype in enumerate(subtypes[0:4]):\n",
    "#     plt.subplot(1,4, ss+1)\n",
    "#     ax = sns.distplot(all_strides.loc[(all_strides['substrate']==subtype)]['St_rotation'].dropna().values, label = '%s'%subtype, color = pltcolors[ss])#,\n",
    "#     plt.ylim((0,0.04))\n",
    "#     plt.xlim((-200,200))\n",
    "#     plt.title('%s'%subtype, loc = 'left')\n",
    "#     if ss == 0:\n",
    "#         plt.ylabel('probability')\n",
    "#         plt.xlabel('stride rotation (deg)')\n",
    "#     else:\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "        \n",
    "# straight stride speed\n",
    "# plt.figure(figsize = (15,5))\n",
    "# for ss, subtype in enumerate(subtypes[0:4]):\n",
    "#     plt.subplot(1,4, ss+1)\n",
    "#     vals_OI = (all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_straight'].values/\n",
    "#                all_strides.loc[(all_strides['substrate']==subtype)]['StDur_all'].values)\n",
    "#     ax = sns.distplot(vals_OI[np.isfinite(vals_OI)], label = '%s'%subtype, color = pltcolors[ss])#,\n",
    "#     plt.ylim((0,0.14))\n",
    "#     plt.xlim((-50,50))\n",
    "#     plt.title('%s'%subtype, loc = 'left')\n",
    "#     if ss == 0:\n",
    "#         plt.ylabel('probability')\n",
    "#     else:\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    \n",
    "# straight/total dist\n",
    "# plt.figure(figsize = (15,5))\n",
    "# for ss, subtype in enumerate(subtypes[0:4]):\n",
    "#     plt.subplot(1,4, ss+1)\n",
    "#     vals_OI = (np.abs(all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_straight'].values)/\n",
    "#                all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_total'].values)\n",
    "#     ax = sns.distplot(vals_OI[np.isfinite(vals_OI)], label = '%s'%subtype, color = pltcolors[ss])#,\n",
    "#     plt.ylim((0,40))\n",
    "#     plt.xlim((-.1,1.1))\n",
    "#     plt.title('%s'%subtype, loc = 'left')\n",
    "#     if ss == 0:\n",
    "#         plt.ylabel('probability')\n",
    "#         plt.xlabel('straight/total dist')\n",
    "#     else:\n",
    "#         ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    \n",
    "\n",
    "# 2D hist: straight/total dist vs. rotation\n",
    "fig = plt.figure(figsize = (15,4))\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "angle_buffer = 15\n",
    "line_factor = angle_buffer #(angle_buffer/np.sin(np.deg2rad(45)))\n",
    "bar_ax = plt.axes((0.8,0.1, 0.1, 0.1), facecolor = 'w')\n",
    "ns = np.full((4,4),np.nan)\n",
    "\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    ax =plt.subplot(1,4, ss+1)\n",
    "#     xvals_OI = np.rad2deg(np.arccos(\n",
    "#         all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_straight'].values/\n",
    "#                all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_total'].values))\n",
    "    xvals_OI = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!='Tunnel_20180329-30')]['St_travel_dir'].values\n",
    "    yvals_OI = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!='Tunnel_20180329-30')]['St_rotation'].values\n",
    "    \n",
    "    # PLOT THINGS\n",
    "    c_array = colors.ListedColormap(pltcolors[ss])(range(0,100))\n",
    "    c_array[:, -1]=np.arange(0,1,0.01)\n",
    "    new_cmap = LinearSegmentedColormap.from_list(name = '%s_alpha'%pltcolors[ss], colors = c_array)\n",
    "    plt.hexbin(xvals_OI, yvals_OI, bins = 'log', gridsize = 40, vmin =0, vmax = 3.5, cmap = new_cmap, edgecolors = 'none')#, color = pltcolors[ss])#,\n",
    "#     ax = sns.jointplot(x = xvals_OI, y = yvals_OI, kind = 'hex', color = pltcolors[ss], xlim = (0,1), ylim = (-150,150))\n",
    "    if ss == 3:\n",
    "        cax = fig.add_axes([.93, .1, .02, .8])\n",
    "        plt.colorbar(cax = cax, label = 'log(probability)')\n",
    "        plt.sca(ax)\n",
    "    plt.axis('equal')\n",
    "    plt.ylim((-180,180))\n",
    "    plt.xlim((-180,180))\n",
    "    \n",
    "    \n",
    "    # quadrants\n",
    "    for vline in [90, -90, 0,]:\n",
    "        plt.axhline(y=vline, color = [0.7, 0.7, 0.7], linestyle = ':', alpha = 0.4)\n",
    "    for vline in [90, -90, 0,]:\n",
    "        plt.axvline(x=vline, color = [0.7, 0.7, 0.7], linestyle = ':', alpha = 0.4)\n",
    "    \n",
    "    # unicycle and co-aligned lines\n",
    "# #     plt.plot([angle_buffer,180-angle_buffer],[angle_buffer,180-angle_buffer],'--k', alpha = 0.4)\n",
    "#     plt.plot([angle_buffer,180],[angle_buffer-line_factor,180-line_factor],':k', alpha = 0.4)\n",
    "#     plt.plot([angle_buffer,180],[angle_buffer+line_factor,180+line_factor],':k', alpha = 0.4)\n",
    "# #     plt.plot([-angle_buffer,-180+angle_buffer],[-angle_buffer,-180+angle_buffer],'--k', alpha = 0.4)\n",
    "#     plt.plot([-angle_buffer,-180],[-angle_buffer+line_factor,-180+line_factor],':k', alpha = 0.4)\n",
    "#     plt.plot([-angle_buffer,-180],[-angle_buffer-line_factor,-180-line_factor],':k', alpha = 0.4)\n",
    "    plt.plot([-180,180],[-180+line_factor,180+line_factor],':k', alpha = 0.4)\n",
    "    plt.plot([-180,180],[-180-line_factor,180-line_factor],':k', alpha = 0.4)\n",
    "    plt.plot([-90,90],[-180,180],'-k', alpha = 0.4)\n",
    "    \n",
    "    \n",
    "    # chasse-ing\n",
    "#     plt.plot([angle_buffer+line_factor,135],[+angle_buffer,+angle_buffer],':k', alpha = 0.4)\n",
    "    plt.plot([0,180],[-angle_buffer,-angle_buffer],':k', alpha = 0.4)\n",
    "#     plt.plot([135,180],[angle_buffer,-angle_buffer],':k', alpha = 0.4)\n",
    "#     plt.plot([-angle_buffer-line_factor,-135],[-angle_buffer,-angle_buffer],':k', alpha = 0.4)\n",
    "    plt.plot([0,-180],[angle_buffer,angle_buffer],':k', alpha = 0.4)\n",
    "#     plt.plot([-135,-180],[-angle_buffer,angle_buffer],':k', alpha = 0.4)\n",
    "    \n",
    "    # going backwards\n",
    "#     for vline in [angle_buffer, -angle_buffer, 180-angle_buffer, -180+angle_buffer]:\n",
    "#         plt.axvline(x=vline, color = 'k', linestyle = ':', alpha = 0.4)\n",
    "\n",
    "    # going backwards\n",
    "    for vline in [angle_buffer, -angle_buffer]:\n",
    "        plt.axvline(x=vline, color = 'k', linestyle = ':', alpha = 0.4)\n",
    "\n",
    "    plt.title('%s'%subtype, loc = 'left')\n",
    "    if ss == 0:\n",
    "        plt.ylabel('facing rotation over stride (deg)')\n",
    "#         plt.xlabel('straight/total dist')\n",
    "        plt.xlabel('body travel dir wrt original facing (deg)')\n",
    "    else:\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "    plt.axis('equal')\n",
    "    plt.text(50, 220, 'ang. buffer: %i'%angle_buffer, FontSize = 6)\n",
    "    plt.text(50, 205, 'n strides: %i'%len(xvals_OI), FontSize = 6)\n",
    "    n_straight = np.sum( np.abs(xvals_OI)<15 )\n",
    "    n_unicycle = np.sum( (np.abs(yvals_OI-xvals_OI)<15) & (np.abs(xvals_OI)>15) )\n",
    "    n_sideslip = np.sum((np.abs(yvals_OI) < np.abs(xvals_OI)-15) & (np.sign(yvals_OI-15) == np.sign(xvals_OI)))\n",
    "    n_backup = np.sum( (np.sign(yvals_OI-15) != np.sign(xvals_OI)) & (np.abs(xvals_OI)>15)  & (np.abs(yvals_OI)>15))\n",
    "    plt.text(50, 190, 'n unicycle: %i'%n_unicycle, FontSize = 6)\n",
    "    plt.text(50, 175, 'n sideslip: %i'%n_sideslip, FontSize = 6)\n",
    "    plt.text(50, 160, 'n straight: %i'%n_straight, FontSize = 6)\n",
    "#     plt.text(50, 160, 'S vs. U: %0.2f%%'%(n_sideslip/n_unicycle*100), FontSize = 6)\n",
    "    ns[ss,:]=np.array([n_straight, n_unicycle, n_sideslip, n_backup])\n",
    "\n",
    "\n",
    "plt.figure\n",
    "idcs = ([0,1,2,3]*np.ones((4,4))).T\n",
    "heights = ns/np.repeat(np.sum(ns,axis=1)[:,np.newaxis], 4, axis =1)\n",
    "bottoms = np.concatenate([np.zeros((1,4)),heights[:,:-1].T]).T\n",
    "for ii in range(4):\n",
    "    plt.bar(idcs[ii,:],heights[ii,:],1,bottom=bottoms[ii,:])\n",
    "\n",
    "#     heights = np.array([n_straight, n_unicycle, n_sideslip, n_backup])/len(xvals_OI)*5\n",
    "#     print(heights)\n",
    "#     bottoms = np.array([0, n_straight, n_unicycle, n_sideslip])\n",
    "#     idcs = ss*np.ones(4)\n",
    "#     plt.sca(bar_ax)\n",
    "    \n",
    "#     plt.bar(idcs, heights, 1, bottom = bottoms)\n",
    "#     aglkngew\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# STRIDE LENGTH\n",
    "# dist plot of all lengths\n",
    "# max_val = ceil(all_strides['StLen_all'].max()*10)/10\n",
    "# n_bins = 100\n",
    "# plt.close('all')\n",
    "# plt.figure(figsize = (15,5))\n",
    "# plt.xlabel('stride len (mm)')\n",
    "# allsubs = [tr['substrate'] for tr in trial_info]\n",
    "# subtypes = sorted(list(set(allsubs)))\n",
    "# allcols = [tr['colony'] for tr in trial_info]\n",
    "# coltypes = sorted(list(set(allcols)))\n",
    "# for ss,subtype in enumerate(subtypes[0:4]):\n",
    "#     plt.subplot(1,4, ss+1)\n",
    "#     ax = sns.distplot(all_strides.loc[(all_strides['substrate']==subtype)]['StLen_all'].dropna().values, label = '%s'%subtype)#, \n",
    "# #                                  bins = np.linspace(0,max_val, n_bins+1), label = '%s'%subtype)\n",
    "#     str_k = kurtosis(all_strides.loc[(all_strides['substrate']==subtype)]['StLen_all'].dropna().values)\n",
    "#     str_s = skew(all_strides.loc[(all_strides['substrate']==subtype)]['StLen_all'].dropna().values)\n",
    "#     B = (str_s**2 +1 )/str_k\n",
    "#     print('K : %0.2f, scew: %0.2f, B: %0.2f'%(str_k, str_s, B))\n",
    "#     plt.title('%s'%subtype, loc = 'left')\n",
    "    \n",
    "#     plt.xlim((-1, 8))\n",
    "#     plt.ylim((0,1.5))\n",
    "#     plt.text(7.5, 1.4, 'n: %i'%len(all_strides.loc[(all_strides['substrate']==subtype)]['StLen_all'].dropna().values), ha = 'right')\n",
    "#     plt.text(7.5, 1.3, 'kurtosis: %0.2f'%str_k, ha = 'right')\n",
    "#     plt.text(7.5, 1.2, 'skew: %0.2f'%str_s, ha = 'right')\n",
    "#     plt.text(7.5, 1.1, 'bimodality coeff: %0.2f'%B, ha = 'right')\n",
    "#     plt.xlabel('stride length (mm)')\n",
    "#     if ss == 0:\n",
    "#         plt.ylabel('probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure\n",
    "idcs = ([0,1,2,3]*np.ones((4,4))).T\n",
    "heights = ns/np.repeat(np.sum(ns,axis=1)[:,np.newaxis], 4, axis =1)\n",
    "bottoms = np.cumsum(np.concatenate([np.zeros((1,4)),heights[:,:-1].T]).T,axis=1)\n",
    "pltcolors = ['b','r','g','k']\n",
    "for ii in range(4):\n",
    "    print(idcs[ii,:], heights[ii,:]*100)\n",
    "    plt.bar(idcs[ii,:], heights[ii,:],1, bottom=bottoms[ii,:], color = pltcolors)\n",
    "plt.ylabel('fraction of strides')\n",
    "plt.gca().get_xaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model what it would look like for a car\n",
    "c_len = 1\n",
    "# steering=-75\n",
    "# c_thrust = 1\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "\n",
    "steerings = -1*np.arange(0,92,5)\n",
    "thrusts = np.arange(0.1,2,0.1)\n",
    "headVtravel = np.full((len(steerings),len(thrusts)), np.nan)\n",
    "\n",
    "\n",
    "for ss, steering in enumerate(steerings):\n",
    "\n",
    "    for tt, c_thrust in enumerate(thrusts[0:1]):\n",
    "        c_heading = np.deg2rad(steering)\n",
    "        \n",
    "        # initial conditions\n",
    "        c_angle = np.deg2rad(90)\n",
    "        c_loc = np.zeros(2)\n",
    "        c_head = c_loc+c_len/2*np.array([np.cos(c_angle), np.sin(c_angle)])\n",
    "        c_tail = c_loc-c_len/2*np.array([np.cos(c_angle), np.sin(c_angle)])\n",
    "        \n",
    "        # consitions at next time step\n",
    "        c_tail = c_tail + c_thrust * np.array([np.cos(c_angle), np.sin(c_angle)])\n",
    "        delta_angle =  c_thrust / c_len * np.tan(c_heading)\n",
    "        c_angle = (c_angle + c_thrust / c_len * np.tan(c_heading))\n",
    "       # print('steering: ', steering,' -- delta heading: ', delta_angle)\n",
    "        \n",
    "        if np.abs(delta_angle) < np.pi/2:\n",
    "\n",
    "            c_head = c_tail + c_len * np.array([np.cos(c_angle), np.sin(c_angle)])\n",
    "            c_loc = c_tail + c_len / 2 * np.array([np.cos(c_angle), np.sin(c_angle)])\n",
    "\n",
    "            travel_dir = 90-np.rad2deg(np.arctan2(c_loc[1],c_loc[0]))\n",
    "            heading_rot = 90-np.rad2deg(c_angle)\n",
    "            headVtravel[ss,tt] = heading_rot/travel_dir\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            ### plot things\n",
    "            plt.plot([ 0,0], [-1*c_len/2, c_len/2], '-b')\n",
    "            plt.plot(0,0,'.b')\n",
    "            plt.plot([c_head[0],c_tail[0]], [c_head[1],c_tail[1]], '-r', alpha = 0.5)\n",
    "            plt.plot(c_loc[0], c_loc[1],'.r', alpha = 0.5)\n",
    "            plt.axis('equal')\n",
    "        \n",
    "        # print things\n",
    "    #     print(np.linalg.norm(np.diff(np.vstack([c_head, c_tail]),axis=0))) # sanity check that new length is 1\n",
    "            print('steering: ', steering,' -- travel dir: ', travel_dir , '-- heading: ', heading_rot)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(headVtravel, center = 1 , cmap = 'seismic', xticklabels = np.round(thrusts, decimals =1),\n",
    "            yticklabels = steerings,  cbar_kws={'label': 'heading/travel dir.'})  \n",
    "plt.ylabel('steering angle')\n",
    "plt.xlabel('forward speed (body lengths/stride)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin plots of straight stride speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "df['St_Len_all'] = df.filter(regex='_St_Len$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1) # in mm\n",
    "df['St_Dur_all'] = df.filter(regex='St_Dur$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/fps, axis = 1) # in sec\n",
    "df['St_tdist_total'] = df.filter(regex='_St_tdist_total$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_tdist_straight'] = df.filter(regex='_St_tdist_straight$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_rotation'] = df.filter(regex='_St_rotation$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_travel_dir'] = df.filter(regex='_St_travel_dir$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_jointID'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "\n",
    "lens = [len(item) for item in df['St_Len_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"date\" : np.repeat(df['date'].values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values),\n",
    "                        \"time\" : np.repeat(df['time'].values, lens)})\n",
    "\n",
    "all_strides['St_speed'] = all_strides['St_tdist_total']/all_strides['St_Dur_all'] # in mm/s\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "coltypes = sorted(list(set(df['colony'].values)))\n",
    "angle_buffer = 15\n",
    "pltcolors = ['#464F56', '#BA4246', '#087E8B', '#701C6F']\n",
    "my_pal = {\"0mm\": '#464F56', \"1mm\": '#BA4246', \"3mm\": '#087E8B', \"5mm\": '#701C6F'}\n",
    "ax = sns.violinplot(x = 'substrate', y = 'St_speed',  \n",
    "                    data = all_strides[(all_strides['colony'] != 'Tunnel_20180508-09') &\n",
    "                                     (np.abs(all_strides['St_travel_dir'])<angle_buffer)], cut = 0 , palette=my_pal) #hue = 'substrate',\n",
    "ax.set_ylabel('stride speed [mm/s]')\n",
    "plt.gcf()\n",
    "\n",
    "\n",
    "\n",
    "print('Saving median and bootstrap files as feathers')\n",
    "import feather\n",
    "temp = all_strides[(all_strides['colony'] != 'Tunnel_20180508-09') &\n",
    "                                     (np.abs(all_strides['St_travel_dir'])<angle_buffer)]\n",
    "colony_R = [col.split('20180')[-1][1:] for col in temp['colony'].values.tolist()]\n",
    "date_days = [col[-2:] for col in temp['date'].values.tolist()]\n",
    "day_R = [col.split('-').index(day) for day, col in zip(date_days, colony_R)]\n",
    "subs_string = temp['substrate'].values.tolist()\n",
    "substrate_R = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "st_speed_R = np.array(temp['St_speed'])\n",
    "df_stspeed_R = pd.DataFrame( {\"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R,\n",
    "                       \"stride_speed\" : st_speed_R } )\n",
    "feather.write_dataframe(df_stspeed_R, vid_locations + 'St_Speed.feather')\n",
    "for ss in list(set(df['substrate'].values)):\n",
    "    print(ss, len(temp[temp['substrate']==ss]))\n",
    "del colony_R, date_days, day_R, subs_string, substrate_R, st_speed_R, df_stspeed_R\n",
    "del temp, all_strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride frequency vs. straight stride speed -- identify disrupted strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bandwidths (scott vs. silverman): 0.175491039, 0.175491039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:102: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45316253]\n",
      "bandwidths (scott vs. silverman): 0.205089878, 0.205089878\n",
      "[0.5297038]\n",
      "bandwidths (scott vs. silverman): 0.182314024, 0.182314024\n",
      "[0.54010848]\n",
      "bandwidths (scott vs. silverman): 0.166293335, 0.166293335\n",
      "[0.51285222]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:218: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "# stride length or frequency vs. straight stride speed - hexbin plot\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "plt.close('all')\n",
    "df['St_Len_all'] = df.filter(regex='_St_Len$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1) # in mm\n",
    "df['St_Dur_all'] = df.filter(regex='_St_Dur$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/fps, axis = 1) # in sec\n",
    "df['St_start'] = df.filter(regex='_St_start$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1) \n",
    "df['St_stop'] = df.filter(regex='_St_stop$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1) \n",
    "df['St_tdist_total'] = df.filter(regex='_St_tdist_total$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_tdist_straight'] = df.filter(regex='_St_tdist_straight$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_rotation'] = df.filter(regex='_St_rotation$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_travel_dir'] = df.filter(regex='_St_travel_dir$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_jointID'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "\n",
    "lens = [len(item) for item in df['St_Len_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_start\" : np.concatenate(df['St_start'].values), \"St_stop\" : np.concatenate(df['St_stop'].values),    \n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values),\n",
    "                        \"time\" : np.repeat(df['time'].values, lens)})\n",
    "\n",
    "\n",
    "subtypes = sorted(list(set(df['substrate'])))\n",
    "coltypes = sorted(list(set(df['colony'].values)))\n",
    "fig = plt.figure(1,figsize = (15,4))\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "angle_buffer = 15\n",
    "\n",
    "# Stride length vs. speed\n",
    "slope, intercept, res_width = np.full(4,np.nan),np.full(4,np.nan),np.full(4,np.nan)\n",
    "if 'density' not in locals():\n",
    "    density = {}\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    plt.figure(1)\n",
    "    sp_ax=plt.subplot(1,4, ss+1)\n",
    "    \n",
    "    # FOR STRIDE FREQUENCY! - SPECIFY IF FOR ALL STRIDES OR JUST STRAIGHT ONES\n",
    "    SL_OI = 1/all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Dur_all'].values\n",
    "    vals_OI = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_tdist_total'].values/\n",
    "               all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Dur_all'].values)\n",
    "    str_idcs = np.isfinite(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_travel_dir'])\n",
    "#     str_idcs = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_travel_dir'])<angle_buffer # only straight strides\n",
    "    d_cutoff = 0.005 # stride duration\n",
    "\n",
    "    \n",
    "    # FOR STRIDE LENGTH\n",
    "#     SL_OI = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Len_all'].values\n",
    "#     vals_OI = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_tdist_total'].values/\n",
    "#                all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Dur_all'].values)\n",
    "#     str_idcs = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_travel_dir'])<angle_buffer\n",
    "#     d_cutoff = 0.03 # stride length\n",
    "    \n",
    "\n",
    "    plt.title('%s'%subtype, loc = 'left')\n",
    "    if ss == 0:\n",
    "        plt.ylabel('stride len (mm)')\n",
    "        plt.ylabel('stride freq (Hz)')\n",
    "#         plt.xlabel('total stride speed (mm/s)')\n",
    "    else:\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        \n",
    "\n",
    "    # FIT LINE ONLY WHERE DENSE POINTS\n",
    "    from sklearn.neighbors import KernelDensity\n",
    "    x = vals_OI[str_idcs]\n",
    "    y = SL_OI[str_idcs]\n",
    "    no_nan_pts = np.logical_and(np.isfinite(x), np.isfinite(y))\n",
    "    x = x[no_nan_pts]\n",
    "    y = y[no_nan_pts]\n",
    "    \n",
    "    xy_train = np.vstack([y,x]).T\n",
    "    d = np.min(xy_train.shape) # number of dimensions\n",
    "    n = np.max(xy_train.shape) # number of points\n",
    "    bw_sil = (n*(d+2) / 4.) ** (-1./ (d +4)) # silverman - \"Density estimation for statistics and data analysis\" 1986\n",
    "    bw_sco = n**(-1./(d+4)) # scott's - \"Multivariate density estimateion...\" 1992\n",
    "    print('bandwidths (scott vs. silverman): %0.9f, %0.9f'%(bw_sco, bw_sil))\n",
    "    kde = KernelDensity(bandwidth = bw_sco, kernel = 'gaussian')\n",
    "    kde.fit(xy_train)\n",
    "    density[ss] = np.exp(kde.score_samples(np.vstack([y,x]).T))\n",
    "\n",
    "    inlier_mask = density[ss] > d_cutoff\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "    # if want to plot whole distribution\n",
    "#     xx, yy = np.meshgrid(np.arange(np.floor(x.min()),np.ceil(x.max()),1), np.arange(np.floor(y.min()),np.ceil(y.max()),0.1))\n",
    "#     xy_sample = np.vstack([yy.ravel(), xx.ravel()]).T\n",
    "#     zz = np.reshape(np.exp(kde.score_samples(xy_sample)), xx.shape)\n",
    "#     print(np.sum(np.sum(zz)))\n",
    "#     # e.g. plt.pcolormesh(xx,yy,zz)\n",
    "    \n",
    "    \n",
    "    # calc linear regression\n",
    "    slope[ss], intercept[ss], r_val, p_val, std_err = stats.linregress(vals_OI[str_idcs][no_nan_pts][inlier_mask], SL_OI[str_idcs][no_nan_pts][inlier_mask])\n",
    "    res_width[ss] = 4*np.nanstd(y[inlier_mask]-(slope[ss]*x[inlier_mask]+intercept[ss]))\n",
    "    disrupted_strides = y>(slope[ss]*x+intercept[ss]+res_width[ss])\n",
    "    \n",
    "#     A = np.vstack([vals_OI[str_idcs][inlier_mask], np.ones(np.sum(inlier_mask))]).T \n",
    "    slope_origin = np.linalg.lstsq(vals_OI[str_idcs][no_nan_pts][inlier_mask][:,np.newaxis], SL_OI[str_idcs][no_nan_pts][inlier_mask])[0]\n",
    "    print(slope_origin)\n",
    "    \n",
    "    \n",
    "    # USE PCA TO GET RID OF OUTLIERS?\n",
    "#     points = np.array([vals_OI[str_idcs], SL_OI[str_idcs]]).T\n",
    "#     cent =np.mean(points, 0)\n",
    "#     new_points = StandardScaler().fit_transform(points-cent)\n",
    "#     pca = PCA(n_components = 2)\n",
    "#     pca.fit(new_points)\n",
    "#     el_angle = np.arctan2(pca.components_[0][1], pca.components_[1][1])\n",
    "#     el_var = pca.explained_variance_\n",
    "#     R = np.array([[np.cos(el_angle), np.sin(el_angle)],[np.sin(el_angle), -1*np.cos(el_angle)]])\n",
    "#     print(points.shape, R.shape)\n",
    "#     el_values = np.sum(np.square(np.einsum('ij, jk->ik', points-cent, R))/(1.96**2 * el_var)[np.newaxis,:], axis =1)\n",
    "#     print('in: %i, out: %i'%(np.sum(el_values<=1), np.sum(el_values>1)))\n",
    "#     inlier_mask = el_values <= 1\n",
    "#     projected = pca.transform(new_points)\n",
    "#     inlier_mask = np.logical_and(np.abs(projected[:,1]) < .5, np.abs(projected[:,0]) < 3)\n",
    "#     inlier_mask = new_points[:,1] <= np.median(np.abs(new_points[:,1]))\n",
    "\n",
    "\n",
    "\n",
    "    # plot using hex bin\n",
    "#     c_array = colors.ListedColormap(pltcolors[ss])(range(0,1000))\n",
    "#     c_array[:, -1]=np.arange(0,1,0.001)\n",
    "#     new_cmap = LinearSegmentedColormap.from_list(name = '%s_alpha'%pltcolors[ss], colors = c_array)\n",
    "#     plt.hexbin(vals_OI[str_idcs], SL_OI[str_idcs],\n",
    "#                 gridsize = 40, vmin =0, vmax = 200, cmap = new_cmap, edgecolors = 'none')\n",
    "    \n",
    "    # plot using 2d hist\n",
    "    c_array = colors.ListedColormap(pltcolors[ss])(range(0,1000))\n",
    "    c_array[:, -1]=np.arange(0,1,0.001)\n",
    "    new_cmap = LinearSegmentedColormap.from_list(name = '%s_alpha'%pltcolors[ss], colors = c_array)\n",
    "    hb=sp_ax.hist2d(x, y, 50, weights =np.ones_like(x)/float(len(x)), vmin = 0, vmax =0.008, cmap = new_cmap)\n",
    "    \n",
    "    # convex hull of all inlier points\n",
    "    hull = ConvexHull(np.vstack([y[inlier_mask],x[inlier_mask]]).T)\n",
    "    for simplex in hull.simplices:\n",
    "        plt.plot(x[inlier_mask][simplex], y[inlier_mask][simplex], 'k-')\n",
    "    \n",
    "    # plot cinnamon trials\n",
    "#     cin_df = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']=='Tunnel_20180329-30') &\n",
    "#                             ((all_strides['time'].map(lambda x: (int(x)>=90000) & (int(x[-3])%5-1<1))).values)]\n",
    "#     SL_OI = 1/cin_df['St_Dur_all'].values\n",
    "#     vals_OI = np.abs(cin_df['St_tdist_total'].values/cin_df['St_Dur_all'].values)\n",
    "#     str_idcs = np.abs(cin_df['St_travel_dir'])<angle_buffer\n",
    "#     plt.plot(vals_OI[str_idcs], SL_OI[str_idcs], '.k', alpha = 0.1, MarkerSize = 2)\n",
    "    \n",
    "    ### PLOT AESTHETICS\n",
    "    # plot aesthetics - stride frequency\n",
    "    plt.plot(np.arange(0,40), slope[ss]*np.arange(0,40)+intercept[ss], '--k')\n",
    "    plt.plot(np.arange(0,40), slope_origin*np.arange(0,40), ':k')\n",
    "    plt.plot(np.arange(0,40), slope[ss]*np.arange(0,40)+intercept[ss]+res_width[ss], '--k', alpha = 0.5)\n",
    "    plt.text(20, 30, 'n: %i'%len(x))\n",
    "    plt.text(20, 28, '%% disrupted:%0.1f'%(np.sum(disrupted_strides)/len(x)*100))\n",
    "    plt.text(20, 26, 'slope: %0.3f'%slope[ss])\n",
    "    plt.text(20, 24, 'intercept: %0.3f'%intercept[ss])\n",
    "    plt.text(20, 22, 'slope_orig: %0.3f'%slope_origin)\n",
    "    plt.xlim((0,40))\n",
    "    plt.ylim((0,30))\n",
    "\n",
    "    # plot aesthetics - stride length\n",
    "#     plt.plot(np.arange(0,40), slope[ss]*np.arange(0,40)+intercept[ss], '--k')\n",
    "#     plt.text(20, 4.5, 'n: %i'%len(x))\n",
    "#     plt.text(20, 4.2, 'slope: %0.2f'%slope[ss])\n",
    "#     plt.text(20, 3.9, 'intercept: %0.2f'%intercept[ss])\n",
    "#     plt.xlim((0,40))\n",
    "#     plt.ylim((0,5))\n",
    "    \n",
    "    \n",
    "    if ss==3:\n",
    "        ax=fig.add_axes([.93,.1,.02,.75])\n",
    "        fig.colorbar(hb[3], cax=ax)\n",
    "    fig.add_subplot(sp_ax)\n",
    "    \n",
    "#     if ss==2:\n",
    "#         cax = fig.add_axes([.93, .1, .02, .8])\n",
    "#         plt.colorbar(cax = cax, label = 'number of strides')\n",
    "        \n",
    "#         plt.figure()\n",
    "#         plt.subplot(1,2,1)\n",
    "#         inlier_mask = density[ss] > 0.005\n",
    "#         plt.plot(x[inlier_mask],y[inlier_mask],'.k', alpha = 0.02)\n",
    "#         plt.xlim((0,40))\n",
    "#         plt.ylim((0,5))\n",
    "#         plt.subplot(1,2,2)\n",
    "#         inlier_mask = density[ss] > 0.03\n",
    "#         plt.plot(x[inlier_mask],y[inlier_mask],'.k', alpha = 0.02)\n",
    "#         plt.xlim((0,40))\n",
    "#         plt.ylim((0,5))\n",
    "    \n",
    "    # FIT RANSAC REGRESSION - gets rid of outliers, not working great\n",
    "#     ransac = linear_model.RANSACRegressor(stop_probability = 0.995)\n",
    "#     ransac.fit(vals_OI[str_idcs][inlier_mask][:,np.newaxis], SL_OI[str_idcs][inlier_mask][:,np.newaxis])\n",
    "#     inlier_mask2 = ransac.inlier_mask_\n",
    "#     outlier_mask2 = np.logical_not(inlier_mask2)\n",
    "#     line_X = np.arange(0,40)[:, np.newaxis]\n",
    "#     line_y = ransac.predict(line_X)\n",
    "#     plt.plot(line_X, line_y, '--k')\n",
    "#     plt.plot(line_X, line_y+3, ':k', alpha = 0.5)\n",
    "#     plt.plot(line_X, line_y-3, ':k', alpha = 0.5)\n",
    "#     print(ransac.estimator_.coef_)\n",
    "#     plt.plot(vals_OI[str_idcs][inlier_mask], SL_OI[str_idcs][inlier_mask], '.', color = pltcolors[ss], alpha = 0.02)\n",
    "#     plt.plot(vals_OI[str_idcs][outlier_mask], SL_OI[str_idcs][outlier_mask], '.', color = 'k', alpha = 0.02)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# calculate if strides are disrupted based on stride length\n",
    "def calc_SF_disrupted_df(x, slope, intercept, res_width, r_cutoff = 4):\n",
    "    xs = x['St_tdist_total']/ x['St_Dur_all']\n",
    "    ys = 1/x['St_Dur_all']\n",
    "    \n",
    "    ss = np.where(np.array(['0mm','1mm','3mm','5mm'])==x['substrate'])[0][0]\n",
    "    \n",
    "    disrupted_strides = ys>(slope[ss]*xs+intercept[ss]+res_width[ss])\n",
    "    return disrupted_strides\n",
    "\n",
    "df['St_disrupted_SF']= df.apply(calc_SF_disrupted_df, args = (slope, intercept, res_width, 4), axis=1)\n",
    "    \n",
    "del x, y, xy_train, kde, inlier_mask, outlier_mask, SL_OI, vals_OI, str_idcs, disrupted_strides\n",
    "# del all_strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving disrupted stride data as feather for use in R\n",
      "Done saving\n"
     ]
    }
   ],
   "source": [
    "# save as feather for lme models in R\n",
    "import feather\n",
    "temp = df.copy()\n",
    "\n",
    "\n",
    "# look only at trials longer than 50fr\n",
    "idcs = [index for index, row in temp.iterrows() if len(row.St_disrupted_SF)>10]\n",
    "longtracks = df.loc[idcs,]\n",
    "# longtracks = longtracks.loc[(longtracks['colony']!=coltypes[-1])] # don't include cinnamon trial data\n",
    "longtracks = longtracks.loc[(longtracks['colony']==coltypes[-1])] # just cinnamon trial data\n",
    "\n",
    "# MEDIAN V\n",
    "colony_R = [col.split('20180')[-1][1:] for col in longtracks['colony'].values.tolist()]\n",
    "date_days = [col[-2:] for col in longtracks['date'].values.tolist()]\n",
    "day_R = [col.split('-').index(day) for day, col in zip(date_days, colony_R)]\n",
    "subs_string = longtracks['substrate'].values.tolist()\n",
    "substrate_R = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "v_med_R = np.array(longtracks['median_v'])/pix2mm\n",
    "n_disrupted_R = longtracks['St_disrupted_SF'].apply(lambda x: np.sum(x)).values\n",
    "n_strides_R = longtracks['St_disrupted_SF'].apply(lambda x: len(x)).values\n",
    "p_disrupted_R = longtracks['St_disrupted_SF'].apply(lambda x: np.sum(x)/len(x)).values\n",
    "df_med_R = pd.DataFrame( {\"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R,\n",
    "                       \"v_med\" : v_med_R, \"n_disrupted\": n_disrupted_R,\n",
    "                      \"n_strides\": n_strides_R, \"percent_disrupted\": p_disrupted_R  } )\n",
    "\n",
    "# SAVE AS FEATHER FOR USE WITH R\n",
    "print('Saving disrupted stride data as feather for use in R')\n",
    "# feather.write_dataframe(df_med_R, vid_locations + 'Disrupted_SF.feather')\n",
    "feather.write_dataframe(df_med_R, vid_locations + 'Disrupted_SF_cinnamon.feather')\n",
    "# testdf = feather.read_dataframe(vid_locations + 'Disrupted_SF.feather')\n",
    "print('Done saving')\n",
    "\n",
    "del idcs, colony_R, day_R, substrate_R, v_med_R, date_days, subs_string, temp, longtracks, n_disrupted_R\n",
    "del df_med_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST OUT KERNEL DENSITY\n",
    "plt.close('all')\n",
    "ss=0\n",
    "lens = [len(item) for item in df['St_Len_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values),\n",
    "                        \"time\" : np.repeat(df['time'].values, lens)})\n",
    "\n",
    "allsubs = [tr['substrate'] for tr in trial_info]\n",
    "subtypes = sorted(list(set(allsubs)))\n",
    "coltypes = sorted(list(set(df['colony'].values)))\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "angle_buffer = 15\n",
    "\n",
    "subtype = subtypes[0]\n",
    "density = {}\n",
    "    \n",
    "SL_OI = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Len_all'].values\n",
    "vals_OI = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_tdist_total'].values/\n",
    "           all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Dur_all'].values)\n",
    "str_idcs = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_travel_dir'])<angle_buffer\n",
    "del all_strides\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "x = vals_OI[str_idcs]\n",
    "y = SL_OI[str_idcs]\n",
    "\n",
    "\n",
    "xy_train = np.vstack([y,x]).T\n",
    "d = np.min(xy_train.shape) # number of dimensions\n",
    "n = np.max(xy_train.shape) # number of points\n",
    "bw_sil = (n*(d+2) / 4.) ** (-1./ (d +4)) # silverman - \"Density estimation for statistics and data analysis\" 1986\n",
    "bw_sco = n**(-1./(d+4)) # scott's - \"Multivariate density estimateion...\" 1992\n",
    "print('bandwidths (scott vs. silverman): %0.9f, %0.9f'%(bw_sco, bw_sil))\n",
    "kde = KernelDensity(bandwidth = bw_sco, kernel = 'gaussian')\n",
    "kde.fit(xy_train)\n",
    "density[ss] = np.exp(kde.score_samples(np.vstack([y,x]).T))\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(np.floor(x.min()),np.ceil(x.max()),1), np.arange(np.floor(y.min()),np.ceil(y.max()),0.1))\n",
    "xy_sample = np.vstack([yy.ravel(), xx.ravel()]).T\n",
    "zz = np.reshape(np.exp(kde.score_samples(xy_sample)), xx.shape)\n",
    "\n",
    "\n",
    "inlier_mask = density[ss] > 0.005\n",
    "# outlier_mask = np.logical_not(inlier_mask)\n",
    "# calc linear regression\n",
    "# slope, intercept, r_val, p_val, std_err = stats.linregress(vals_OI[str_idcs][inlier_mask], SL_OI[str_idcs][inlier_mask])\n",
    "\n",
    "plt.pcolormesh(xx,yy,zz)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.subplot(1,2,1)\n",
    "# inlier_mask = density[ss] > 0.005\n",
    "# plt.plot(x[inlier_mask],y[inlier_mask],'.k', alpha = 0.02)\n",
    "# plt.xlim((0,40))\n",
    "# plt.ylim((0,5))\n",
    "# plt.subplot(1,2,2)\n",
    "# inlier_mask = density[ss] > 0.1\n",
    "# plt.plot(x[inlier_mask],y[inlier_mask],'.k', alpha = 0.02)\n",
    "# plt.xlim((0,40))\n",
    "# plt.ylim((0,5))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(x, y, c=density[0], s = 2)#, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot speed vs. % disrupted for trials with many strides:\n",
    "from scipy.stats import poisson\n",
    "\n",
    "plt.close('all')\n",
    "# plt.figure()\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    plt.figure()\n",
    "    vals_OI = df.loc[(df['substrate']==subtype) & (df['colony']!=coltypes[-1])]['St_disrupted_SF'].apply(lambda x: np.sum(x)/len(x)).values\n",
    "    med_v = df.loc[(df['substrate']==subtype) & (df['colony']!=coltypes[-1])]['median_v'].values\n",
    "    n_strides = df.loc[(df['substrate']==subtype) & (df['colony']!=coltypes[-1])]['St_disrupted_SF'].apply(lambda x: len(x)).values\n",
    "    \n",
    "    glenna = vals_OI[n_strides>10]*100\n",
    "    print(np.mean(glenna))\n",
    "\n",
    "    plt.plot(vals_OI[n_strides>10], med_v[n_strides>10]/pix2mm, '.', color = pltcolors[ss], alpha = 0.05)\n",
    "    plt.xlabel('perecent of strides disrupted based on stride frequency')\n",
    "    plt.ylabel('median trackway speed (mm/s)')\n",
    "    plt.xlim([0, 0.7])\n",
    "    plt.ylim([0,35])\n",
    "    \n",
    "    print(stats.linregress(vals_OI[n_strides>10], med_v[n_strides>10]/pix2mm))\n",
    "#     plt.hist(vals_OI, bins=np.arange(0,0.52,0.02), range = (0,0.5), alpha = 0.2, color = pltcolors[ss], density = True)\n",
    "    \n",
    "#     for power_OI in [1,0.5,1/3]:\n",
    "#         dist_hist = np.histogram(np.power(vals_OI, power_OI), bins = np.arange(0,0.52,0.02), range = (0,0.5), density = True)[0]\n",
    "#         plt.plot(np.arange(0,0.5,0.02), dist_hist, '.', label = 'power %0.1f'%power_OI)\n",
    "\n",
    "#     resolution = 2\n",
    "\n",
    "#     dist_hist = np.histogram(glenna, bins = np.arange(0,50+resolution,resolution), range = (0,50), density = True)[0]\n",
    "#     plt.plot(np.arange(0,50,resolution), dist_hist, '.', label = 'raw hist')\n",
    "    \n",
    "    # get poisson from scipy to get expected probability density function\n",
    "#     pois_comp = poisson.pmf(np.arange(0,50,resolution), np.mean(glenna))\n",
    "#     plt.plot(np.arange(0,50,resolution), pois_comp, ':k', label = 'poisson L = %0.1f'%np.mean(glenna))\n",
    "    \n",
    "    \n",
    "    # log\n",
    "#     dist_hist = np.histogram(np.log(glenna*100), bins = np.arange(0,52,2), range = (0,0.5), density = True)[0]\n",
    "#     plt.plot(np.arange(0,50,2), dist_hist, '.', label = 'log')\n",
    "    plt.legend()\n",
    "    \n",
    "# del vals_OI, n_strides, med_v\n",
    "\n",
    "\n",
    "# # print info for some trials:\n",
    "# for tr in range(0,10):\n",
    "#     print('\\nTrial %i:')\n",
    "#     print('median v: %0.2f, %i/%i disrupted strides'%(df['median_v'][tr], np.sum(df['St_disrupted_SF'][tr]) , len(df['St_disrupted_SF'][tr])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import factorial\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "\n",
    "def poisson(k, lamb):\n",
    "    \"\"\"poisson pdf, parameter lamb is the fit parameter\"\"\"\n",
    "    return (lamb**k/factorial(k)) * np.exp(-lamb)\n",
    "\n",
    "\n",
    "def negLogLikelihood(params, data):\n",
    "    \"\"\" the negative log-Likelohood-Function\"\"\"\n",
    "    lnl = - np.sum(np.log(poisson(data, params[0])))\n",
    "    return lnl\n",
    "\n",
    "\n",
    "\n",
    "def negLogLikelihood_NB(params, data):\n",
    "    \"\"\" the negative log-Likelohood-Function\"\"\"\n",
    "    lnl = - np.sum(np.log(nbinom(params[0], params[1]).pmf(data)  ))\n",
    "    return lnl\n",
    "\n",
    "# def CMPoisson(k, lamb, decay):\n",
    "#     \"\"\"poisson pdf, parameter lamb is the fit parameter\"\"\"\n",
    "#     return (lamb**k/factorial(k)) * np.exp(-lamb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get poisson deviated random numbers\n",
    "data = glenna\n",
    "\n",
    "# # minimize the negative log-Likelihood\n",
    "# result = minimize(negLogLikelihood,  # function to minimize\n",
    "#                   x0=np.ones(1),     # start value\n",
    "#                   args=(data,),      # additional arguments for function\n",
    "#                   method='Powell',   # minimization method, see docs\n",
    "#                   )\n",
    "\n",
    "# minimize the negative log-Likelihood\n",
    "result = minimize(negLogLikelihood_NB,  # function to minimize\n",
    "                  x0=np.ones(1),     # start value\n",
    "                  args=(data,),      # additional arguments for function\n",
    "                  method='Powell',   # minimization method, see docs\n",
    "                  )\n",
    "\n",
    "# result is a scipy optimize result object, the fit parameters \n",
    "# are stored in result.x\n",
    "print(result)\n",
    "\n",
    "# plot poisson-deviation with fitted parameter\n",
    "x_plot = np.linspace(0, 50, 1000)\n",
    "\n",
    "plt.close('all')\n",
    "plt.hist(data, bins=np.arange(0,50,2) - 0.5, normed=True)\n",
    "plt.plot(x_plot, poisson(x_plot, result.x), 'r-', lw=2)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_params(mu, theta):\n",
    "    \"\"\"\n",
    "    Convert mean/dispersion parameterization of a negative binomial to the ones scipy supports\n",
    "\n",
    "    See https://en.wikipedia.org/wiki/Negative_binomial_distribution#Alternative_formulations\n",
    "    \"\"\"\n",
    "    var = mu + theta * mu ** 2\n",
    "    p = (var - mu) / var\n",
    "    return theta, 1 - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which limb most likely to have disrupted strides?\n",
    "all_strides[\"disrupted_strides\"] = np.concatenate(df['St_disrupted_SF'].values)\n",
    "\n",
    "\n",
    "temp=all_strides['Joints_all'][all_strides['disrupted_strides']]\n",
    "all_js = np.array([int(x[-1]) for x in temp])\n",
    "temp = all_strides['substrate'][all_strides['disrupted_strides']]\n",
    "all_ss = np.array([int(x[0]) for x in temp])\n",
    "\n",
    "disrupted_st_by_limb = np.full([6,4], np.nan)\n",
    "for s,ss in enumerate([0,1,3,5]):\n",
    "    for jj in range(0,6):\n",
    "        disrupted_st_by_limb[jj,s] = np.sum(np.logical_and(all_ss ==ss, all_js == jj))\n",
    "\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "plt.hist(clifton, bins= 6)\n",
    "plt.xlabel('joint num')\n",
    "plt.ylabel('# disrupted strides')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for s,ss in enumerate([0,1,3,5]):\n",
    "    for jj in range(0,3):\n",
    "        plt.plot([jj,jj], disrupted_st_by_limb[[jj,jj+3], s], '-', color = pltcolors[s])\n",
    "        plt.plot(jj, np.mean(disrupted_st_by_limb[[jj,jj+3], s]), '+', color = pltcolors[s])\n",
    "        plt.plot(jj, np.mean(disrupted_st_by_limb[[jj,jj+3], s]), 'o', color = pltcolors[s])\n",
    "plt.ylim([0,1500])\n",
    "plt.yticks([0,500,1000,1500])\n",
    "plt.text(0,1300, 'total n = %i'%np.sum(all_strides['disrupted_strides']) )\n",
    "    \n",
    "\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make video of sample disrupted strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for making video\n",
    "\n",
    "def load_video(raw_video_path, frame_range, verbose):\n",
    "    \"\"\"\n",
    "    Independent of the frame range loaded, background has to be computed over total video or else can run into\n",
    "    tracking problems\n",
    "    \"\"\"\n",
    "    vid = cv2.VideoCapture(raw_video_path)\n",
    "    Height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    NumFrames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if not (NumFrames > 0):\n",
    "        raise IOError('Codec issue: cannot read number of frames.')\n",
    "\n",
    "    # restrict to desired range of frames\n",
    "    if frame_range is None:\n",
    "        frame_range = (0, int(NumFrames))\n",
    "    else:\n",
    "        # check doesn't exceed number of frames\n",
    "        if frame_range[0] + frame_range[1] > NumFrames:\n",
    "            frame_range = (int(frame_range[0]), int(NumFrames - frame_range[0]))\n",
    "\n",
    "    # initialize blank frames\n",
    "    frames = np.zeros((frame_range[1], Height, Width), np.uint8)\n",
    "\n",
    "    # set the first frame to read in\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for kk in range(frame_range[0]):\n",
    "        tru, ret = vid.read(1)\n",
    "    # vid.set(cv.CAP_PROP_POS_FRAMES, frame) # this way of setting the frame doesn't work on all cv versions\n",
    "\n",
    "    # read in all frames\n",
    "    for kk in range(frame_range[1]):\n",
    "        tru, ret = vid.read(1)\n",
    "\n",
    "        # check if video frames are being loaded\n",
    "        if not tru:\n",
    "            raise IOError('Codec issue: cannot load frames.')\n",
    "        frames[kk, :, :] = ret[:, :, 0]  # assumes loading color\n",
    "        if ((kk % 100) == 0) and verbose:\n",
    "            print(kk)\n",
    "    return frames, NumFrames, frame_range, vid\n",
    "\n",
    "\n",
    "\n",
    "def WRTant_to_WRTframe(val_x, val_y, frame_center_x, frame_center_y, ant_ang_deg):\n",
    "    ant_ang = ant_ang_deg *np.pi/180\n",
    "    R = np.array([[np.cos(ant_ang), -1*np.sin(ant_ang)],\n",
    "                  [np.sin(ant_ang),    np.cos(ant_ang)]])\n",
    "    rotated_vals = np.dot(R,np.array([val_x-100,val_y-100]))\n",
    "    translated_vals = rotated_vals*np.array([1,1]) + np.array([frame_center_x, frame_center_y])  \n",
    "    return translated_vals[0], translated_vals[1];\n",
    "\n",
    "def plot_ant_pt(ant_part, ant_part_num, filt, df, tr_num, idx, ant_x, ant_y, ant_ang_deg, buffer): #filt = '' if want raw data\n",
    "    x = df['%s%s_x%s'%(ant_part,str(ant_part_num),filt)][tr_num][idx]\n",
    "    y = df['%s%s_y%s'%(ant_part,str(ant_part_num),filt)][tr_num][idx]\n",
    "    conf = df['%s%s_conf'%(ant_part,str(ant_part_num))][tr_num][idx]\n",
    "#     (newx, newy)= (x,y)\n",
    "    (newx, newy) = WRTant_to_WRTframe(x, y, ant_x, ant_y, ant_ang_deg)\n",
    "#     print('old vals: %i, %i  TO %0.1f, %0.1f'%(x,y,newx, newy))\n",
    "\n",
    "    if ('joint' in ant_part) or ('antenna' in ant_part):\n",
    "        if '_filt' in filt:\n",
    "            \n",
    "            # plot strides and touchdowns\n",
    "            if 'joint%i_TD_idcs'%ant_part_num in df:\n",
    "                if idx in df['joint%i_TD_idcs'%ant_part_num][tr_num][df['joint%i_good_TDs'%ant_part_num][tr_num]]:\n",
    "#                     print('Joint %i -- Fr %i'%(ant_part_num, idx))\n",
    "                    sca = plt.scatter(newx+buffer, newy+buffer, s = 10, facecolor = 'none', edgecolor = 'w')\n",
    "                dur_starts = df['joint%i_TD_idcs'%ant_part_num][tr_num][:-1][df['joint%i_good_strides'%ant_part_num][tr_num]]\n",
    "                dur_stops = df['joint%i_TD_idcs'%ant_part_num][tr_num][1:][df['joint%i_good_strides'%ant_part_num][tr_num]]\n",
    "                if np.any(np.logical_and( ff>dur_starts, ff<dur_stops)):\n",
    "                    str_OI = dur_starts[ np.logical_and( ff>dur_starts, ff<dur_stops)]\n",
    "                    plt.plot([df['joint%i_x_filt_fullfr'%ant_part_num][tr_num][str_OI]+buffer, newx+buffer],\n",
    "                             [df['joint%i_y_filt_fullfr'%ant_part_num][tr_num][str_OI]+buffer, newy+buffer], '-w', alpha = 0.2)\n",
    "                \n",
    "            # plot actual feet points\n",
    "            if ant_part_num < 3:\n",
    "                sca = plt.scatter(newx+buffer, newy+buffer, c = 'c', s = 10, edgecolor = 'none')# '.g')\n",
    "            else:\n",
    "                sca = plt.scatter(newx+buffer, newy+buffer, c = 'm', s = 10, edgecolor = 'none')\n",
    "#             if ('joint' in ant_part):\n",
    "#                 if df['frames_final'][tr_num][fr_num] in df['%s%i_TD_frs'%(ant_part, ant_part_num)][tr_num]:\n",
    "#                     sca.set_edgecolor('w')\n",
    "        else:\n",
    "            # define colormap to show confidence\n",
    "            norm2 = colors.Normalize(vmin=0, vmax=1)\n",
    "            plt.scatter(newx+buffer, newy+buffer, c = conf, s = 10, cmap = cm.bwr,\n",
    "                       edgecolor = 'none', norm=norm2)# '.g')\n",
    "    else:\n",
    "        plt.scatter(newx+buffer, newy+buffer, c = 'w', s = 10, edgecolor = 'none')\n",
    "        \n",
    "    return;\n",
    "\n",
    "\n",
    "def crop_to_view(variable_to_use, tr_num, fr, x_dim, y_dim, buffer, axisOI):\n",
    "    x = df[variable_to_use%'x'][tr_num][fr]\n",
    "    y = df[variable_to_use%'y'][tr_num][fr]\n",
    "    xrange = range(int(round(x)), int(round(x+2*buffer)))\n",
    "    yrange = range(int(round(y)), int(round(y+2*buffer)))\n",
    "    # account for if range goes outside of video frame\n",
    "    xrange_actual = np.array(sorted(list( set(xrange) & set(range(0, x_dim+2*buffer) ) )))[[0,-1]]\n",
    "    yrange_actual = np.array(sorted(list( set(yrange) & set(range(0, y_dim+2*buffer) ) )))[[0,-1]]\n",
    "    plt.sca(axisOI)\n",
    "    plt.xlim(xrange_actual)\n",
    "    plt.ylim(yrange_actual)\n",
    "    \n",
    "    return xrange_actual, yrange_actual\n",
    "\n",
    "\n",
    "def save_image(vlocation, nfig, name_base):\n",
    "    pname = os.path.join(vlocation, '%s%d.png'%(name_base,nfig))\n",
    "    plt.savefig(pname)\n",
    "    nfig = nfig + 1\n",
    "    plt.pause(0.2)\n",
    "#     plt.close('all')\n",
    "    return nfig\n",
    "\n",
    "\n",
    "def save_video(vlocation, name_base):\n",
    "    # save images as movie\n",
    "    if os.path.isfile((vlocation+'/%s.mp4'%name_base)):\n",
    "        os.remove(vlocation + \"/%s.mp4\"%name_base)\n",
    "        print('** Deleted %s.mp4 file'%name_base)\n",
    "    print('saving %s.mp4 file'%name_base)\n",
    "    command_p1 = \"ffmpeg -r 10 -i '%s/%s\"%(vlocation, name_base)\n",
    "    command_p2 = \" -vcodec libx264 '%s/%s.mp4'\"%(vlocation, name_base)\n",
    "    command = command_p1 + \"%01d.png'\" + command_p2\n",
    "#     print(command)\n",
    "    os.system(command)\n",
    "    plt.pause(10)\n",
    "\n",
    "    # delete all trackway vids\n",
    "    pics2delete = glob.glob(os.path.join(vlocation, '%s*.png'%name_base))\n",
    "    for pic in pics2delete:\n",
    "        os.remove(pic)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/3mm/20180313_093328_16276718-0000.mp4\n",
      "    806 -- stride OI: 14, joint 3, starting fr 203\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/3mm/20180313_101847_16276718-0000.mp4\n",
      "    835 -- stride OI: 33, joint 4, starting fr 134\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/5mm/20180313_093139_16276735-0000.mp4\n",
      "    1213 -- stride OI: 4, joint 1, starting fr 123\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/5mm/20180313_094113_16276735-0000.mp4\n",
      "    1220 -- stride OI: 3, joint 0, starting fr 438\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/5mm/20180313_101212_16276735-0000.mp4\n",
      "    1244 -- stride OI: 1, joint 0, starting fr 292\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/5mm/20180313_105741_16276735-0000.mp4\n",
      "    1298 -- stride OI: 18, joint 2, starting fr 407\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180320-21/0mm/20180320_092017_16276712-0000.mp4\n",
      "    2761 -- stride OI: 1, joint 0, starting fr 541\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180320-21/0mm/20180320_114509_16276712-0000.mp4\n",
      "    2857 -- stride OI: 3, joint 0, starting fr 166\n",
      "    2857 -- stride OI: 49, joint 5, starting fr 371\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180320-21/0mm/20180320_114509_16276712-0000.mp4\n",
      "    2857 -- stride OI: 3, joint 0, starting fr 166\n",
      "    2857 -- stride OI: 49, joint 5, starting fr 371\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180320-21/3mm/20180320_092444_16276718-0000.mp4\n",
      "    3438 -- stride OI: 2, joint 0, starting fr 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180320-21/3mm/20180321_100640_16276718-0000.mp4\n",
      "    3606 -- stride OI: 17, joint 3, starting fr 120\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180320-21/5mm/20180321_085929_16276736-0000.mp4\n",
      "    3912 -- stride OI: 11, joint 5, starting fr 6\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180322-23/1mm/20180322_093612_16276712-0000.mp4\n",
      "    4416 -- stride OI: 11, joint 3, starting fr 152\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180322-23/3mm/20180322_091855_16276735-0000.mp4\n",
      "    5025 -- stride OI: 2, joint 2, starting fr 0\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180322-23/3mm/20180322_093913_16276735-0000.mp4\n",
      "    5089 -- stride OI: 14, joint 5, starting fr 57\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180322-23/3mm/20180323_115050_16276735-0000.mp4\n",
      "    5768 -- stride OI: 36, joint 3, starting fr 301\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180324-25/5mm/20180324_093030_16276712-0000.mp4\n",
      "    7999 -- stride OI: 7, joint 5, starting fr 524\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180508-09/1mm/20180508_100810_16276718-0000.mp4\n",
      "    10925 -- stride OI: 2, joint 2, starting fr 639\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180508-09/3mm/20180508_081341_16276736-0000.mp4\n",
      "    11216 -- stride OI: 2, joint 1, starting fr 147\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180508-09/3mm/20180508_082730_16276736-0000.mp4\n",
      "    11239 -- stride OI: 11, joint 2, starting fr 210\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180508-09/3mm/20180508_103505_16276736-0000.mp4\n",
      "    11318 -- stride OI: 5, joint 2, starting fr 548\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180508-09/3mm/20180508_114014_16276736-0000.mp4\n",
      "    11378 -- stride OI: 16, joint 3, starting fr 251\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180508-09/3mm/20180509_081630_16276736-0000.mp4\n",
      "    11409 -- stride OI: 0, joint 0, starting fr 9\n",
      "saving Disrupted_Strides_vid.mp4 file\n"
     ]
    }
   ],
   "source": [
    "# plot images with tracked data and lowpass filtered data\n",
    "\n",
    "buffer = 150\n",
    "limbs = ['LH','LM','LF', 'RH', 'RM', 'RF']\n",
    "vlocation = '/media/gravishlab/SeagateExpansionDrive/AntTrack'\n",
    "\n",
    "#where are disrupted stides\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "im_n = 0\n",
    "\n",
    "# FOR DISRUPTED STRIDES\n",
    "# for tt in np.arange(0,20):\n",
    "#     tr_num = random.randint(0,len(df))\n",
    "\n",
    "# FOR WEIRDLY LONG STRIDE DISTANCE\n",
    "for tr_num in all_strides.loc[all_strides['St_tdist_total']>4]['trackway'].values:\n",
    "\n",
    "\n",
    "    videofile = df.video[tr_num]\n",
    "    print(videofile)\n",
    "    \n",
    "#     for st in np.where(df['St_disrupted_SF'][tr_num])[0]: # look at disrupted strides\n",
    "    for st in np.where(df['St_tdist_total'][tr_num]>4)[0]: # look at long strides\n",
    "        \n",
    "        frame_range =[df['St_start'][tr_num][st]-20 , \n",
    "                      df['St_stop'][tr_num][st]+20 ]\n",
    "        if frame_range[0]<np.min(df['frames'][tr_num]):\n",
    "            frame_range[0] = int(np.min(df['frames'][tr_num]))\n",
    "        if frame_range[1]>np.max(df['frames'][tr_num]):\n",
    "            frame_range[1] = int(np.max(df['frames'][tr_num]))\n",
    "        joint_OI = int(df['St_jointID'][tr_num][st][-1])\n",
    "        print('    %i -- stride OI: %i, joint %i, starting fr %i'%(tr_num, st, joint_OI, frame_range[0]))\n",
    "\n",
    "        frames, NumFrames, _, vid = load_video(videofile, frame_range, verbose = False)\n",
    "        \n",
    "\n",
    "        for ff, fr_OI in  enumerate(np.arange(frame_range[0], frame_range[1])):\n",
    "            fr_id = np.where(df['frames'][tr_num] == fr_OI)[0][0]\n",
    "\n",
    "\n",
    "            plt.clf()\n",
    "            # load frame\n",
    "            x_dim = frames.shape[2]\n",
    "            y_dim = frames.shape[1]\n",
    "            frame = np.stack((frames[ff,:,:],)*3,-1)\n",
    "\n",
    "            # RAW IMAGE WITH FILTERED DATA\n",
    "            ax3=fig.add_axes([0.1,0.1, 0.8, 0.8]) #plt.axes()\n",
    "            black_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer,3),dtype=np.uint8)* 1# 1.001# np.max(temp) # gray background  1.0001#\n",
    "            bframe = black_frame.copy()\n",
    "            bframe[buffer:-buffer, buffer:-buffer,:] = frame\n",
    "            plt.imshow(bframe)\n",
    "            xrange_actual, yrange_actual = crop_to_view('%s_raw', tr_num, fr_id, x_dim, y_dim, buffer, ax3)\n",
    "            plt.text(xrange_actual[0]+10, yrange_actual[1]-20, 'Fr: %i'%fr_OI, color= 'w')\n",
    "            plt.text(xrange_actual[0]+10, yrange_actual[1]-30, 'Joint OI: %i'%joint_OI, color= 'w')\n",
    "            ss= np.where(np.array([0,1,3,5])==int(df['substrate'][tr_num][0]))[0]\n",
    "            st_resid = (1/df['St_Dur_all'][tr_num][st] - (slope[ss]*df['St_tdist_total'][tr_num][st]/ df['St_Dur_all'][tr_num][st]+intercept[ss]))/(res_width[ss]/4)\n",
    "            plt.text(xrange_actual[0]+10, yrange_actual[0]+40, 'Residual = %0.2f stdevs'%st_resid, color= 'w')\n",
    "                \n",
    "            # plot text and foot data if during disrupted stride\n",
    "            if np.logical_and(fr_OI >= df['St_start'][tr_num][st], fr_OI <= df['St_stop'][tr_num][st] ):\n",
    "                plt.text(xrange_actual[0]+10, yrange_actual[0]+30, 'Disrupted Stride', color= 'r')\n",
    "                plt.plot(df['joint%i_x_filt_fullfr'%joint_OI][tr_num][fr_id]+buffer, df['joint%i_y_filt_fullfr'%joint_OI][tr_num][fr_id]+buffer, '.r')\n",
    "            else:\n",
    "                plt.scatter(df['joint%i_x_filt_fullfr'%joint_OI][tr_num][fr_id]+buffer, df['joint%i_y_filt_fullfr'%joint_OI][tr_num][fr_id]+buffer, \n",
    "                            s = 40, facecolors='none', edgecolors = 'w')\n",
    "\n",
    "            titleparts = videofile.split('/')\n",
    "            plt.suptitle( 'Tr: %i -- %s -- %s -- %s'\n",
    "                  %(tr_num, titleparts[-2], titleparts[-1].split('_')[0], titleparts[-1].split('_')[1]),x=0.02, y=.95, horizontalalignment = 'left')\n",
    "            plt.gca().invert_yaxis()\n",
    "\n",
    "            plt.pause(0.1)\n",
    "            save_image(vlocation, im_n, 'Disrupted_Strides_vid')\n",
    "            im_n = im_n+1\n",
    "save_video(vlocation, 'Disrupted_Strides_vid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=0\n",
    "n_st = len(df['St_jointID'][tr_num])\n",
    "np.reshape(np.vstack([df['St_jointID'][tr_num], df['St_start'][tr_num], df['St_Dur_all'][tr_num], \n",
    "                     1/df['St_Dur_all'][tr_num], slope[ss]*df['St_tdist_total'][tr_num]/ df['St_Dur_all'][tr_num]+intercept[ss]+res_width[ss]]).T, (n_st,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot travel dist vs. stride length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "lens = [len(item) for item in df['St_Len_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_start\" : np.concatenate(df['St_start'].values), \"St_stop\" : np.concatenate(df['St_stop'].values),    \n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values),\n",
    "                        \"time\" : np.repeat(df['time'].values, lens), \"date\" : np.repeat(df['date'].values, lens)})\n",
    "\n",
    "\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    plt.figure(1)\n",
    "    sp_ax=plt.subplot(1,4, ss+1)\n",
    "    \n",
    "    # FOR STRIDE FREQUENCY! - SPECIFY IF FOR ALL STRIDES OR JUST STRAIGHT ONES\n",
    "    SL_OI = all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_Len_all'].values\n",
    "    vals_OI = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_tdist_total'].values)\n",
    "#     str_idcs = np.isfinite(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_travel_dir'])\n",
    "    str_idcs = np.abs(all_strides.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!=coltypes[-1])]['St_travel_dir'])<angle_buffer # only straight strides\n",
    "    d_cutoff = 0.005 # stride duration\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    if ss == 0:\n",
    "        plt.ylabel('foot stride len (mm)')\n",
    "        plt.xlabel('body stride length (mm)')\n",
    "    else:\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "    x = vals_OI[str_idcs]\n",
    "    y = SL_OI[str_idcs]\n",
    "    no_nan_pts = np.logical_and(np.isfinite(x), np.isfinite(y))\n",
    "    x = x[no_nan_pts]\n",
    "    y = y[no_nan_pts]            \n",
    "    # plot using 2d hist\n",
    "    c_array = colors.ListedColormap(pltcolors[ss])(range(0,1000))\n",
    "    c_array[:, -1]=np.arange(0,1,0.001)\n",
    "    new_cmap = LinearSegmentedColormap.from_list(name = '%s_alpha'%pltcolors[ss], colors = c_array)\n",
    "    hb=sp_ax.hist2d(x, y, 50, weights =np.ones_like(x)/float(len(x)), vmin = 0, vmax =0.008, cmap = new_cmap)\n",
    "    \n",
    "    \n",
    "    plt.title('%s'%subtype, loc = 'left')\n",
    "    plt.ylim([0,5])\n",
    "    plt.xlim([0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving disrupted stride data as feather for use in R\n",
      "Done saving\n"
     ]
    }
   ],
   "source": [
    "# save body and foot stride distance data as feather for stats modeling in R\n",
    "\n",
    "temp = all_strides.copy()\n",
    "longtracks = temp.loc[(temp['colony']!=coltypes[-1])] # don't include cinnamon trial data\n",
    "# longtracks = longtracks.loc[(longtracks['colony']==coltypes[-1])] # just cinnamon trial data\n",
    "\n",
    "# Get variables ready for R\n",
    "colony_R = [col.split('20180')[-1][1:] for col in longtracks['colony'].values.tolist()]\n",
    "date_days = [col[-2:] for col in longtracks['date'].values.tolist()]\n",
    "day_R = [col.split('-').index(day) for day, col in zip(date_days, colony_R)]\n",
    "subs_string = longtracks['substrate'].values.tolist()\n",
    "substrate_R = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "b_SLen_R = np.array(longtracks['St_tdist_total'])\n",
    "f_SLen_R = np.array(longtracks['St_Len_all'])\n",
    "f_SDur_R = np.array(longtracks['St_Dur_all'])\n",
    "\n",
    "df_med_R = pd.DataFrame( {\"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R,\n",
    "                       \"body_len\" : b_SLen_R, \"foot_len\": f_SLen_R,\n",
    "                      \"foot_dur\": f_SDur_R  } )\n",
    "\n",
    "# SAVE AS FEATHER FOR USE WITH R\n",
    "print('Saving disrupted stride data as feather for use in R')\n",
    "feather.write_dataframe(df_med_R, vid_locations + 'Body_distance.feather')\n",
    "print('Done saving')\n",
    "\n",
    "del colony_R, day_R, substrate_R, date_days, subs_string, temp, longtracks\n",
    "del df_med_R, b_SLen_R, f_SLen_R, f_SDur_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save stride speed vs. foot placement data for analysis in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done calculating average foot displacment for each limb\n",
      "compiled foot displacements for all limbs\n"
     ]
    }
   ],
   "source": [
    "# calculate average foot displacement for TDs bookending each stride\n",
    "def find_foot_disp_df(x, part, flat_XY):\n",
    "    j = int(part[-1])\n",
    "    all_x = x['%s_x_filt_WRTneck'%part]\n",
    "    all_y = x['%s_y_filt_WRTneck'%part]\n",
    "    d_x_1 = all_x[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]]-flat_XY[0][j] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    d_y_1 = all_y[x['%s_TD_idcs'%part][:-1][x['%s_good_strides'%part]]]-flat_XY[1][j]\n",
    "#     d_x_2 = all_x[x['%s_TD_idcs'%part][1:][x['%s_good_strides'%part]]]-flat_XY[0][j] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "#     d_y_2 = all_y[x['%s_TD_idcs'%part][1:][x['%s_good_strides'%part]]]-flat_XY[1][j]\n",
    "#     disp_pix = np.mean([np.linalg.norm([d_x_1,d_y_1],axis=0), np.linalg.norm([d_x_2,d_y_2],axis=0)],axis=0) # can take average or sum\n",
    "#     return disp_pix\n",
    "    return np.linalg.norm([d_x_1,d_y_1],axis=0)\n",
    "\n",
    "for joint_num in range(0,6):\n",
    "    df['joint%i_St_foot_disp'%joint_num]= df.apply(find_foot_disp_df, args = ('joint%i'%joint_num, flat_XY), axis=1)\n",
    "print('done calculating average foot displacment for each limb')\n",
    "\n",
    "df['St_foot_disp'] = df.filter(regex='_St_foot_disp$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "print('compiled foot displacements for all limbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe for R and save as a feather\n",
    "\n",
    "# compile dataframe of all strides\n",
    "lens = [sum(item<=15) for item in df['St_travel_dir']]\n",
    "all_St_disp = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"date\" : np.repeat(df['date'].values, lens), \n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values)[np.concatenate(df['St_travel_dir'].values)<=15],\n",
    "                        \"St_Dur_all\": np.concatenate(df['St_Dur_all'].values)[np.concatenate(df['St_travel_dir'].values)<=15],\n",
    "                        \"St_Len_all\": np.concatenate(df['St_Len_all'].values)[np.concatenate(df['St_travel_dir'].values)<=15],     \n",
    "                        \"St_foot_disp\" : np.concatenate(df['St_foot_disp'].values)[np.concatenate(df['St_travel_dir'].values)<=15]/pix2mm, # in mm\n",
    "                        \"St_tdist_total_v\" : (np.concatenate(df['St_tdist_total'].values)/np.concatenate(df['St_Dur_all'].values))[np.concatenate(df['St_travel_dir'].values)<=15], # in mm/s\n",
    "                        })\n",
    "print('done compiling all straight strides into dataframe')\n",
    "\n",
    "\n",
    "# save as feather for lme models in R\n",
    "import feather\n",
    "\n",
    "# MEDIAN V\n",
    "colony_R = [col.split('20180')[-1][1:] for col in all_St_disp['colony'].values.tolist()]\n",
    "date_days = [col[-2:] for col in all_St_disp['date'].values.tolist()]\n",
    "day_R = [col.split('-').index(day) for day, col in zip(date_days, colony_R)]\n",
    "subs_string = all_St_disp['substrate'].values.tolist()\n",
    "substrate_R = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "v_R = np.array(all_St_disp['St_tdist_total_v'])\n",
    "foot_disp_R = all_St_disp['St_foot_disp']\n",
    "dur_R = all_St_disp['St_Dur_all']\n",
    "len_R = all_St_disp['St_Len_all']\n",
    "dist_R = all_St_disp['St_tdist_total']\n",
    "df_med_R = pd.DataFrame( { \"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R, \"trackway\": all_St_disp['trackway'],\n",
    "                       \"v\" : v_R, \"foot_displacement\": foot_disp_R, \"stride_dist\": dist_R, \"stride_dur\": dur_R, \"stride_len\": len_R } )\n",
    "print('%i strides in dataframe for analysis in R'%len(df_med_R))\n",
    "\n",
    "# SAVE AS FEATHER FOR USE WITH R\n",
    "print('\\nSaving disrupted stride data as feather for use in R')\n",
    "feather.write_dataframe(df_med_R, vid_locations + 'Foot_Displacement.feather')\n",
    "print('Done saving')\n",
    "\n",
    "# del colony_R, day_R, substrate_R, v_R, date_days, subs_string, all_St_disp, foot_disp_R, lens\n",
    "del df_med_R, dist_R, dur_R, len_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D scatter of duration, length and distance traveled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D scatter of St duration vs. St length vs. dist traveled\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.close('all')\n",
    "pix2mm = 1000/32\n",
    "fps = 240\n",
    "df['St_Len_all'] = df.filter(regex='_St_Len$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1) # in mm\n",
    "df['St_Dur_all'] = df.filter(regex='St_Dur$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/fps, axis = 1) # in sec\n",
    "df['St_tdist_total'] = df.filter(regex='_St_tdist_total$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_tdist_straight'] = df.filter(regex='_St_tdist_straight$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0))/pix2mm, axis = 1)\n",
    "df['St_rotation'] = df.filter(regex='_St_rotation$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_travel_dir'] = df.filter(regex='_St_travel_dir$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['St_jointID'] = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: np.sum(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "\n",
    "lens = [len(item) for item in df['StLen_all']]\n",
    "all_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"Joints_all\" : np.concatenate(df['St_jointID'].values),\n",
    "                        \"St_Len_all\" : np.concatenate(df['St_Len_all'].values), \"St_Dur_all\" : np.concatenate(df['St_Dur_all'].values),\n",
    "                        \"St_tdist_total\" : np.concatenate(df['St_tdist_total'].values), \"St_tdist_straight\" : np.concatenate(df['St_tdist_straight'].values), \n",
    "                        \"St_rotation\" : np.concatenate(df['St_rotation'].values), \"St_travel_dir\" : np.concatenate(df['St_travel_dir'].values) })\n",
    "\n",
    "def save_image(vlocation, nfig, name_base):\n",
    "    pname = os.path.join(vlocation, '%s%d.png'%(name_base,nfig))\n",
    "    plt.savefig(pname)\n",
    "    nfig = nfig + 1\n",
    "    plt.pause(0.2)\n",
    "#     plt.close('all')\n",
    "    return nfig\n",
    "\n",
    "def save_video(vlocation, name_base):\n",
    "    # save images as movie\n",
    "    if os.path.isfile((vlocation+'/%s.mp4'%name_base)):\n",
    "        os.remove(vlocation + \"/%s.mp4\"%name_base)\n",
    "        print('** Deleted %s.mp4 file'%name_base)\n",
    "    print('saving %s.mp4 file'%name_base)\n",
    "    command_p1 = \"ffmpeg -r 4 -i '%s/%s\"%(vlocation, name_base)\n",
    "    command_p2 = \" -vcodec libx264 '%s/%s.mp4'\"%(vlocation, name_base)\n",
    "    command = command_p1 + \"%01d.png'\" + command_p2\n",
    "#     print(command)\n",
    "#     os.system(command)\n",
    "    call(command, shell = True)\n",
    "    plt.pause(15)\n",
    "\n",
    "    # delete all trackway vids\n",
    "    pics2delete = glob.glob(os.path.join(vlocation, '%s*.png'%name_base))\n",
    "    for pic in pics2delete:\n",
    "        os.remove(pic)\n",
    "    return\n",
    "\n",
    "def save_gif(vlocation, name_base):\n",
    "    if os.path.isfile((vlocation+'/%s.gif'%name_base)):\n",
    "        os.remove(vlocation + \"/%s.gif\"%name_base)\n",
    "        print('** Deleted %s.gif file'%name_base)\n",
    "    command_p1 = \"ffmpeg -i '%s/%s.mp4'\"%(vlocation, name_base)\n",
    "    command_p2 = \" -filter_complex '[0:v] fps=5,split[a][b];[a] palettegen [p];[b][p] paletteuse' '%s/%s.gif'\"%(vlocation, name_base) # - gif\n",
    "    command = command_p1 + command_p2\n",
    "    print('saving gif')\n",
    "#     os.system(command)\n",
    "    call(command, shell = True)\n",
    "    plt.pause(2)\n",
    "    return\n",
    "\n",
    "\n",
    "########## WHAT VARIABLES TO USE #############\n",
    "y_var = 'frequency'\n",
    "z_var = 'speed'\n",
    "##############################################\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (15,4))\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    ax=fig.add_subplot(140+ss+1, projection='3d')\n",
    "    \n",
    "    if z_var == 'speed':\n",
    "        z =np.abs(all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_total'].values/\n",
    "               all_strides.loc[(all_strides['substrate']==subtype)]['St_Dur_all'].values)\n",
    "        norm = colors.Normalize(vmin=0, vmax=40)\n",
    "        ax.set_zlim((0,50))\n",
    "        ax.set_zticklabels([0,'',20,'',40, ''])\n",
    "        ax.set_zlabel('body speed (mm/s)')\n",
    "    elif z_var == 'distance':\n",
    "        z =np.abs(all_strides.loc[(all_strides['substrate']==subtype)]['St_tdist_total'].values)\n",
    "        norm = colors.Normalize(vmin=0, vmax=5)\n",
    "        ax.set_zlim((0,5))\n",
    "        ax.set_zticklabels([0,'',2,'',4, ''])\n",
    "        ax.set_zlabel('dist. traveled (mm)')\n",
    "    else:\n",
    "        print('z variable specified is not recognized')\n",
    "        break\n",
    "        \n",
    "        \n",
    "    if y_var == 'duration':\n",
    "        y =all_strides.loc[(all_strides['substrate']==subtype)]['St_Dur_all'].values\n",
    "        ax.set_ylim((0,1))\n",
    "        ax.set_yticks(np.linspace(0,1,5))\n",
    "        ax.set_yticklabels([0,'',0.5,'',1])\n",
    "        ax.set_ylabel('stride dur (s)')\n",
    "    elif y_var == 'frequency':\n",
    "        y =1/all_strides.loc[(all_strides['substrate']==subtype)]['St_Dur_all'].values\n",
    "        ax.set_ylim((0,40))\n",
    "        ax.set_yticks(np.linspace(0,40,5))\n",
    "        ax.set_yticklabels([0,'',20,'',40])\n",
    "        ax.set_ylabel('stride fq (Hz)')\n",
    "    else:\n",
    "        print('y variable specified is not recognized')\n",
    "        break\n",
    "\n",
    "\n",
    "    x =all_strides.loc[(all_strides['substrate']==subtype)]['St_Len_all'].values\n",
    "    str_idcs = np.abs(all_strides.loc[(all_strides['substrate']==subtype)]['St_travel_dir'])<angle_buffer\n",
    "    ax.scatter(x[str_idcs], y[str_idcs], z[str_idcs], c=z[str_idcs], marker='.', alpha = 0.02, norm = norm )\n",
    "    ax.set_xlim((0,4))\n",
    "    ax.set_xticklabels([0,'',2,'',4])\n",
    "    ax.set_xlabel('stride len (mm)')\n",
    "    ax.plot(x[str_idcs],z[str_idcs], '.', c = [0.6,0.6,0.6], zdir = 'y', zs = ax.get_ylim()[1], alpha = 0.002)\n",
    "    ax.plot(y[str_idcs],z[str_idcs], '.', c = [0.6,0.6,0.6], zdir = 'x', zs = ax.get_xlim()[1], alpha = 0.002)\n",
    "    plt.show()\n",
    "\n",
    "del all_strides, x, y, z\n",
    "    \n",
    "save_location = '/media/gravishlab/SeagateExpansionDrive/AntTrack'\n",
    "name_base = '3D_%s_%s'%(y_var, z_var)\n",
    "print(name_base)\n",
    "for nfig, ang in enumerate(range(-175, -90, 2)):\n",
    "#     print(ang)\n",
    "    for ax in fig.get_axes():\n",
    "#         print(ss)\n",
    "        ax.view_init(20,ang)\n",
    "    plt.show()\n",
    "    plt.pause(0.2)\n",
    "    \n",
    "    save_image(save_location, nfig, name_base)\n",
    "    \n",
    "save_video(save_location,name_base)\n",
    "save_gif(save_location,name_base)\n",
    "\n",
    "del ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "done analyzing\n",
      "calculating disrupted sequential strides for each trial\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "# FIND SEQUENTIAL STRIDES AND PLOT:\n",
    "# -- ALL STRIDE PARAMETERS ON ONE PLOT\n",
    "# -- ONLY TOTAL STRIDE DISTANCE\n",
    "# -- QUIVER PLOT FOR FACING ROTATION VS. TRAVEL DIRECTION\n",
    "from matplotlib.colors import LogNorm\n",
    "plt.close('all')\n",
    "\n",
    "def find_sequential_strides_df(x, joint_num, parameter): #'rotation', 'Len', 'Dur', 'travel_dir'\n",
    "    arr = x['joint%s_St_%s'%(joint_num, parameter)]\n",
    "    good_st = x['joint%s_good_strides'%joint_num]\n",
    "    idcs = range(len(good_st))\n",
    "    st_idcs = np.cumsum(good_st)-1\n",
    "    st_len_groups  = [arr[st_idcs[np.array(list(g))]] for k,g in groupby(iter(idcs), lambda x: good_st[x]) if k == True]\n",
    "    arr_0 = [g[:-1] for g in st_len_groups if len(g)>1]\n",
    "    arr_1 = [g[1:] for g in st_len_groups if len(g)>1]\n",
    "    if len(arr_0)>0:\n",
    "        arr_0 = np.concatenate(arr_0)\n",
    "        arr_1 = np.concatenate(arr_1)\n",
    "    return arr_0, arr_1\n",
    "\n",
    "\n",
    "# for parameter  in ['Len', 'Dur', 'tdist_total', 'travel_dir', 'rotation']:\n",
    "#     print(parameter)\n",
    "#     # for each joint, find the 1st (0) and 2nd (1) parameter values for sequential strides\n",
    "#     for joint_num in range(0,6):\n",
    "#         df['joint%s_SeqSt0_%s'%(joint_num, parameter)], df['joint%s_SeqSt1_%s'%(joint_num, parameter)]= \\\n",
    "#             zip(*df.apply(find_sequential_strides_df, args = (joint_num, parameter), axis=1))\n",
    "#     # combine all joints\n",
    "#     df['SeqSt0_%s'%parameter] = df.filter(regex='_SeqSt0_%s$'%parameter, axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "#     df['SeqSt1_%s'%parameter] = df.filter(regex='_SeqSt1_%s$'%parameter, axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "#     # get joint ID info\n",
    "#     if parameter == 'tdist_total':\n",
    "#         df['SeqSt_jointID'] = df.filter(regex='_SeqSt0_tdist_total$', axis=1).applymap(lambda x: len(x)).apply(\n",
    "#             lambda x: np.concatenate([x]), axis = 1).map(\n",
    "#             lambda x: np.repeat(['joint0', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5'], x))\n",
    "#     # remove colulmns for individual joint sequential stride info\n",
    "#     for joint_num in range(0,6):\n",
    "#         df = df.drop(['joint%s_SeqSt0_%s'%(joint_num, parameter), 'joint%s_SeqSt1_%s'%(joint_num, parameter)], axis =1)\n",
    "    \n",
    "    \n",
    "# new df with just sequential stride info of interest\n",
    "lens = [len(item) for item in df['SeqSt0_travel_dir']]\n",
    "seq_strides = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"joint_ID\" : np.repeat(df['SeqSt_jointID'].values, lens), \n",
    "                        \"Len_0\" : np.concatenate(df['SeqSt0_Len'].values/pix2mm), \"Len_1\" : np.concatenate(df['SeqSt1_Len'].values/pix2mm),\n",
    "                        \"Dur_0\" : np.concatenate(df['SeqSt0_Dur'].values/fps), \"Dur_1\" : np.concatenate(df['SeqSt1_Dur'].values/fps),\n",
    "                        \"travel_dist_0\" : np.concatenate(df['SeqSt0_tdist_total'].values/pix2mm), \n",
    "                        \"travel_dist_1\" : np.concatenate(df['SeqSt1_tdist_total'].values/pix2mm),\n",
    "                        \"speed_0\" : np.concatenate(df['SeqSt0_tdist_total'].values/pix2mm)/np.concatenate(df['SeqSt0_Dur'].values/fps), \n",
    "                        \"speed_1\" : np.concatenate(df['SeqSt1_tdist_total'].values/pix2mm)/np.concatenate(df['SeqSt1_Dur'].values/fps),\n",
    "                        \"travel_dir_0\" : np.concatenate(df['SeqSt0_travel_dir'].values), \"travel_dir_1\" : np.concatenate(df['SeqSt1_travel_dir'].values),\n",
    "                        \"rotation_0\" : np.concatenate(df['SeqSt0_rotation'].values), \"rotation_1\" : np.concatenate(df['SeqSt1_rotation'].values)    })\n",
    "\n",
    "print('\\ndone analyzing')\n",
    "\n",
    "\n",
    "#####################\n",
    "# ONLY DIST TRAVELED -- PLOT CURRENT VS. PAST STRIDE\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "subtypes = sorted(list(set(df['substrate'])))\n",
    "coltypes = sorted(list(set(df['colony'].values)))\n",
    "\n",
    "plt.close('all')\n",
    "fig =plt.figure(figsize = (17,5))\n",
    "p_toplot = 'travel_dist'\n",
    "density = {}\n",
    "coltypes = sorted(list(set(df['colony'].values)))\n",
    "xlimits = [np.floor(np.nanmin(seq_strides['%s_0'%p_toplot].values)), np.ceil(np.nanmax(seq_strides['%s_0'%p_toplot].values))]\n",
    "cutoff_info = np.full((4,5),np.nan)\n",
    "for ss, subtype in enumerate(subtypes[0:4]):\n",
    "    sp_ax = plt.subplot(1,4,ss+1)\n",
    "    xvals = seq_strides.loc[(seq_strides['substrate']==subtype) & (seq_strides['colony']!=coltypes[-2])]['%s_0'%p_toplot].values\n",
    "    yvals = seq_strides.loc[(seq_strides['substrate']==subtype) & (seq_strides['colony']!=coltypes[-2])]['%s_1'%p_toplot].values\n",
    "#     sp_ax.plot(xvals, yvals, '.', alpha = 0.008, c = pltcolors[ss])\n",
    "    \n",
    "#     # plot cinnamon colony\n",
    "#     xvals = seq_strides.loc[(seq_strides['substrate']==subtype) & (seq_strides['colony']=='Tunnel_20180329-30')]['%s_0'%p_toplot].values\n",
    "#     yvals = seq_strides.loc[(seq_strides['substrate']==subtype) & (seq_strides['colony']=='Tunnel_20180329-30')]['%s_1'%p_toplot].values\n",
    "#     sp_ax.plot(xvals, yvals, '.', alpha = 0.008, c = 'k')\n",
    "#     plt.text(4,5,'n: %i'%len(xvals), color = 'k')\n",
    "\n",
    "    # plot unity lines\n",
    "    plt.plot([0,6],[0,6], '--k', alpha = 0.4)\n",
    "    # 10% of previous stride length is considered the same\n",
    "    plt.plot([0,6],[0,6.6], ':k', alpha = 0.4)\n",
    "    plt.plot([0,6],[0,5.4], ':k', alpha = 0.4)\n",
    "#     plt.plot([0,6],[0.5,6.5], ':k')\n",
    "#     plt.plot([0,6],[-.5,5.5], ':k')\n",
    "\n",
    "    # use density and pca to identify side clouds\n",
    "    x = xvals\n",
    "    y = yvals\n",
    "    H, xbins, ybins =np.histogram2d(x, y, 50, weights =np.ones_like(x)/float(len(x)))\n",
    "    xloc = np.array([np.where(xbins[:-1]<= xi)[0][-1]  for xi in x])\n",
    "    yloc = np.array([np.where(ybins[:-1]<= yi)[0][-1]  for yi in y])\n",
    "    density[ss] = H[xloc,yloc]\n",
    "    cutoff = 0.002# 0.0025\n",
    "    inlier_mask = density[ss] > cutoff\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    inlier_mask_org = inlier_mask.copy()\n",
    "#     sp_ax.plot(xvals[inlier_mask], yvals[inlier_mask], '.', alpha = 0.008, c = pltcolors[ss])\n",
    "#     sp_ax.plot(xvals[outlier_mask], yvals[outlier_mask], '.', alpha = 0.008, c = 'k')\n",
    "    \n",
    "    points = np.array([x, y]).T\n",
    "    cent =np.mean(points[inlier_mask], axis = 0)\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit_transform(points[inlier_mask])\n",
    "    projected_in= pca.transform(points[inlier_mask])\n",
    "    a = 4*np.linalg.norm(pca.inverse_transform([np.std(projected_in, axis =0)[0],0])-cent)\n",
    "    b = 4*np.linalg.norm(pca.inverse_transform([np.std(projected_in, axis =0)[1],0])-cent)\n",
    "    new_unit =pca.inverse_transform([1,0])-cent\n",
    "    el_angle = np.rad2deg(np.arctan2(new_unit[1], new_unit[0]))\n",
    "    \n",
    "    projected= pca.transform(points)\n",
    "    inlier_mask = np.logical_or(np.sum(np.square(projected)/[a**2,b**2],axis=1)<1, np.sign(el_angle)*projected[:,0]>0)\n",
    "    inlier_mask = np.logical_or(inlier_mask, (y-x)/x < 0.1)\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    cutoff_info[ss,:] = [cent[0], cent[1], a, b, el_angle]\n",
    "    \n",
    "#     # plot using scatter\n",
    "# #     sp_ax.plot(xvals[inlier_mask], yvals[inlier_mask], '.', alpha = 0.01, c = pltcolors[ss], ms = 2)\n",
    "# #     sp_ax.plot(xvals[outlier_mask], yvals[outlier_mask], '.', alpha = 0.01, c = 'k', ms =2)\n",
    "    \n",
    "    # plot using hist\n",
    "    plt.plot(cent[0],cent[1],'.k')\n",
    "    c_array = colors.ListedColormap(pltcolors[ss])(range(0,1000))\n",
    "    c_array[:, -1]=np.arange(0,1,0.001)\n",
    "    new_cmap = LinearSegmentedColormap.from_list(name = '%s_alpha'%pltcolors[ss], colors = c_array)\n",
    "#     hb=sp_ax.hist2d(x, y, 50,  cmap = new_cmap, norm = LogNorm(), vmin = 1, vmax = 800)\n",
    "    hb=sp_ax.hist2d(x, y, 50, weights =np.ones_like(x)/float(len(x)), vmin = 0, vmax = 0.008, cmap = new_cmap)\n",
    "\n",
    "    # plot pca ellipse cut-off\n",
    "#     el_axes = np.sqrt(el_var)*cutoff/2\n",
    "#     el_dim = np.linalg.norm(pca.inverse_transform([[a,0],[0,b]]),axis =1)*2\n",
    "#     el = Ellipse(cent, el_dim[0], el_dim[1], angle = np.rad2deg(el_angle), ec = 'k', fc = 'None', LineStyle = '--')\n",
    "    el = Ellipse(cent, 2*a,2*b, angle = el_angle, ec = 'k', fc = 'None', LineStyle = '--')\n",
    "    plt.gca().add_patch(el)\n",
    "    \n",
    "    # convex hull around dense data\n",
    "    hull = ConvexHull(np.vstack([y[inlier_mask_org],x[inlier_mask_org]]).T)\n",
    "    for simplex in hull.simplices:\n",
    "        plt.plot(x[inlier_mask_org][simplex], y[inlier_mask_org][simplex], 'k-')\n",
    "#     hull = ConvexHull(np.vstack([y[inlier_mask],x[inlier_mask]]).T)\n",
    "#     for simplex in hull.simplices:\n",
    "#         plt.plot(x[inlier_mask][simplex], y[inlier_mask][simplex], 'b:')\n",
    "    \n",
    "    \n",
    "#     # how many strides in each category\n",
    "#     n_total = len(inlier_mask)\n",
    "#     n_normal=np.sum(inlier_mask)\n",
    "#     n_disrupted=np.sum(outlier_mask)\n",
    "#     n_normal_constant = np.sum(np.abs(y[inlier_mask]-x[inlier_mask])<0.1*x[inlier_mask])\n",
    "#     n_normal_notconstant = n_normal - n_normal_constant\n",
    "#     plt.text(4, 5.5,'n: %i'%n_normal, color = pltcolors[ss])\n",
    "#     plt.text(4, 5.1, 'n: %i'%n_disrupted, color = 'k')\n",
    "#     plt.text(4, 3, '%% disrupted: \\n%0.2f'%(n_disrupted/n_total*100))\n",
    "#     ax=fig.add_axes([.26+ss*.2,.25,.02,.2])\n",
    "#     plt.bar(np.zeros(3), np.array([n_normal_constant, n_normal_notconstant, n_disrupted])/n_total, \n",
    "#             bottom = np.array([0, n_normal_constant, n_normal])/n_total, color=[pltcolors[ss],'m','k'], alpha = 0.4)\n",
    "#     ax.set_ylim([0,1])\n",
    "#     ax.axis('off')\n",
    "    \n",
    "    # plot aesthetics\n",
    "    sp_ax.set_aspect('equal')\n",
    "    sp_ax.set_xlim(xlimits)\n",
    "    sp_ax.set_ylim(xlimits)\n",
    "    sp_ax.set_ylabel('current stride %s (mm)'%p_toplot)\n",
    "    sp_ax.set_xlabel('previous stride %s (mm)'%p_toplot)\n",
    "    if ss==3:\n",
    "        ax=fig.add_axes([.93,.2,.02,.75])\n",
    "        fig.colorbar(hb[3], cax=ax)\n",
    "    fig.add_subplot(sp_ax)\n",
    "    \n",
    "fig.show()\n",
    "\n",
    "\n",
    "#####################\n",
    "# # FOR EACH KINEMATIC PARAMETER, PLOT CURRENT VS. PAST STRIDE\n",
    "# plt.close('all')\n",
    "# fig =plt.figure(figsize = (14,9))\n",
    "# outer = gridspec.GridSpec(2,3, wspace = 0.2, hspace = 0.2)\n",
    "# for sp, p_toplot in enumerate(['travel_dist', 'Dur', 'speed', 'travel_dir', 'rotation', 'Len']):\n",
    "#     print(sp)\n",
    "#     inner = gridspec.GridSpecFromSubplotSpec(2,2, subplot_spec = outer[sp], wspace = 0, hspace = 0)\n",
    "#     xlimits = [np.floor(np.nanmin(seq_strides['%s_0'%p_toplot].values)), np.ceil(np.nanmax(seq_strides['%s_0'%p_toplot].values))]\n",
    "#     for ss, subtype in enumerate(subtypes[0:4]):\n",
    "#         sp_ax = plt.Subplot(fig, inner[ss])\n",
    "#         xvals = seq_strides.loc[(seq_strides['substrate']==subtype)]['%s_0'%p_toplot].values\n",
    "#         yvals = seq_strides.loc[(seq_strides['substrate']==subtype)]['%s_1'%p_toplot].values\n",
    "#         sp_ax.plot(xvals, yvals, '.', alpha = 0.002, c = pltcolors[ss])\n",
    "#         sp_ax.set_aspect('equal')\n",
    "#         sp_ax.set_xlim(xlimits)\n",
    "#         sp_ax.set_ylim(xlimits)\n",
    "#         if ss != 2:\n",
    "#             sp_ax.set_xticks([])\n",
    "#             sp_ax.set_yticks([])\n",
    "#         else:\n",
    "#             sp_ax.set_ylabel('%s'%p_toplot)\n",
    "#             sp_ax.set_xlabel('%s'%p_toplot)\n",
    "#         fig.add_subplot(sp_ax)\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "#########################\n",
    "# # PLOT QUIVER PLOT ON BODY TRAVEL DIRECTION VS. FACING ROTATION\n",
    "# plt.figure(figsize = (17,4))\n",
    "# for ss, subtype in enumerate(subtypes[0:4]):\n",
    "#     x = seq_strides.loc[(seq_strides['substrate']==subtype)]['travel_dir_0'].values\n",
    "#     y = seq_strides.loc[(seq_strides['substrate']==subtype)]['rotation_0'].values\n",
    "#     dx = seq_strides.loc[(seq_strides['substrate']==subtype)]['travel_dir_1'].values - seq_strides.loc[(seq_strides['substrate']==subtype)]['travel_dir_0'].values\n",
    "#     dy = seq_strides.loc[(seq_strides['substrate']==subtype)]['rotation_1'].values - seq_strides.loc[(seq_strides['substrate']==subtype)]['rotation_0'].values\n",
    "#     idcs = np.linalg.norm([dx,dy], axis = 0) > 80\n",
    "#     ax = plt.subplot(1,4,ss+1)\n",
    "#     plt.quiver(x, y, dx, dy, color = 'k', alpha = 0.03, angles = 'xy', scale_units = 'xy', scale = 1)\n",
    "#     plt.quiver(x[idcs], y[idcs], dx[idcs], dy[idcs], color = pltcolors[ss], alpha = 0.1,  angles = 'xy', scale_units = 'xy', scale = 1)\n",
    "#     plt.xlim((-180,180))\n",
    "#     plt.ylim((-180,180))\n",
    "#     plt.xlabel('travel dir')\n",
    "#     plt.ylabel('facing rotation')\n",
    "\n",
    "\n",
    "\n",
    "del xvals, yvals, sp_ax, ss, xlimits, p_toplot, seq_strides\n",
    "\n",
    "\n",
    "\n",
    "# calculate if strides are disrupted based on stride length\n",
    "def calc_SS_disrupted_df(x, cutoff_info):\n",
    "    ss0 = x['SeqSt0_tdist_total']/pix2mm\n",
    "    ss1 = x['SeqSt1_tdist_total']/pix2mm\n",
    "    ss = np.where(np.array(['0mm','1mm','3mm','5mm'])==x['substrate'])[0][0]\n",
    "    (c_x, c_y, a, b, ang) = cutoff_info[ss,:]\n",
    "    ang = np.deg2rad(ang)\n",
    "\n",
    "    rad = ((ss0-c_x)*np.cos(ang)+(ss1-c_y)*np.sin(ang))**2/a**2 + ((ss0-c_x)*np.sin(ang)-(ss1-c_y)*np.cos(ang))**2/b**2\n",
    "    p_diff = (ss1-ss0)/ss0\n",
    "    disrupted_strides = np.logical_and(rad>1, np.abs(p_diff)>0.1)\n",
    "    return disrupted_strides\n",
    "\n",
    "print('calculating disrupted sequential strides for each trial')\n",
    "df['St_disrupted_SS']= df.apply(calc_SS_disrupted_df, args = (cutoff_info,), axis=1)\n",
    "print('all done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test out seq stride df function on one trial\n",
    "ss0 = df['SeqSt0_tdist_total'][0]/pix2mm\n",
    "ss1 = df['SeqSt1_tdist_total'][0]/pix2mm\n",
    "ss = np.where(np.array(['0mm','1mm','3mm','5mm'])==df['substrate'][0])[0][0]\n",
    "(c_x, c_y, a, b, ang) = cutoff_info[ss,:]\n",
    "ang = np.deg2rad(ang)\n",
    "rad = ((ss0-c_x)*np.cos(ang)+(ss1-c_y)*np.sin(ang))**2/a**2 + ((ss0-c_x)*np.sin(ang)-(ss1-c_y)*np.cos(ang))**2/b**2\n",
    "disrupted_strides = rad>1\n",
    "print(rad)\n",
    "\n",
    "# look at seq stride disrtupted results for one trial\n",
    "tr= 689\n",
    "np.vstack([df['SeqSt_jointID'][tr], df['St_disrupted_SS'][tr], df['SeqSt0_tdist_total'][tr]/pix2mm, df['SeqSt1_tdist_total'][tr]/pix2mm  ]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving disrupted stride data as feather for use in R\n",
      "Done saving\n"
     ]
    }
   ],
   "source": [
    "# save as feather for lme models in R\n",
    "import feather\n",
    "temp = df.copy()\n",
    "\n",
    "# look only at trials longer than 50fr\n",
    "idcs = [index for index, row in temp.iterrows() if len(row.St_disrupted_SS)>10]\n",
    "longtracks = df.loc[idcs,]\n",
    "longtracks = longtracks.loc[(longtracks['colony']!=coltypes[-1])] # don't include cinnamon trial data\n",
    "\n",
    "# MEDIAN V\n",
    "colony_R = [col.split('20180')[-1][1:] for col in longtracks['colony'].values.tolist()]\n",
    "date_days = [col[-2:] for col in longtracks['date'].values.tolist()]\n",
    "day_R = [col.split('-').index(day) for day, col in zip(date_days, colony_R)]\n",
    "subs_string = longtracks['substrate'].values.tolist()\n",
    "substrate_R = np.array([int(s.split('mm')[0]) for s in subs_string])\n",
    "v_med_R = np.array(longtracks['median_v'])/pix2mm\n",
    "n_disrupted_R = longtracks['St_disrupted_SS'].apply(lambda x: np.sum(x)).values\n",
    "n_strides_R = longtracks['St_disrupted_SS'].apply(lambda x: len(x)).values\n",
    "p_disrupted_R = longtracks['St_disrupted_SS'].apply(lambda x: np.sum(x)/len(x)).values\n",
    "df_med_R = pd.DataFrame( {\"colony\" : colony_R, \"day\" : day_R, \"substrate\" : substrate_R,\n",
    "                       \"v_med\" : v_med_R, \"n_disrupted\": n_disrupted_R,\n",
    "                      \"n_strides\": n_strides_R, \"percent_disrupted\": p_disrupted_R  } )\n",
    "\n",
    "# SAVE AS FEATHER FOR USE WITH R\n",
    "print('Saving disrupted stride data as feather for use in R')\n",
    "feather.write_dataframe(df_med_R, vid_locations + 'Disrupted_SS.feather')\n",
    "# testdf = feather.read_dataframe(vid_locations + 'Disrupted_SF.feather')\n",
    "print('Done saving')\n",
    "\n",
    "del idcs, colony_R, day_R, substrate_R, v_med_R, date_days, subs_string, temp, longtracks, p_disrupted_R\n",
    "del df_med_R, n_strides_R, n_disrupted_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.64351655537718\n",
      "[0.12914604 0.10330766]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2.858317009384496, 3.450483020032533, -2.2619134098066223, 4.381794585606526)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.array([x, y]).T\n",
    "cent =np.mean(points[inlier_mask], 0)\n",
    "new_points = points[inlier_mask]-cent\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "t_points = pca.fit_transform(new_points)\n",
    "el_angle = np.arctan2(pca.components_[0][1], pca.components_[0][0])\n",
    "print(np.rad2deg(el_angle))\n",
    "a = np.max(np.abs(t_points[:,0]))*1.2\n",
    "b = np.max(np.abs(t_points[:,1]))*1.2\n",
    "\n",
    "\n",
    "el_var = pca.explained_variance_\n",
    "\n",
    "\n",
    "# el_values = np.sum(np.square(np.einsum('ij, jk->ik', points-cent, R))/(1.96**2 * el_var)[np.newaxis,:], axis =1)\n",
    "#     print('in: %i, out: %i'%(np.sum(el_values<=1), np.sum(el_values>1)))\n",
    "#     inlier_mask = el_values <= 1\n",
    "print(el_var)\n",
    "projected = pca.transform(points-cent)\n",
    "cutoff = 12\n",
    "pca_mask = np.logical_or(np.sum(np.square(projected)/[a**2,b**2],axis=1)<1, np.sign(el_angle)*projected[:,0]>0)\n",
    "\n",
    "# pca_mask = np.logical_and(np.any(np.abs(projected)>[a,b],axis =1), projected[:,0]<0)\n",
    "# pca_mask =np.any(np.abs(projected)>[a,b],axis =1)\n",
    "# pca_mask = np.sum(np.square(projected)/[a**2,b**2],axis=1)<1\n",
    "\n",
    "# inlier_mask = np.logical_or(np.linalg.norm(projected, axis =1)<1, np.sign(el_angle)*projected[:,0]>0)\n",
    "# outlier_mask = np.logical_not(inlier_mask)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(projected[:,0], projected[:,1], '.k', alpha = 0.02, ms = 2)\n",
    "plt.plot(t_points[:,0], t_points[:,1], '.b', alpha = 0.2, ms = 2)\n",
    "plt.plot(projected[pca_mask,0], projected[pca_mask, 1], '.g', alpha = 0.2, ms =2)\n",
    "glenna= pca.inverse_transform(projected)\n",
    "# plt.plot(glenna[:,0], glenna[:,1],'.g', alpha = 0.2, ms = 2)\n",
    "# plt.plot(glenna[pca_mask,0], glenna[pca_mask,1], '.m', alpha = 0.2, ms = 2)\n",
    "# plt.plot(1,0,'.r')\n",
    "\n",
    "\n",
    "# el_axes = np.abs(pca.inverse_transform([1,0]))\n",
    "# el = Ellipse(cent, el_axes[0], el_axes[1], angle = np.rad2deg(el_angle), ec = 'k', fc = 'None', LineStyle = '--')\n",
    "# plt.gca().add_patch(el)\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = range(474,475)\n",
    "\n",
    "\n",
    "def load_video(raw_video_path, frame_range, verbose):\n",
    "    \"\"\"\n",
    "    Independent of the frame range loaded, background has to be computed over total video or else can run into\n",
    "    tracking problems\n",
    "    \"\"\"\n",
    "    vid = cv2.VideoCapture(raw_video_path)\n",
    "    Height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    NumFrames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if not (NumFrames > 0):\n",
    "        raise IOError('Codec issue: cannot read number of frames.')\n",
    "    # restrict to desired range of frames\n",
    "    if frame_range is None:\n",
    "        frame_range = (0, int(NumFrames))\n",
    "    else:\n",
    "        # check doesn't exceed number of frames\n",
    "        if frame_range[0] + frame_range[1] > NumFrames:\n",
    "            frame_range = (int(frame_range[0]), int(NumFrames - frame_range[0]))\n",
    "    # initialize blank frames\n",
    "    frames = np.zeros((frame_range[1], Height, Width), np.uint8)\n",
    "    # set the first frame to read in\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, frame_range[0]) # this way of setting the frame doesn't work on all cv versions\n",
    "    # read in all frames\n",
    "    for kk in range(frame_range[1]):\n",
    "        tru, ret = vid.read(1)\n",
    "        # check if video frames are being loaded\n",
    "        if not tru:\n",
    "            raise IOError('Codec issue: cannot load frames.')\n",
    "        frames[kk, :, :] = ret[:, :, 0]  # assumes loading color\n",
    "        if ((kk % 100) == 0) and verbose:\n",
    "            print(kk)\n",
    "    return frames, NumFrames, frame_range, vid\n",
    "\n",
    "\n",
    "for tr in trs:\n",
    "    for n_tri in [0]:\n",
    "#         n_tri = 0\n",
    "        subset_df = df.filter(regex='_TD_idcs$', axis=1).iloc[tr,range(0,6)[n_tri::2]]\n",
    "\n",
    "        stops = []\n",
    "        starts = []\n",
    "        all_TDs = []\n",
    "        for ii in range(0,3):\n",
    "            all_TDs = np.append(all_TDs, df['joint%i_TD_idcs'%(n_tri+2*ii)][tr][df['joint%i_good_TDs'%(n_tri+2*ii)][tr]])\n",
    "            starts = np.append(starts, df['joint%i_TD_idcs'%(n_tri+2*ii)][tr][:-1][df['joint%i_good_strides'%(n_tri+2*ii)][tr]])\n",
    "            stops = np.append(stops, df['joint%i_TD_idcs'%(n_tri+2*ii)][tr][1:][df['joint%i_good_strides'%(n_tri+2*ii)][tr]])\n",
    "\n",
    "\n",
    "        all_TDs = np.sort(all_TDs)\n",
    "        if len(all_TDs)==0:\n",
    "            continue\n",
    "        all_stride_diff = np.insert(np.diff(np.sort(all_TDs)),0,0)\n",
    "\n",
    "        arr = all_TDs\n",
    "        arr_diff = np.cumsum(all_stride_diff>10)\n",
    "        idcs = range(len(arr_diff))\n",
    "        TD_groups  = [arr[(list(g))] for k,g in groupby(iter(idcs), lambda x: arr_diff[x])]\n",
    "\n",
    "        # lone strides\n",
    "        group_is_one  = np.array([len(g) for g in TD_groups])==1\n",
    "        if not np.any(group_is_one):\n",
    "            continue\n",
    "        lone_TDs = np.concatenate(np.array(TD_groups)[group_is_one])\n",
    "\n",
    "        for lTD in lone_TDs:\n",
    "            fr = int(df['frames'][tr][int(lTD)])\n",
    "            is_disrupted = np.sum(np.logical_and(lTD>=starts, lTD < stops))>2\n",
    "\n",
    "\n",
    "            if is_disrupted ==True:\n",
    "                \n",
    "                which_joint = np.where(subset_df.apply(lambda x: np.isin(lTD, x)).values)[0]*2+n_tri\n",
    "                other_tjoints = np.where(np.array(range(n_tri,6,2)) != which_joint)[0]*2+n_tri\n",
    "                frames, _, _, _ = load_video(df['video'][tr], [fr-60,120], verbose= False)\n",
    "                \n",
    "                print('\\n%i **** '%tr, df['video'][tr])\n",
    "                print('tripod: %i -- fr: %i -- joint: %i'%(n_tri, fr, which_joint))\n",
    "                for loop in range(2):\n",
    "                    plt.close('all')\n",
    "                    fig = plt.figure()\n",
    "                    for f_num in range(len(frames)):\n",
    "                        plt.cla()\n",
    "                        plt.imshow(frames[f_num,:,:], cmap = 'gray')\n",
    "                        plt.plot(df['joint%i_x_filt_fullfr'%which_joint][tr][int(lTD-60)+f_num], df['joint%i_y_filt_fullfr'%which_joint][tr][int(lTD-60)+f_num] ,\n",
    "                                     '.r', MarkerSize = 3)\n",
    "                        for jj in other_tjoints:\n",
    "                            plt.plot(df['joint%i_x_filt_fullfr'%jj][tr][int(lTD-60)+f_num], df['joint%i_y_filt_fullfr'%jj][tr][int(lTD-60)+f_num] ,\n",
    "                                         '.w', MarkerSize = 3)\n",
    "                        plt.xlim([-100, 100] + df['thorax_x_filt_fullfr'][tr][int(lTD)])\n",
    "                        plt.ylim([-100, 100] + df['thorax_y_filt_fullfr'][tr][int(lTD)])\n",
    "                        plt.gca().invert_yaxis()\n",
    "                        plt.text(df['thorax_x_filt_fullfr'][tr][int(lTD)]+70, df['thorax_y_filt_fullfr'][tr][int(lTD)]-90 ,'joint %i'%which_joint, color = 'r')\n",
    "                        plt.scatter(df['joint%i_x_filt_fullfr'%which_joint][tr][int(lTD)], df['joint%i_y_filt_fullfr'%which_joint][tr][int(lTD)] ,\n",
    "                                    s=40, edgecolor= 'r', facecolor = 'None', linestyle = ':')\n",
    "                        plt.show()\n",
    "                        if f_num == 60:\n",
    "                            plt.pause(0.003)\n",
    "                        else:\n",
    "                            plt.pause(0.01)\n",
    "                    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_strides_in_group(group, group_idx, n_tri, starts, stops, good_strides, stride_ID):\n",
    "    joints_not_in_group = np.array(range(n_tri,6,2))[np.logical_not( np.isin(range(n_tri,6,2), group_idx) )]\n",
    "    n_other_strides = 0\n",
    "    if (len(joints_not_in_group) >0) and (np.sum(good_strides)>0):\n",
    "        where_stride_edges = np.where(np.diff(stride_ID[good_strides]).astype(bool))[0]+1\n",
    "        starts_joints = np.split(starts[good_strides], where_stride_edges)\n",
    "        stops_joints = np.split(stops[good_strides], where_stride_edges)\n",
    "        joint_joints = np.split(stride_ID[good_strides], where_stride_edges)\n",
    "#         print([jj[0] for jj in joint_joints])\n",
    "        joints_not_in_group_id = [[jj[0] for jj in joint_joints].index(ii) for ii in joints_not_in_group if ii in [jj[0] for jj in joint_joints]]\n",
    "        if len(joints_not_in_group_id)>0:\n",
    "            starts_OI = np.concatenate(np.array(starts_joints)[joints_not_in_group_id])\n",
    "            stops_OI = np.concatenate(np.array(stops_joints)[joints_not_in_group_id])\n",
    "            n_other_strides = np.sum(np.logical_and(np.mean(group)>starts_OI, np.mean(group)<stops_OI))\n",
    "    return n_other_strides\n",
    "\n",
    "\n",
    "for tr in [476, 479,489]:#range(475,490):\n",
    "    frames = df['frames'][tr]\n",
    "    print('%i **** '%tr, df['video'][tr])\n",
    "\n",
    "    all_TDs = df.filter(regex='_TD_idcs$', axis=1).applymap(lambda x: x).apply(lambda x: np.concatenate(np.concatenate([x])), axis = 1)[tr]\n",
    "    starts = df.filter(regex='_TD_idcs$', axis=1).applymap(lambda x: x[:-1]).apply(lambda x: np.concatenate(np.concatenate([x])), axis = 1)[tr]\n",
    "    stops = df.filter(regex='_TD_idcs$', axis=1).applymap(lambda x: x[1:]).apply(lambda x: np.concatenate(np.concatenate([x])), axis = 1)[tr]\n",
    "    good_strides = df.filter(regex='_good_strides$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x])), axis = 1)[tr]\n",
    "    good_TDs = df.filter(regex='_good_TDs$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x])), axis = 1)[tr]\n",
    "    TDs_ID = df.filter(regex='_TD_idcs$', axis=1).applymap(lambda x: len(x)).apply(\n",
    "        lambda x: np.concatenate([x]), axis = 1).map(lambda x: np.repeat(np.array(range(0,6)), x))[tr]\n",
    "    stride_ID = df.filter(regex='_good_strides$', axis=1).applymap(lambda x: len(x)).apply(\n",
    "        lambda x: np.concatenate([x]), axis = 1).map(\n",
    "        lambda x: np.repeat(np.array(range(0,6)), x))[tr]\n",
    "    good_stride_ID = stride_ID.copy().astype(float)\n",
    "    good_stride_ID[np.logical_not(good_strides)] = np.nan\n",
    "    stride_order = np.argsort(starts)\n",
    "\n",
    "    # keep starts and stops of strides as trusted TDs\n",
    "    where_strides = np.diff(np.insert(TDs_ID, len(TDs_ID),-1)) == 0\n",
    "    temp = np.full(where_strides.shape, False)\n",
    "    temp[where_strides] = good_strides\n",
    "    temp = np.insert(temp,0,False)\n",
    "    trusted_TDs = np.logical_or(temp[:-1],temp[1:])\n",
    "    del temp\n",
    "\n",
    "\n",
    "#     plt.figure(figsize = (14,2))\n",
    "#     pltcolors = np.array(['r', 'm', 'y', 'g', 'c', 'b'])\n",
    "#     tricolors = np.array(['r','g'])\n",
    "#     plt.scatter(frames[np.concatenate([starts,stops])], np.tile(stride_ID,2), s=4, c=pltcolors[stride_ID], alpha = 0.3)#, color = list(pltcolors[stride_ID]));\n",
    "#     plt.plot(frames[np.array([starts[good_strides],stops[good_strides]])], np.tile(stride_ID[good_strides],(2,1)), '--k', alpha = 0.5);\n",
    "#     plt.scatter(frames[all_TDs[trusted_TDs]], TDs_ID[trusted_TDs], s=8, c=pltcolors[TDs_ID[trusted_TDs]])\n",
    "#     for tt,td in enumerate(TDs_ID[trusted_TDs]):\n",
    "#         plt.text(frames[all_TDs[trusted_TDs][tt]], 6, '%i'%td, color = pltcolors[td], horizontalalignment = 'center')\n",
    "#     plt.ylim([-.5,6])\n",
    "#     plt.gca().invert_yaxis()\n",
    "#     plt.title('Tr %i -- %s'%(tr,(' -- ').join(df['video'][tr].split('/')[-2:]) ), loc = 'left')\n",
    "\n",
    "    for n_tri in [0,1]:\n",
    "\n",
    "        # define only tripod of interest\n",
    "        tripod_TDs = all_TDs[TDs_ID%2==n_tri]\n",
    "        tripod_good_TDs = good_TDs[TDs_ID%2==n_tri]\n",
    "        tripod_TDs_ID = TDs_ID[TDs_ID%2 == n_tri]\n",
    "\n",
    "        # sort good TDs into clusters\n",
    "        arr = tripod_TDs[tripod_good_TDs]\n",
    "        arr_sort = np.argsort(arr)\n",
    "        arr_diff = np.insert(np.diff(arr[arr_sort]),0,0)>15\n",
    "        TD_groups  = np.split(arr[arr_sort], np.where(arr_diff)[0])\n",
    "        TD_groups_ID  = np.split(tripod_TDs_ID[tripod_good_TDs][arr_sort], np.where(arr_diff)[0])\n",
    "        \n",
    "        # split any groups that have more than one TD from same foot\n",
    "        temp = [gg for gg,[gr,idx] in enumerate(zip(TD_groups,TD_groups_ID)) if len(np.unique(idx))<len(idx)]\n",
    "\n",
    "        for gr in temp[::-1]:\n",
    "            temp2 = TD_groups[gr]\n",
    "#             print(np.split(temp2,[np.argmax(np.diff(temp2))+1]))\n",
    "            TD_groups[gr:gr+1]=np.split(temp2,[np.argmax(np.diff(temp2))+1])\n",
    "            TD_groups_ID[gr:gr+1]=np.split(TD_groups_ID[gr],[np.argmax(np.diff(temp2))+1])\n",
    "            del temp2\n",
    "\n",
    "        # how many TDS in each group\n",
    "        TD_groups_n_TDs = np.array([len(x) for x in TD_groups])\n",
    "\n",
    "        # how many good strides from tripod are trusted around each cluster\n",
    "        TD_groups_n_other_strides = np.array([other_strides_in_group(group, group_idx, n_tri, starts, stops, good_strides, stride_ID) \n",
    "                                     for group, group_idx in zip(TD_groups, TD_groups_ID)])\n",
    "\n",
    "#         print(TD_groups_n_TDs)\n",
    "#         print(TD_groups_n_other_strides)\n",
    "\n",
    "        tripods = np.array(TD_groups)[TD_groups_n_TDs == 3]\n",
    "        pairs = np.array(TD_groups)[TD_groups_n_TDs == 2]\n",
    "        disrupted = np.array(TD_groups)[np.logical_and(TD_groups_n_TDs == 1, TD_groups_n_other_strides >1)]\n",
    "        disrupted_idx = np.array(TD_groups_ID)[np.logical_and(TD_groups_n_TDs == 1, TD_groups_n_other_strides >1)]\n",
    "\n",
    "#         for t in tripods:\n",
    "#             rect = Rectangle([frames[np.min(t)],-.5],np.max(t)-np.min(t),6.5, color = tricolors[n_tri], alpha = 0.2)\n",
    "#             plt.gca().add_patch(rect)\n",
    "#         for t in pairs:\n",
    "#             rect = Rectangle([frames[np.min(t)],-.5],np.max(t)-np.min(t),6.5, color = tricolors[n_tri], alpha = 0.05)\n",
    "#             plt.gca().add_patch(rect)\n",
    "        for t, ii in zip(disrupted, disrupted_idx):\n",
    "#             plt.axvline(x=frames[t], color = pltcolors[ii][0])\n",
    "            fr = frames[t]\n",
    "            which_joint = ii\n",
    "            other_tjoints = np.where(np.array(range(n_tri,6,2)) != which_joint)[0]*2+n_tri\n",
    "            vframes, _, _, _ = load_video(df['video'][tr], [fr-60,120], verbose= False)\n",
    "\n",
    "#             print('\\n%i **** '%tr, df['video'][tr])\n",
    "            print('     tripod: %i -- fr: %i -- joint: %i'%(n_tri, fr, which_joint))\n",
    "#             for loop in range(1):\n",
    "            plt.close('all')\n",
    "            fig = plt.figure()\n",
    "            for f_num in range(len(vframes)):\n",
    "                plt.cla()\n",
    "                plt.imshow(vframes[f_num,:,:], cmap = 'gray')\n",
    "                plt.plot(df['joint%i_x_filt_fullfr'%which_joint][tr][int(t-60)+f_num], df['joint%i_y_filt_fullfr'%which_joint][tr][int(t-60)+f_num] ,\n",
    "                             '.r', MarkerSize = 3)\n",
    "                for jj in other_tjoints:\n",
    "                    plt.plot(df['joint%i_x_filt_fullfr'%jj][tr][int(t-60)+f_num], df['joint%i_y_filt_fullfr'%jj][tr][int(t-60)+f_num] ,\n",
    "                                 '.w', MarkerSize = 3)\n",
    "                plt.xlim([-100, 100] + df['thorax_x_filt_fullfr'][tr][t])\n",
    "                plt.ylim([-100, 100] + df['thorax_y_filt_fullfr'][tr][t])\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.text(df['thorax_x_filt_fullfr'][tr][t]+70, df['thorax_y_filt_fullfr'][tr][t]-90 ,'joint %i'%which_joint, color = 'r')\n",
    "                plt.scatter(df['joint%i_x_filt_fullfr'%which_joint][tr][t], df['joint%i_y_filt_fullfr'%which_joint][tr][t] ,\n",
    "                            s=40, edgecolor= 'r', facecolor = 'None', linestyle = ':')\n",
    "                plt.show()\n",
    "                if f_num == 60:\n",
    "                    plt.pause(0.003)\n",
    "                else:\n",
    "                    plt.pause(0.01)\n",
    "            plt.close(fig)\n",
    "            \n",
    "\n",
    "        del TD_groups, TD_groups_ID, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at ant placement wrt block edge for each substrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate where in checkerboard box for user defined trials\n",
    "\n",
    "def split_by_bool(arr, boo):\n",
    "    split_idcs = np.nonzero(boo[1:] != boo[:-1])[0]+1\n",
    "    split_arr = np.split(arr, split_idcs)\n",
    "    split_arr = [split_arr[0::2] if boo[0] else split_arr[1::2]]\n",
    "    return split_arr[0]\n",
    "\n",
    "plt.close('all')\n",
    "for tr in range(875,896):\n",
    "\n",
    "    # collect data into easy to use variables\n",
    "    all_x = df['thorax_x_filt_fullfr'][tr]\n",
    "    all_y = df['thorax_y_filt_fullfr'][tr]\n",
    "    col_OI = df['colony'][tr]\n",
    "    sub_OI = df['substrate'][tr]\n",
    "\n",
    "    # find horizontal and vertical lines\n",
    "    step_height_OI = step_height_df[\n",
    "        step_height_df['substrate'].str.contains(sub_OI) & step_height_df['colony'].str.contains(col_OI)]\n",
    "    height_profile = step_height_OI['height_profile'].values[0]\n",
    "    vlines = step_height_OI['vlines'].values[0]\n",
    "    n_vlines = len(vlines)\n",
    "    hlines = step_height_OI['hlines'].values[0]\n",
    "    hlines_sep = np.diff(hlines[:,1]*500+hlines[:,0]) # if close-by hline it's a ledge and remove\n",
    "    where_ledge = np.where((np.median(hlines_sep)-hlines_sep)>30)[0]\n",
    "    if len(where_ledge)>0:\n",
    "        if where_ledge[0]==0:\n",
    "            hlines=np.delete(hlines,0,axis=0)\n",
    "            height_profile=np.delete(height_profile,0,axis=0)\n",
    "        else:\n",
    "            hlines=np.delete(hlines,where_ledge[0]+1,axis=0)\n",
    "            height_profile=np.delete(height_profile,where_ledge[0],axis=0)\n",
    "    n_hlines = len(hlines)\n",
    "\n",
    "    # find where close to middle vertical line\n",
    "    vert_box_cutoff = 0.5 # in mm\n",
    "    where_in_vert_box = np.full(all_x.shape, False)\n",
    "    if sub_OI == '0mm':\n",
    "        vline_OI = 0\n",
    "        for vs in [1,3]:\n",
    "            a = np.mean(1/vlines[vline_OI:vline_OI+2,1])/2*vs\n",
    "            b = np.mean(vlines[vline_OI:vline_OI+2,0]/vlines[vline_OI:vline_OI+2,1])/2*vs\n",
    "            x_pred =all_y*a-b\n",
    "            temp = np.abs(all_x-x_pred)<(vert_box_cutoff*pix2mm)\n",
    "            where_in_vert_box = np.logical_or(temp, where_in_vert_box)\n",
    "    else:\n",
    "        for vs in [1,2]:\n",
    "            vline_OI = int(np.round(n_vlines/3*vs))-1\n",
    "            a = np.mean(1/vlines[vline_OI:vline_OI+2,1])\n",
    "            b = np.mean(vlines[vline_OI:vline_OI+2,0]/vlines[vline_OI:vline_OI+2,1])\n",
    "            x_pred =all_y*a-b\n",
    "            temp = np.abs(all_x-x_pred)<(vert_box_cutoff*pix2mm)\n",
    "            where_in_vert_box = np.logical_or(temp, where_in_vert_box)\n",
    "    \n",
    "    \n",
    "\n",
    "    # find if far from edges\n",
    "    edge_cutoff = [1.5, 1.5, 3, 2.5][subtypes.index(sub_OI)]# in mm\n",
    "    is_far_from_top = all_y>(all_x*hlines[0,1]+hlines[0,0]+edge_cutoff*pix2mm)\n",
    "    is_far_from_bottom = all_y<(all_x*hlines[-1,1]+hlines[-1,0]-edge_cutoff*pix2mm)\n",
    "    good_points = is_far_from_top & where_in_vert_box & is_far_from_bottom\n",
    "\n",
    "    # isolate trails through vertical box\n",
    "    x_chunks = split_by_bool(all_x, good_points)\n",
    "    y_chunks = split_by_bool(all_y, good_points)\n",
    "\n",
    "    if len(y_chunks)>0:\n",
    "        y_box_fraction = np.full(len(y_chunks), np.nan)\n",
    "        checkerboard_height = np.full(len(y_chunks), np.nan)\n",
    "        # find average y_location\n",
    "        for cc in range(len(y_chunks)):\n",
    "\n",
    "            if len(y_chunks[cc])>10:\n",
    "                \n",
    "                plt.plot(all_x,all_y,'-k')\n",
    "                \n",
    "                y_mean = np.nanmedian(y_chunks[cc])\n",
    "                x_mean = np.nanmedian(x_chunks[cc])\n",
    "                \n",
    "                # check if going straight through window\n",
    "                slope = (y_chunks[cc][-1]-y_chunks[cc][0])/(x_chunks[cc][-1]-x_chunks[cc][0])\n",
    "                max_divergence = np.max( np.abs( y_chunks[cc]-y_mean ))\n",
    "                if np.abs(slope) > 0.75:\n",
    "                    print('too slope-y: %0.1f'%slope)\n",
    "                    continue\n",
    "                elif max_divergence/pix2mm > 1/2:\n",
    "                    print('too divergent: %0.1f mm'%(max_divergence/pix2mm))\n",
    "                    continue\n",
    "\n",
    "                plt.plot(x_chunks[cc],y_chunks[cc],'.r', Markersize = 2)\n",
    "                \n",
    "                # find where in checkerboard box\n",
    "                y_pred = hlines[:,1]*x_mean+hlines[:,0]\n",
    "                y_top = y_pred[y_mean>hlines[:,1]*x_mean+hlines[:,0]][-1]\n",
    "                y_bot = y_pred[y_mean<hlines[:,1]*x_mean+hlines[:,0]][0]\n",
    "                y_box_fraction[cc] =np.abs(y_mean-np.mean([y_top,y_bot]))/np.diff([y_top,y_bot])*2\n",
    "                \n",
    "                # find checkerboard box height\n",
    "                row = np.where(y_mean<hlines[:,1]*x_mean+hlines[:,0])[0][0]-1\n",
    "                col = np.where(x_mean<(1/vlines[:,1])*y_mean-vlines[:,0]/vlines[:,1])[0][0]-1\n",
    "                checkerboard_height[cc] = height_profile[row,col]\n",
    "\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                plt.plot(all_x,all_y,'-k',alpha = 0.5)\n",
    "                \n",
    "            print('%s - fraction %0.3f - slope %0.1f - divergence %0.1f - height: %0.0f'%(tr,y_box_fraction[cc],slope,max_divergence/pix2mm,checkerboard_height[cc]))\n",
    "    else:\n",
    "        print('%s - no trail through'%tr)\n",
    "        plt.plot(all_x,all_y,'-k', alpha = 0.5)\n",
    "        \n",
    "for vv in range(n_vlines):\n",
    "    plt.plot(np.linspace(0,550,551)*(1/vlines[vv,1])- vlines[vv,0]/vlines[vv,1], np.linspace(0,550,551),'k', alpha = 0.1)\n",
    "for vv in range(n_hlines):\n",
    "    plt.plot(np.linspace(0,1000,1001), np.linspace(0,1000,1001)*(hlines[vv,1])+hlines[vv,0],'k', alpha = 0.1)\n",
    "plt.plot(np.linspace(0,1000,1001), hlines[0,1]*np.linspace(0,1000,1001)+hlines[0,0],'k', alpha = 0.3)\n",
    "plt.plot(np.linspace(0,1000,1001), hlines[-1,1]*np.linspace(0,1000,1001)+hlines[-1,0],'k', alpha = 0.3)\n",
    "plt.plot(np.linspace(0,1000,1001), hlines[0,1]*np.linspace(0,1000,1001)+hlines[0,0]+edge_cutoff*pix2mm,'--k', alpha = 0.3)\n",
    "plt.plot(np.linspace(0,1000,1001), hlines[-1,1]*np.linspace(0,1000,1001)+hlines[-1,0]-edge_cutoff*pix2mm,'--k', alpha = 0.3)\n",
    "# plt.plot(np.linspace(0,550,551)*(1/vlines[vline_OI,1])- vlines[vline_OI,0]/vlines[vline_OI,1], np.linspace(0,550,551),'k', alpha = 0.3)\n",
    "# plt.plot(np.linspace(0,550,551)*(1/vlines[vline_OI,1])- vlines[vline_OI,0]/vlines[vline_OI,1]+pix2mm*vert_box_cutoff, np.linspace(0,550,551),':k', alpha = 0.3)\n",
    "# plt.plot(np.linspace(0,550,551)*(1/vlines[vline_OI,1])- vlines[vline_OI,0]/vlines[vline_OI,1]-pix2mm*vert_box_cutoff, np.linspace(0,550,551),':k', alpha = 0.3)\n",
    "plt.ylim([0,550])\n",
    "plt.xlim([0,1000])\n",
    "plt.axis('equal')\n",
    "plt.xlabel('x (pix)')\n",
    "plt.ylabel('y (pix)')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where in checkerboard for all dataframe\n",
    "\n",
    "def split_by_bool(arr, boo):\n",
    "    split_idcs = np.nonzero(boo[1:] != boo[:-1])[0]+1\n",
    "    split_arr = np.split(arr, split_idcs)\n",
    "    split_arr = [split_arr[0::2] if boo[0] else split_arr[1::2]]\n",
    "    return split_arr[0]\n",
    "\n",
    "\n",
    "def checkerboard_fraction_df(x, step_height_df):\n",
    "    subtypes = ['0mm', '1mm', '3mm', '5mm']\n",
    "\n",
    "    # collect data into easy to use variables\n",
    "    all_x = x['thorax_x_filt_fullfr']\n",
    "    all_y = x['thorax_y_filt_fullfr']\n",
    "    col_OI = x['colony']\n",
    "    sub_OI = x['substrate']\n",
    "\n",
    "    # find horizontal and vertical lines\n",
    "    step_height_OI = step_height_df[\n",
    "        step_height_df['substrate'].str.contains(sub_OI) & step_height_df['colony'].str.contains(col_OI)]\n",
    "    height_profile = step_height_OI['height_profile'].values[0]\n",
    "    vlines = step_height_OI['vlines'].values[0]\n",
    "    n_vlines = len(vlines)\n",
    "    hlines = step_height_OI['hlines'].values[0]\n",
    "    hlines_sep = np.diff(hlines[:,1]*500+hlines[:,0]) # if close-by hline it's a ledge and remove\n",
    "    where_ledge = np.where((np.median(hlines_sep)-hlines_sep)>30)[0]\n",
    "    if len(where_ledge)>0:\n",
    "        if where_ledge[0]==0:\n",
    "            hlines=np.delete(hlines,0,axis=0)\n",
    "        else:\n",
    "            hlines=np.delete(hlines,where_ledge[0]+1,axis=0)\n",
    "    n_hlines = len(hlines)\n",
    "\n",
    "    # find where close to middle vertical lines\n",
    "    vert_box_cutoff = 0.5 # in mm\n",
    "    where_in_vert_box = np.full(all_x.shape, False)\n",
    "    if sub_OI == '0mm':\n",
    "        vline_OI = 0\n",
    "        for vs in [1,3]:\n",
    "            a = np.mean(1/vlines[vline_OI:vline_OI+2,1])/2*vs\n",
    "            b = np.mean(vlines[vline_OI:vline_OI+2,0]/vlines[vline_OI:vline_OI+2,1])/2*vs\n",
    "            x_pred =all_y*a-b\n",
    "            temp = np.abs(all_x-x_pred)<(vert_box_cutoff*pix2mm)\n",
    "            where_in_vert_box = np.logical_or(temp, where_in_vert_box)\n",
    "    else:\n",
    "        for vs in [1,2]:\n",
    "            vline_OI = int(np.round(n_vlines/3*vs))-1\n",
    "            a = np.mean(1/vlines[vline_OI:vline_OI+2,1])\n",
    "            b = np.mean(vlines[vline_OI:vline_OI+2,0]/vlines[vline_OI:vline_OI+2,1])\n",
    "            x_pred =all_y*a-b\n",
    "            temp = np.abs(all_x-x_pred)<(vert_box_cutoff*pix2mm)\n",
    "            where_in_vert_box = np.logical_or(temp, where_in_vert_box)\n",
    "\n",
    "    # find if far from edges\n",
    "    edge_cutoff = [1.5, 1.5, 3, 2.4][subtypes.index(sub_OI)] # in mm\n",
    "    is_far_from_top = all_y>(all_x*hlines[0,1]+hlines[0,0]+edge_cutoff*pix2mm)\n",
    "    is_far_from_bottom = all_y<(all_x*hlines[-1,1]+hlines[-1,0]-edge_cutoff*pix2mm)\n",
    "    good_points = is_far_from_top & where_in_vert_box & is_far_from_bottom\n",
    "\n",
    "    # isolate trails through vertical box\n",
    "    x_chunks = split_by_bool(all_x, good_points)\n",
    "    y_chunks = split_by_bool(all_y, good_points)\n",
    "\n",
    "    y_box_fraction = []\n",
    "    checkerboard_height = []\n",
    "    if len(y_chunks)>0:\n",
    "        \n",
    "        # find average y_location\n",
    "        for cc in range(len(y_chunks)):\n",
    "            \n",
    "            if len(y_chunks[cc])>10:\n",
    "                \n",
    "                y_mean = np.median(y_chunks[cc])\n",
    "                x_mean = np.median(x_chunks[cc])\n",
    "                \n",
    "                # check if going straight through window\n",
    "                slope = (y_chunks[cc][-1]-y_chunks[cc][0])/(x_chunks[cc][-1]-x_chunks[cc][0])\n",
    "                max_divergence = np.max( np.abs( y_chunks[cc]-y_mean ))\n",
    "                if np.abs(slope) > 0.75:\n",
    "                    continue\n",
    "                elif max_divergence/pix2mm > 1/2:\n",
    "                    continue\n",
    "\n",
    "                # find where in checkerboard box\n",
    "                y_pred = hlines[:,1]*x_mean+hlines[:,0]\n",
    "                y_top = y_pred[y_mean>hlines[:,1]*x_mean+hlines[:,0]][-1]\n",
    "                y_bot = y_pred[y_mean<hlines[:,1]*x_mean+hlines[:,0]][0]\n",
    "                y_box_fraction =np.append(y_box_fraction, np.abs(y_mean-np.mean([y_top,y_bot]))/np.diff([y_top,y_bot])*2 )\n",
    "                \n",
    "                # find checkerboard height\n",
    "                if sub_OI == '0mm':\n",
    "                    checkerboard_height = np.append(checkerboard_height, 1)\n",
    "                else:\n",
    "                    row = np.where(y_mean<hlines[:,1]*x_mean+hlines[:,0])[0][0]-1\n",
    "                    col = np.where(x_mean<(1/vlines[:,1])*y_mean-vlines[:,0]/vlines[:,1])[0][0]-1\n",
    "                    checkerboard_height = np.append(checkerboard_height, height_profile[row,col])\n",
    "                \n",
    "    if len(y_box_fraction)>0:\n",
    "        return y_box_fraction, checkerboard_height\n",
    "    else:\n",
    "        return np.full(1,np.nan), np.full(1,np.nan)\n",
    "\n",
    "            \n",
    "\n",
    "df['vertical_checkerboard_fraction'], df['checkerboard_height'] =  zip(*df.apply(checkerboard_fraction_df, args = ( step_height_df,), axis=1))\n",
    "print('done calculated checkerboard fractions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram plot\n",
    "# plt.close('all')\n",
    "plt.figure()\n",
    "line_styles = ['--','-']\n",
    "\n",
    "precision = 50 # how many bins per 1 unit\n",
    "bins = np.linspace(0, 1, precision+1)\n",
    "\n",
    "for ss,subtype in enumerate(subtypes):\n",
    "    hist_OI_raw = np.hstack(df.loc[(df['substrate']==subtype) & (df['colony']!= coltypes[-1])]['vertical_checkerboard_fraction'].values)\n",
    "    heights = np.hstack(df.loc[(df['substrate']==subtype) & (df['colony']!= coltypes[-1])]['checkerboard_height'].values)\n",
    "    print('%i data points out of %i trailway chunks'%(np.sum(np.isfinite(hist_OI_raw)), len(hist_OI_raw)))\n",
    "    hist_OI= hist_OI_raw[np.isfinite(hist_OI_raw)]\n",
    "    heights= heights[np.isfinite(hist_OI_raw)]\n",
    "    \n",
    "    \n",
    "    # plot all together\n",
    "#     # find histogram counts\n",
    "#     h_counts = np.histogram(hist_OI, bins = bins)[0]\n",
    "#     plt.hist(hist_OI, bins = bins[:-1], color = pltcolors[ss], alpha = 0.2, weights = np.ones(hist_OI.shape)*(1/np.sum(h_counts)))\n",
    "#     h_counts = h_counts/np.sum(h_counts)\n",
    "#     plt.plot(bins[:-1][h_counts>0]+(1/(2*precision)), h_counts[h_counts>0], ':', color = pltcolors[ss])\n",
    "\n",
    "#     # lowpass filter histogram data\n",
    "#     b,a = signal.butter(2, 1/(precision/4))\n",
    "#     temp = signal.filtfilt(b,a, np.hstack([np.flipud(h_counts[h_counts>0]),h_counts[h_counts>0], np.flipud(h_counts[h_counts>0])]) , padlen = 10)\n",
    "#     h_counts_filt= temp[ len(h_counts[h_counts>0]):(2*len(h_counts[h_counts>0]))]\n",
    "#     plt.plot(bins[:-1][h_counts>0]+(1/(2*precision)), h_counts_filt, linestyle = line_styles[height], color = pltcolors[ss])\n",
    "#     plt.text(0.82, .06-ss*0.003, 'n: %i'%len(hist_OI), color  = pltcolors[ss])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # separate by height\n",
    "    for height in [0,1]:\n",
    "        \n",
    "        if len(hist_OI[heights==height])==0:\n",
    "            continue\n",
    "        \n",
    "        h_counts = np.histogram(hist_OI[heights==height], bins = bins)[0]\n",
    "        h_counts = h_counts/np.sum(h_counts)\n",
    "#         plt.plot(bins[:-1][h_counts>0]+(1/(2*precision)), h_counts[h_counts>0], ':', color = pltcolors[ss])\n",
    "    \n",
    "        # lowpass filter histogram data\n",
    "        b,a = signal.butter(2, 1/(precision/4))\n",
    "        temp = signal.filtfilt(b,a, np.hstack([np.flipud(h_counts[h_counts>0]),h_counts[h_counts>0], np.flipud(h_counts[h_counts>0])]) , padlen = 10)\n",
    "        h_counts_filt= temp[ len(h_counts[h_counts>0]):(2*len(h_counts[h_counts>0]))]\n",
    "        plt.plot(bins[:-1][h_counts>0]+(1/(2*precision)), h_counts_filt, linestyle = line_styles[height], color = pltcolors[ss])\n",
    "        plt.text(0.72+height/10, .06-ss*0.003, 'n: %i'%len(hist_OI[heights==height]), color  = pltcolors[ss])\n",
    "        plt.ylim([0,0.07])\n",
    "\n",
    "plt.xlabel('center  <---->  edge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot TDs on video image to see foot placement strategies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_num = 1332\n",
    "fr_range = [14, 300]\n",
    "\n",
    "# 0 mm - 79 - 25, 200\n",
    "# 1 mm - 412 - 548,680\n",
    "# 3 mm - 824 - 193,430\n",
    "# 5 mm - 1332 - 14, 300\n",
    "\n",
    "file_idc = np.where(np.array(['%s_%s'%(df['date'][tr_num],df['time'][tr_num]) in f for f in file_list]))[0][0]\n",
    "file = file_list[file_idc]\n",
    "print(file)\n",
    "lcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "jcolors = ['xkcd:goldenrod',  'xkcd:crimson', 'xkcd:fuchsia',  'xkcd:green', 'xkcd:azure', 'xkcd:aqua']\n",
    "linetypes = ['-.',':','--']\n",
    "ss= np.where(['1mm'== s for s in subtypes])[0][0]\n",
    "# ['xkcd:aqua', 'xkcd:azure', 'xkcd:crimson', 'xkcd:fuchsia', 'xkcd:goldenrod', 'xkcd:green']\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "cap = cv2.VideoCapture(file)\n",
    "width = int(cap.get(3))\n",
    "height = int(cap.get(4))\n",
    "vid_length = np.min([int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),500])\n",
    "rgb_convert = np.array([[[0.2989]],[[0.5870]],[[0.1140]]]).T\n",
    "frames_to_read = fr_range #np.arange(0,vid_length,100)]\n",
    "frames = np.zeros((len(frames_to_read), height, width), np.uint8)\n",
    "for kk in range(0,len(frames_to_read)):\n",
    "    fr_OI=frames_to_read[kk]\n",
    "    cap.set(1,fr_OI)\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame2 = cap.read()\n",
    "    if ret:\n",
    "        frames[kk,:,:] = np.sum(frame2*rgb_convert, axis = 2)\n",
    "    else:\n",
    "        print('couldnt get frame')\n",
    "cap.release()\n",
    "img = np.mean(frames, axis = 0)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (13,7))\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "\n",
    "\n",
    "if df['substrate'][tr_num] != '0mm':\n",
    "    lname = ('/').join(file_list[0].split('/')[:-2]) + '/%s/%s_%s_Step_Height.pkl'%(\n",
    "        df['substrate'][tr_num], df['colony'][tr_num], df['substrate'][tr_num])\n",
    "    with open(lname, 'rb') as f:\n",
    "        hlines, vlines, height_profile,_ = pickle.load(f)\n",
    "        plt.plot()\n",
    "    f.close()\n",
    "    plt.plot( np.repeat(np.array([0,1000])[:,np.newaxis],len(hlines), axis =1) , \n",
    "             np.array([hlines[:,0], hlines[:,0]+hlines[:,1]*1000]), '-', color = lcolors[ss], alpha = 0.2)\n",
    "    plt.plot(np.array([-1*vlines[:,0]/vlines[:,1], -1*vlines[:,0]/vlines[:,1]+1/vlines[:,1]*1000])  , \n",
    "             np.repeat(np.array([0,550])[:,np.newaxis],len(vlines), axis =1) ,  '-', color = lcolors[ss], alpha = 0.2)\n",
    "\n",
    "    \n",
    "for jj in range(0,6):\n",
    "    idcs = df['joint%i_TD_idcs'%jj][tr_num]\n",
    "    idcs_OI = idcs[np.logical_and(df['frames'][tr_num][idcs]>=fr_range[0]-10, df['frames'][tr_num][idcs]<=fr_range[1]+5)]\n",
    "    xs = df['joint%i_x_filt_fullfr'%jj][tr_num][idcs_OI]\n",
    "    ys = df['joint%i_y_filt_fullfr'%jj][tr_num][idcs_OI]\n",
    "#     plt.xlim([0,1000])\n",
    "#     plt.ylim([550,0])\n",
    "#     print(xs)\n",
    "    plt.plot(xs, ys, '.', color = jcolors[jj])\n",
    "\n",
    "\n",
    "    \n",
    "plt.figure(figsize = (15,4))\n",
    "for jj in range(0,6):\n",
    "    plt.subplot(2,1,(jj%2)+1)\n",
    "    idcs = df['joint%i_TD_idcs'%jj][tr_num]\n",
    "    idcs_OI = idcs[np.logical_and(df['frames'][tr_num][idcs]>=fr_range[0]-10, df['frames'][tr_num][idcs]<=fr_range[1]+10)]\n",
    "    plt.plot(df['frames'][tr_num][:-1], df['joint%i_vel'%jj][tr_num],'-',color = jcolors[jj])\n",
    "    plt.plot(df['frames'][tr_num][np.array([idcs_OI,idcs_OI])], np.repeat(np.array([0,10])[:,np.newaxis],len(idcs_OI), axis =1), \n",
    "             color = jcolors[jj], linestyle = linetypes[jj%3], alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check follow the leader foot placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ONE TRIAL (TEST OUT ANALYSIS)\n",
    "tr=300\n",
    "x=df\n",
    "\n",
    "for joint_num in [0,1,3,4]:\n",
    "    \n",
    "    if not np.any(np.isfinite(x['joint%i_x_filt_fullfr'%joint_num][tr])): # not just a single nan\n",
    "        print('no data for filt_fullfr data')\n",
    "        continue\n",
    "    if not np.any(np.isfinite(x['joint%i_x_filt_fullfr'%(joint_num+1)][tr])): # not just a single nan\n",
    "        print('no data for filt_fullfr data')\n",
    "        continue\n",
    "    \n",
    "    # posterior limb info\n",
    "    post_x = x['joint%i_x_filt_fullfr'%joint_num][tr]\n",
    "    post_y = x['joint%i_y_filt_fullfr'%joint_num][tr]\n",
    "    post_TD_starts = x['joint%i_TD_idcs'%joint_num][tr][:-1][x['joint%i_good_strides'%joint_num][tr]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    post_TD_stops = x['joint%i_TD_idcs'%joint_num][tr][1:][x['joint%i_good_strides'%joint_num][tr]]\n",
    "    \n",
    "    # anterior limb info\n",
    "    ant_x = x['joint%i_x_filt_fullfr'%(joint_num+1)][tr]\n",
    "    ant_y = x['joint%i_y_filt_fullfr'%(joint_num+1)][tr]\n",
    "    ant_TD_starts = x['joint%i_TD_idcs'%(joint_num+1)][tr][:-1][x['joint%i_good_strides'%(joint_num+1)][tr]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    ant_TD_stops = x['joint%i_TD_idcs'%(joint_num+1)][tr][1:][x['joint%i_good_strides'%(joint_num+1)][tr]]\n",
    "\n",
    "    all_dists = []\n",
    "    St_idcs = []\n",
    "    d_xy = np.full((1,2),np.nan)\n",
    "    print('post TD stops: ', x['frames'][tr][post_TD_stops])\n",
    "    final_post_TD_stops=post_TD_stops.copy().astype(float )\n",
    "    for post_idc in range(0,len(post_TD_stops)):\n",
    "#         print(post_TD_stops[post_idc], np.logical_and(ant_TD_starts<post_TD_stops[post_idc],ant_TD_stops>post_TD_stops[post_idc]))\n",
    "        ant_idc = np.where(np.logical_and(post_TD_stops[post_idc]-ant_TD_starts > 7, ant_TD_stops-post_TD_stops[post_idc]>7))[0]\n",
    "        if len(ant_idc)<2:\n",
    "            if np.isfinite(ant_idc):\n",
    "                ant_loc = np.hstack([ant_x[ant_TD_starts[ant_idc[0]]],  ant_y[ant_TD_starts[ant_idc[0]]]])\n",
    "                post_loc = np.hstack( [post_x[post_TD_stops[post_idc]],  post_y[post_TD_stops[post_idc]]])\n",
    "                d_xy = np.append(d_xy, np.array([post_loc-ant_loc])/pix2mm, axis = 0)\n",
    "                dist = np.linalg.norm([post_loc-ant_loc])/pix2mm\n",
    "                all_dists.append(dist)\n",
    "                Stride_angle = np.abs(x['joint%i_St_travel_dir'%(joint_num+1)][tr][ant_idc])\n",
    "                St_idcs.append( Stride_angle <=15)\n",
    "                frame_OI = x['frames'][tr][post_TD_stops[post_idc]]\n",
    "                print('joint %i, frame %i, dist = %0.2f mm, turning = %0.1f'%(joint_num, frame_OI, dist, Stride_angle))\n",
    "            else:\n",
    "                final_post_TD_stops[post_idc]=np.nan\n",
    "        else:\n",
    "            final_post_TD_stops[post_idc]=np.nan\n",
    "            \n",
    "    final_post_TD_stops = final_post_TD_stops[~np.isnan(final_post_TD_stops)].astype(np.uint8)\n",
    "    dx = d_xy[1:,0]\n",
    "    dy = d_xy[1:,1]\n",
    "    \n",
    "    \n",
    "    # rotate dxy wrt ant facing\n",
    "    if np.any(final_post_TD_stops):\n",
    "#         print(x['frames'][tr][final_post_TD_stops])\n",
    "        thorax_x = x['thorax_x_filt_fullfr'][tr][final_post_TD_stops]\n",
    "        thorax_y = x['thorax_y_filt_fullfr'][tr][final_post_TD_stops]\n",
    "        neck_x = x['neck_x_filt_fullfr'][tr][final_post_TD_stops]\n",
    "        neck_y = x['neck_y_filt_fullfr'][tr][final_post_TD_stops]\n",
    "    \n",
    "        val_coord = np.array([dx,dy])#-np.array([thorax_x,thorax_y])\n",
    "        neck_coord = np.array([neck_x-thorax_x,neck_y-thorax_y])\n",
    "        ang = np.arctan2( (neck_y-thorax_y),(neck_x-thorax_x))\n",
    "#         print(np.rad2deg(ang))\n",
    "        c, s = np.cos(ang), np.sin(ang)\n",
    "        Rx = np.array([c,s])\n",
    "        Ry = np.array([-s,c])\n",
    "        newx = np.einsum('mn,mn->n', val_coord, Rx)\n",
    "        newy = np.einsum('mn,mn->n', val_coord, Ry)\n",
    "    else:\n",
    "        newx = dx\n",
    "        newy = dy\n",
    "#     print(dx,dy, ' to ', newx, newy)\n",
    "                \n",
    "# del x, post_x, post_y, post_TD_starts, post_TD_stops\n",
    "# del ant_x, ant_y, ant_TD_starts, ant_TD_stops\n",
    "# del all_dists, St_idcs, d_xy\n",
    "# del Stride_angle, frame_OI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TD_dists_df(x, joint_num):\n",
    "    \n",
    "    if not np.any(np.isfinite(x['joint%i_x_filt_fullfr'%joint_num])): # not just a single nan\n",
    "        return [],[],[],[]\n",
    "    if not np.any(np.isfinite(x['joint%i_x_filt_fullfr'%(joint_num+1)])): # not just a single nan\n",
    "        return [],[],[],[]\n",
    "    \n",
    "    # posterior limb info\n",
    "    post_x = x['joint%i_x_filt_fullfr'%joint_num]\n",
    "    post_y = x['joint%i_y_filt_fullfr'%joint_num]\n",
    "    post_TD_starts = x['joint%i_TD_idcs'%joint_num][:-1][x['joint%i_good_strides'%joint_num]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    post_TD_stops = x['joint%i_TD_idcs'%joint_num][1:][x['joint%i_good_strides'%joint_num]]\n",
    "    \n",
    "    # anterior limb info\n",
    "    ant_x = x['joint%i_x_filt_fullfr'%(joint_num+1)]\n",
    "    ant_y = x['joint%i_y_filt_fullfr'%(joint_num+1)]\n",
    "    ant_TD_starts = x['joint%i_TD_idcs'%(joint_num+1)][:-1][x['joint%i_good_strides'%(joint_num+1)]] # USING ONLY TRUSTED STRIDES, NOT ALL TDs\n",
    "    ant_TD_stops = x['joint%i_TD_idcs'%(joint_num+1)][1:][x['joint%i_good_strides'%(joint_num+1)]]\n",
    "\n",
    "    all_dists = []\n",
    "    St_angles = []\n",
    "    d_xy = np.full((1,2),np.nan)\n",
    "    final_post_TD_stops = post_TD_stops.copy().astype(float)\n",
    "    for post_idc in range(0,len(post_TD_stops)):\n",
    "        ant_idc = np.where(np.logical_and(post_TD_stops[post_idc]-ant_TD_starts > 7, ant_TD_stops-post_TD_stops[post_idc]>7))[0]\n",
    "        if len(ant_idc)<2:\n",
    "            if np.isfinite(ant_idc):\n",
    "                ant_loc = np.hstack([ant_x[ant_TD_starts[ant_idc][0]],  ant_y[ant_TD_starts[ant_idc][0]]])\n",
    "                post_loc = np.hstack( [post_x[post_TD_stops[post_idc]],  post_y[post_TD_stops[post_idc]]])\n",
    "                d_xy = np.append(d_xy, np.array([post_loc-ant_loc])/pix2mm, axis = 0)\n",
    "                dist = np.linalg.norm([post_loc-ant_loc])/pix2mm\n",
    "                all_dists.append(dist)\n",
    "                Stride_angle = np.abs(x['joint%i_St_travel_dir'%(joint_num+1)][ant_idc])\n",
    "                St_angles.append( (Stride_angle <=15)[0])\n",
    "    #             print(ant_loc, post_loc, 'dist = %0.2f mm'%dist)\n",
    "            else:\n",
    "                final_post_TD_stops[post_idc]=np.nan\n",
    "        else:\n",
    "            final_post_TD_stops[post_idc]=np.nan\n",
    "    \n",
    "    final_post_TD_stops = final_post_TD_stops[~np.isnan(final_post_TD_stops)].astype(np.uint8)\n",
    "    dx = d_xy[1:,0]\n",
    "    dy = d_xy[1:,1]\n",
    "\n",
    "    # rotate dxy wrt ant facing\n",
    "    if np.any(final_post_TD_stops):\n",
    "        thorax_x = x['thorax_x_filt_fullfr'][final_post_TD_stops]\n",
    "        thorax_y = x['thorax_y_filt_fullfr'][final_post_TD_stops]\n",
    "        neck_x = x['neck_x_filt_fullfr'][final_post_TD_stops]\n",
    "        neck_y = x['neck_y_filt_fullfr'][final_post_TD_stops]\n",
    "        val_coord = np.array([dx,dy])\n",
    "        ang = np.arctan2( (neck_y-thorax_y),(neck_x-thorax_x))\n",
    "        c, s = np.cos(ang), np.sin(ang)\n",
    "        Rx = np.array([c,s])\n",
    "        Ry = np.array([-s,c])\n",
    "        newx = np.einsum('mn,mn->n', val_coord, Rx)\n",
    "        newy = np.einsum('mn,mn->n', val_coord, Ry)\n",
    "    else:\n",
    "        newx = dx\n",
    "        newy = dy\n",
    "\n",
    "    return np.array(all_dists), newx, newy, np.array(St_angles)\n",
    "\n",
    "\n",
    "# compile data of TD locations and heights\n",
    "print('\\ncalculating step distances')\n",
    "for joint_num in [0,1,3,4]:\n",
    "    print(joint_num)\n",
    "    df['joint%i_TD_dists'%joint_num], df['joint%i_TD_dist_x'%joint_num], df['joint%i_TD_dist_y'%joint_num] , df['joint%i_TD_dist_idcs'%joint_num]= zip(*\n",
    "                                df.apply(get_TD_dists_df, args = (joint_num, ), axis=1))\n",
    "\n",
    "print('\\nDone analyzing step distances!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  distribution plot of anterior-posterior step distances\n",
    "plt.close('all')\n",
    "subtypes = sorted(df['substrate'].unique())\n",
    "coltypes = sorted(df['colony'].unique())\n",
    "\n",
    "\n",
    "df['TD_dists_all'] = df.filter(regex='_TD_dists$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1) \n",
    "df['TD_dist_x_all'] = df.filter(regex='_TD_dist_x$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1) \n",
    "df['TD_dist_y_all'] = df.filter(regex='_TD_dist_y$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1) \n",
    "df['TD_dist_straight'] = df.filter(regex='_TD_dist_idcs$', axis=1).apply(lambda x: np.concatenate(np.concatenate([x], axis = 0)), axis = 1)\n",
    "df['TD_dist_jointID'] = df.filter(regex='_TD_dists$', axis=1).applymap(lambda x: len(x)).apply(\n",
    "    lambda x: np.concatenate([x]), axis = 1).map(\n",
    "    lambda x: np.repeat([0,1,3,4], x))\n",
    "\n",
    "lens = [len(item) for item in df['TD_dists_all']]\n",
    "all_TD_dists = pd.DataFrame( {\"substrate\" : np.repeat(df['substrate'].values, lens), \"trackway\" : np.repeat(df.index.values, lens),\n",
    "                        \"colony\" : np.repeat(df['colony'].values, lens), \"TD_dists_all\" : np.concatenate(df['TD_dists_all'].values),\n",
    "                        \"TD_dist_x_all\" : np.concatenate(df['TD_dist_x_all'].values), \"TD_dist_y_all\" : np.concatenate(df['TD_dist_y_all'].values),\n",
    "                        \"TD_dist_straight\" : np.concatenate(df['TD_dist_straight'].values).astype(bool), \"TD_dist_jointID\" : np.concatenate(df['TD_dist_jointID'].values)})\n",
    "\n",
    "\n",
    "pltcolors = ['#B1740F', '#BA4246', '#087E8B', '#701C6F']\n",
    "sp_max = 3\n",
    "precision = 20 # how many bins per 1 unit\n",
    "bins = np.linspace(0,sp_max, sp_max*precision+1)\n",
    "\n",
    "for ss,subtype in enumerate(subtypes[0:4]):\n",
    "    print(subtype)\n",
    "#     sub_df = all_TD_dists.loc[(all_TD_dists['substrate']==subtype) & (all_TD_dists['colony']!=coltypes[-1])]\n",
    "    vals = all_TD_dists.loc[(all_TD_dists['substrate']==subtype) & \n",
    "                                   (all_TD_dists['colony']!=coltypes[-1]) &\n",
    "                                   (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all']\n",
    "    sns.distplot(  vals , bins = bins, color = pltcolors[ss], kde_kws={'clip': (np.min(vals), np.max(vals))})\n",
    "    \n",
    "#     # combine all joints together\n",
    "#     vals_OI = sub_df['TD_dists_all'].values\n",
    "#     straight_vals = sub_df['TD_dist_straight'].values.astype(bool)\n",
    "#     hist_OI = np.histogram(vals_OI[straight_vals], bins, density = True)[0]\n",
    "# #     hist_OI = vals_OI.mean()\n",
    "#     plt.bar(bins[:-1], hist_OI , width =1/precision, color = pltcolors[ss], alpha = 0.3, align = 'edge')\n",
    "# #     kde_data = np.repeat(bins[:-1]+1/(2*precision),np.round((hist_OI*10000)).astype(int))\n",
    "# #     kde = stats.gaussian_kde(kde_data)\n",
    "# #     kde_fit = kde.evaluate(bins[:-1])/precision\n",
    "# # #     if ss == 0:\n",
    "# # #         ref_speed = bins[np.argmax(kde_fit)]+1/(2*precision)\n",
    "# # #     plt.axvline(x=ref_speed, ymin = 0, ymax = 1, color = 'k', linestyle = ':', alpha = 0.4)\n",
    "# #     plt.plot(bins[:-1][hist_OI != 0]+1/(2*precision), kde_fit[hist_OI != 0], '-', color = pltcolors[ss], alpha = 0.4)\n",
    "    n_pts = len(all_TD_dists.loc[(all_TD_dists['substrate']==subtype) & \n",
    "                                   (all_TD_dists['colony']!=coltypes[-1]) &\n",
    "                                   (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all'] )\n",
    "    plt.text(2, 2-ss*0.2, 'n: %i'%n_pts, color = pltcolors[ss], alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc if distributions are sig diff\n",
    "for ss,subtype in enumerate(subtypes[0:4]):\n",
    "    vals_0 = all_TD_dists.loc[(all_TD_dists['substrate']==subtype) & \n",
    "                                   (all_TD_dists['colony']!=coltypes[-1]) &\n",
    "                                   (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all']\n",
    "    for comp in range(ss+1, 4):\n",
    "        vals_1 = all_TD_dists.loc[(all_TD_dists['substrate']==subtypes[comp]) & \n",
    "                                   (all_TD_dists['colony']!=coltypes[-1]) &\n",
    "                                   (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all']\n",
    "        pval = stats.ttest_ind(vals_0, vals_1, equal_var = False)[1]\n",
    "        print('\\ncompare %s and %s: p = '%(subtype, subtypes[comp]), pval, ' -- means: %0.2f vs. %0.2f'%(np.mean(vals_0), np.mean(vals_1)))\n",
    "        \n",
    "        # perform whitney mann comparison (doesn't assume normally-distributed)\n",
    "        _, pval = stats.ranksums(vals_0, vals_1)\n",
    "        print('Mann-Whitney-Wilcox: p = ', pval)\n",
    "\n",
    "print('\\nanova comparing all groups')\n",
    "_, p_val = stats.f_oneway( all_TD_dists.loc[(all_TD_dists['substrate']==subtypes[0]) & (all_TD_dists['colony']!=coltypes[-1]) & (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all'], \n",
    "                         all_TD_dists.loc[(all_TD_dists['substrate']==subtypes[1]) & (all_TD_dists['colony']!=coltypes[-1]) & (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all'], \n",
    "                         all_TD_dists.loc[(all_TD_dists['substrate']==subtypes[2]) & (all_TD_dists['colony']!=coltypes[-1]) & (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all'], \n",
    "                         all_TD_dists.loc[(all_TD_dists['substrate']==subtypes[3]) & (all_TD_dists['colony']!=coltypes[-1]) & (all_TD_dists['TD_dist_straight']==True)]['TD_dists_all'], \n",
    "                         )\n",
    "print('anova p-val: ', p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot location of TD relative to anterior step\n",
    "plt.close('all')\n",
    "\n",
    "def WRTant_to_WRTneck_df(df, ant_part):\n",
    "    x = df['%s_x_filt'%ant_part]\n",
    "    y = df['%s_y_filt'%ant_part]\n",
    "    thorax_x = df['thorax_x_filt']\n",
    "    thorax_y = df['thorax_y_filt']\n",
    "    neck_x = df['neck_x_filt']\n",
    "    neck_y = df['neck_y_filt']\n",
    "    \n",
    "    val_coord = np.array([x,y])-np.array([thorax_x,thorax_y])\n",
    "    neck_coord = np.array([neck_x-thorax_x,neck_y-thorax_y])\n",
    "    ang = np.arctan( (neck_y-thorax_y)/(neck_x-thorax_x))\n",
    "    c, s = np.cos(ang), np.sin(ang)\n",
    "    Rx = np.array([c,s])\n",
    "    Ry = np.array([-s,c])\n",
    "    newx = np.einsum('mn,mn->n', val_coord, Rx)\n",
    "    newy = np.einsum('mn,mn->n', val_coord, Ry)\n",
    "    return newx, newy\n",
    "\n",
    "def plot_convex_hull(points, pltcolors, ss_num):\n",
    "    hull = ConvexHull(points)\n",
    "    cent =np.mean(points, 0)\n",
    "    pts = []\n",
    "    for pt in points[hull.simplices]:\n",
    "        pts.append(pt[0].tolist())\n",
    "        pts.append(pt[1].tolist())\n",
    "    pts.sort(key=lambda p: np.arctan2(p[1]-cent[1], p[0] - cent[0]))\n",
    "    pts = pts[0::2]\n",
    "    pts.insert(len(pts), pts[0])\n",
    "    k= 1.0\n",
    "    poly = Polygon(k*(np.array(pts)-cent) + cent, closed = True, facecolor = pltcolors[ss_num], alpha = 0.05)\n",
    "    poly.set_capstyle('round')\n",
    "    plt.gca().add_patch(poly)\n",
    "    plt.plot(cent[0],cent[1],'.', color = pltcolors[ss_num])\n",
    "    return \n",
    "\n",
    "def plt_pca_ellipse(points, pltcolors, ss_num):\n",
    "    \n",
    "    cent =np.mean(points, axis = 0)\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit_transform(points)\n",
    "    projected = pca.transform(points)\n",
    "    a = np.linalg.norm(pca.inverse_transform([np.std(projected, axis =0)[0],0])-cent)\n",
    "    b = np.linalg.norm(pca.inverse_transform([np.std(projected, axis =0)[1],0])-cent)\n",
    "    new_unit =pca.inverse_transform([1,0])-cent\n",
    "    el_angle = np.rad2deg(np.arctan2(new_unit[1], new_unit[0]))\n",
    "    lstyle = '-'\n",
    "    xoffset = 0\n",
    "\n",
    "    el = Ellipse(cent, 2*a, 2*b, angle = el_angle, ec = pltcolors[ss_num], fc = 'None', LineStyle = lstyle)\n",
    "    plt.gca().add_patch(el)\n",
    "    el = Ellipse(cent, 2*1.96*a, 2*1.96*b, angle = el_angle, ec = pltcolors[ss_num], fc = 'None', LineStyle = lstyle)\n",
    "    plt.gca().add_patch(el)\n",
    "#     plt.text(-100 + xoffset, -115 + 10*joint_num, '%i'%len(points), color = pltcolors[joint_num])\n",
    "#     SD = np.sqrt(a*b) # radius of circle with same area as ellipse\n",
    "#     plt.text(-60 + xoffset, -115 + 10*joint_num, '%0.1f'%SD, color = pltcolors[joint_num])\n",
    "    return \n",
    "\n",
    "plt.figure(figsize = (5,5))\n",
    "sp_order = [3,1,4,2]\n",
    "for ff,foot in enumerate([0,1,3,4]):\n",
    "    plt.subplot(2,2,sp_order[ff])\n",
    "    for ss,subtype in enumerate(subtypes[0:4]):\n",
    "        \n",
    "        vals_0 = all_TD_dists.loc[(all_TD_dists['substrate']==subtype) & (all_TD_dists['colony']!=coltypes[-1]) &\n",
    "                                    (all_TD_dists['TD_dist_straight']==True) & (all_TD_dists['TD_dist_jointID']==foot)]['TD_dist_x_all'].values\n",
    "        vals_1 = all_TD_dists.loc[(all_TD_dists['substrate']==subtype) & (all_TD_dists['colony']!=coltypes[-1]) &\n",
    "                                    (all_TD_dists['TD_dist_straight']==True) & (all_TD_dists['TD_dist_jointID']==foot)]['TD_dist_y_all'].values\n",
    "        tmp = vals_0\n",
    "        vals_0=vals_0[~np.logical_or(np.isnan(tmp),np.isnan(vals_1))]\n",
    "        vals_1=vals_1[~np.logical_or(np.isnan(tmp),np.isnan(vals_1))]\n",
    "        del tmp\n",
    "        plot_convex_hull(np.array([vals_1,vals_0]).T, pltcolors, ss)\n",
    "        plt_pca_ellipse(np.array([vals_1,vals_0]).T, pltcolors, ss)\n",
    "        plt.text((ss-2),-1.8,'%i'%len(vals_0), color = pltcolors[ss])\n",
    "    plt.text(0.5,1.5,'%i wrt %i'%(foot, foot+1))\n",
    "    \n",
    "    plt.xlim(-2,2)\n",
    "    plt.ylim(-2,2)\n",
    "#         plt.plot(vals_1,vals_0, '.', color = pltcolors[ss], alpha = 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to delete a bunch of columns from a dataframe\n",
    "\n",
    "# for joint_num in range(0,6):\n",
    "#     columns_to_drop = ['TD_dists_all', 'TD_dist_x', 'TD_dist_y', 'TD_dist_idcs',\n",
    "#                       'joint%i_TD_dists'%joint_num, 'joint%i_TD_dist_x'%joint_num, 'joint%i_TD_dist_y'%joint_num, 'joint%i_TD_dist_idcs'%joint_num]\n",
    "#     for colmn in columns_to_drop:\n",
    "#         if colmn in df: # remove columns if already exist\n",
    "#             df = df.drop(colmn, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOVED TO OWN NOTEBOOK: MODEL where ant limbs can touchdown based on body location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close('all')\n",
    "import itertools\n",
    "from scipy.linalg import toeplitz\n",
    "\n",
    "# USER INPUT\n",
    "for box_size in [1,3,5]:\n",
    "    \n",
    "    # box_size = 1\n",
    "    precision = box_size/50\n",
    "    plot_things = False\n",
    "    print('box_size is %i, precision %i'%(box_size, precision))\n",
    "\n",
    "\n",
    "    data = []\n",
    "    plt.close('all')\n",
    "\n",
    "    floor_x_range = [-5,10]\n",
    "    floor_y_range = [-5,10]\n",
    "    h_lines = np.hstack([np.flip(-1*np.arange(0,5,box_size)[1:], axis =0),np.arange(0,10,box_size)])\n",
    "    v_lines = np.hstack([np.flip(-1*np.arange(0,5,box_size)[1:], axis =0),np.arange(0,10,box_size)])\n",
    "    heights = toeplitz(np.arange(0,len(h_lines))%2,r=np.arange(0,len(v_lines))%2)-1\n",
    "    colors = ['grey','silver']\n",
    "\n",
    "    # neutral conditions\n",
    "    neutral_body_height = 2/3\n",
    "    flatX=np.mean(np.reshape(footX[1,0,:],[2,3]).T,axis=1)/pix2mm # ave across R and L to get symmetrical --> hind, mid, fore\n",
    "    flatY=np.mean(np.abs(np.reshape(footY[1,0,:],[2,3])).T,axis=1)/pix2mm * [1,-1,1]\n",
    "    leg_lengths = np.linalg.norm(np.array([flatX,flatY,neutral_body_height*np.ones(3)]),axis=0) # leg lengths from stance\n",
    "    leg_lengths = leg_lengths*1.1\n",
    "\n",
    "    # for a given body location\n",
    "    for body_height in neutral_body_height+np.linspace(0,-1,10):\n",
    "        print(body_height)\n",
    "        dict_to_df = {}\n",
    "\n",
    "        # initialize figure\n",
    "        if plot_things:\n",
    "            plt.figure()\n",
    "            plt.title('body height = %0.2f mm'%body_height)\n",
    "            for hh,h in enumerate(h_lines[:-1]):\n",
    "                for vv,v in enumerate(v_lines[:-1]):\n",
    "                    rect = patches.Rectangle((h,v), box_size, box_size, color = colors[heights[hh,vv]+1])\n",
    "                    plt.gca().add_patch(rect)\n",
    "                    plt.show()\n",
    "            plt.xlim(floor_x_range)\n",
    "            plt.xlim(floor_y_range)\n",
    "            plt.axis('equal')\n",
    "\n",
    "        for body_y in np.arange(0,box_size+precision, precision):\n",
    "\n",
    "            for body_x in np.arange(0,2*box_size+precision, precision):\n",
    "                foot_xs, foot_ys, foot_thetas, foot_phis, foot_dists, foot_heights = np.full((2,3),np.nan), np.full((2,3),np.nan), np.full((2,3),np.nan), np.full((2,3),np.nan), np.full((2,3),np.nan), np.full((2,3),np.nan)\n",
    "\n",
    "                body_loc = [body_x,body_y]\n",
    "\n",
    "                if plot_things:\n",
    "                    plt.plot(body_x,body_y,'+k')\n",
    "                    foot_colors = ['r','g','b']\n",
    "                    line_styles = ['--','-']\n",
    "\n",
    "                # for each foot, \n",
    "                for ff in [0,1,2]:\n",
    "                    foot_x = body_loc[0]+flatX[ff]\n",
    "                    foot_y = body_loc[1]+flatY[ff]\n",
    "                    angOI = np.arctan2(flatY[ff],flatX[ff])\n",
    "\n",
    "                    if plot_things:\n",
    "                        plt.plot(foot_x,foot_y, '+', color = foot_colors[ff], alpha = 0.5)\n",
    "\n",
    "                    for zz in [-1,0]: \n",
    "\n",
    "                        if body_height-zz>leg_lengths[ff]: # if leg can't touch surface\n",
    "                            continue\n",
    "\n",
    "                        # find best touchdown location on that surface\n",
    "                        r= (leg_lengths[ff]**2-(zz-body_height)**2)**(1/2) \n",
    "                        thetas = np.arange(-180,180,0.1)\n",
    "                        arc_xs = r*np.cos(np.deg2rad(thetas))+body_x\n",
    "                        arc_ys = r*np.sin(np.deg2rad(thetas))+body_y\n",
    "                        arc_rows = np.argmax(np.repeat(arc_ys[np.newaxis,:],len(v_lines),axis=0)<np.repeat(v_lines[:,np.newaxis],len(thetas),axis = 1), axis =0)-1\n",
    "                        arc_cols = np.argmax(np.repeat(arc_xs[np.newaxis,:],len(h_lines),axis=0)<np.repeat(h_lines[:,np.newaxis],len(thetas),axis = 1), axis =0)-1\n",
    "                        arc_heights = heights[arc_rows,arc_cols]\n",
    "                        good_thetas = (arc_heights ==zz) & (np.abs(thetas-np.rad2deg(angOI))<30) & (np.sign(thetas)==np.sign(angOI))\n",
    "                        arc_dist_to_neutral = np.linalg.norm(np.vstack([arc_xs-foot_x,arc_ys-foot_y]),axis =0)\n",
    "                        if np.sum(good_thetas)==0:\n",
    "                            continue\n",
    "                        theta_min = np.min(thetas[good_thetas])\n",
    "                        theta_max = np.max(thetas[good_thetas])\n",
    "                        tmp = arc_dist_to_neutral.copy().astype(float)\n",
    "                        tmp[np.logical_not(good_thetas)]=np.nan\n",
    "                        best_theta_idc = np.nanargmin(tmp)\n",
    "                        del tmp\n",
    "\n",
    "                        if plot_things:\n",
    "                            h_arc = patches.Arc(body_loc, 2*r, 2*r, angle = 0, theta1=theta_min, theta2=theta_max , color = foot_colors[ff], \n",
    "                                            linestyle = line_styles[zz+1], alpha = 0.8)\n",
    "                            plt.gca().add_patch(h_arc)\n",
    "                            plt.plot(arc_xs[best_theta_idc], arc_ys[best_theta_idc], '.', color = foot_colors[ff], alpha = 0.5)\n",
    "                            plt.plot()\n",
    "                            plt.show()\n",
    "\n",
    "                        # save to variables\n",
    "                        foot_xs[zz+1,ff]=arc_xs[best_theta_idc]\n",
    "                        foot_ys[zz+1,ff]=arc_ys[best_theta_idc]\n",
    "                        foot_thetas[zz+1,ff]=thetas[best_theta_idc]\n",
    "                        foot_phis[zz+1,ff]=np.rad2deg(np.arccos(r/leg_lengths[ff]))\n",
    "                        foot_dists[zz+1,ff]=arc_dist_to_neutral[best_theta_idc]\n",
    "                        foot_heights[zz+1,ff]=arc_heights[best_theta_idc]\n",
    "\n",
    "                # append data for each valid stance\n",
    "                tmp =foot_xs.copy()\n",
    "                tmp[np.isfinite(tmp)]=np.sum(np.argwhere(np.isfinite(foot_xs))*np.array([3,1]),axis=1)\n",
    "                list_of_TDs = [i[np.isfinite(i)].astype(int).tolist() for i in np.split(tmp.T,3, axis =0)]\n",
    "                if len(list_of_TDs)<3:\n",
    "                    continue\n",
    "                stance_idcs = list(itertools.product(*list_of_TDs))\n",
    "                for ss in range(len(stance_idcs)):\n",
    "                    dict_to_df['box_size']=box_size\n",
    "                    dict_to_df['body_x']=body_x\n",
    "                    dict_to_df['body_y']=body_y\n",
    "                    dict_to_df['body_z']=body_height\n",
    "                    dict_to_df['foot_xs']=foot_xs.flatten()[np.array(stance_idcs[ss])]\n",
    "                    dict_to_df['foot_ys']=foot_ys.flatten()[np.array(stance_idcs[ss])]\n",
    "                    dict_to_df['foot_d_xs']=foot_xs.flatten()[np.array(stance_idcs[ss])] - (body_loc[0]+flatX)\n",
    "                    dict_to_df['foot_d_ys']=foot_ys.flatten()[np.array(stance_idcs[ss])] - (body_loc[1]+flatY)\n",
    "                    dict_to_df['foot_thetas']=foot_thetas.flatten()[np.array(stance_idcs[ss])]\n",
    "                    dict_to_df['foot_phis']=foot_phis.flatten()[np.array(stance_idcs[ss])]\n",
    "                    dict_to_df['foot_dists']=foot_dists.flatten()[np.array(stance_idcs[ss])]\n",
    "                    dict_to_df['foot_heights']=foot_heights.flatten()[np.array(stance_idcs[ss])]\n",
    "                    dict_to_df['stance_type']=['flat','pitch','roll'][int(np.sum(np.abs(np.diff( foot_heights.flatten()[np.array(stance_idcs[ss])]))))]\n",
    "                    dict_to_df['stance_displacement']=np.sum(foot_dists.flatten()[np.array(stance_idcs[ss])])\n",
    "                    dict_to_df['stance_height']=['valley','peak'][(np.sum(foot_heights.flatten()[np.array(stance_idcs[ss])])>=-1).astype(int)]\n",
    "\n",
    "                    # append to dict\n",
    "                    data.append(dict_to_df.copy())\n",
    "\n",
    "\n",
    "foot_placement_df = pd.DataFrame(data)\n",
    "print('done making foot placement dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze dataframe of foot placement info\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "floor_x_range = [-5,10]\n",
    "floor_y_range = [-5,10]\n",
    "h_lines = np.hstack([np.flip(-1*np.arange(0,5,box_size)[1:], axis =0),np.arange(0,10,box_size)])\n",
    "v_lines = np.hstack([np.flip(-1*np.arange(0,5,box_size)[1:], axis =0),np.arange(0,10,box_size)])\n",
    "heights = toeplitz(np.arange(0,len(h_lines))%2,r=np.arange(0,len(v_lines))%2)-1\n",
    "colors = ['grey','silver']\n",
    "text_locations = np.meshgrid(h_lines[2:4]-box_size/2,v_lines[1::2]-box_size/2)\n",
    "\n",
    "# where are box cut-offs for 2d histogram\n",
    "xedges = np.arange(floor_x_range[0],floor_x_range[1],precision*2)-precision\n",
    "yedges = np.arange(floor_y_range[0],floor_y_range[1],precision*2)-precision\n",
    "\n",
    "# 2d histogram\n",
    "for box_size in [1,3,5]:\n",
    "    fig=plt.figure(figsize = (9,5))\n",
    "    n_stances = np.full((2,3), np.nan)\n",
    "    n_stances_adjusted = np.full((2,3), np.nan)\n",
    "    stance_types = ['flat','pitch','roll']\n",
    "    for ss,s_type in enumerate(stance_types):\n",
    "        for hh,h_type in enumerate(['valley', 'peak']):\n",
    "\n",
    "\n",
    "            df_OI = foot_placement_df.loc[(foot_placement_df['box_size']==box_size) & (foot_placement_df['stance_type']==s_type) & (foot_placement_df['stance_height']==h_type) ]\n",
    "            n_stances[hh,ss] = len(df_OI)\n",
    "            n_stances_adjusted[hh,ss] = np.sum(df_OI['foot_dists'].apply(lambda x: 1/np.sum(x)).values)\n",
    "            print('stance type: %s, height: %s, n: %i, adjusted: %0.1f'%(s_type, h_type, n_stances[hh,ss], n_stances_adjusted[hh,ss]))\n",
    "\n",
    "            H, _,_ = np.histogram2d(df_OI['body_x'].values, df_OI['body_y'].values, bins = (xedges,yedges)) # count number of stances\n",
    "        #     H, _,_ = np.histogram2d(df_OI['body_x'].values, df_OI['body_y'].values, bins = (xedges,yedges) # weight each stance by \"cost\" (how much cumulative distance from neutral position)\n",
    "        #                             , weights = 1/foot_placement_df.loc[(foot_placement_df['stance_type']==s_type)]['stance_displacement'].values)\n",
    "            H = H.T\n",
    "\n",
    "            plt.subplot(2,3,ss+1+hh*3)\n",
    "            for ii in range(0,3):\n",
    "                plt.axvline(x=box_size*ii, color ='w', linestyle='-')\n",
    "                plt.axhline(y=box_size*ii, color ='w', linestyle='-')\n",
    "            X,Y = np.meshgrid(xedges, yedges)\n",
    "            pc=plt.gca().pcolormesh(X,Y,H, vmin = 0, vmax = 100) # number stanced\n",
    "        #     pc=plt.gca().pcolormesh(X,Y,H, vmin = 0, vmax = 80) # weighted\n",
    "            plt.axis('equal')\n",
    "            plt.xlim([-1*box_size,3*box_size])\n",
    "            plt.ylim([-1*box_size,box_size*2])\n",
    "            if hh == 0:\n",
    "                plt.title('%s stances'%s_type)\n",
    "                plt.gca().get_xaxis().set_visible(False)\n",
    "            for ttx, tx in enumerate(range(0,box_size*6,box_size)):\n",
    "                for tty, ty in enumerate(range(0,box_size*3,box_size)):\n",
    "                    if (tty==1) & ((ttx==1) or (ttx==2)):\n",
    "                        continue\n",
    "                    plt.text(tx-box_size/2,ty-box_size/2, ['v','p'][(ttx+tty)%2], color ='w' , ha='center')\n",
    "\n",
    "    cax = fig.add_axes([0.92,0.1,0.02,0.8])\n",
    "    #         plt.colorbar(pc, cax = cax, label = 'more <---> less displacement')\n",
    "    plt.colorbar(pc, cax = cax, label = '# stances')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot stacked bar graph of number of stances\n",
    "plt.figure()\n",
    "total_n = np.sum(np.sum(n_stances))\n",
    "total_n_adjusted = np.sum(np.sum(n_stances_adjusted))\n",
    "bcolors = ['r','g','b']\n",
    "for box_size in [1,3,5]:\n",
    "    for ss in range(0,3):\n",
    "        for hh in range(0,2):\n",
    "            plt.bar(box_size-1, n_stances[hh,ss]/total_n, width = 1/2, \n",
    "                    bottom = np.insert(np.cumsum(n_stances.T.flatten()),0,0)[ss*2+hh]/total_n,  color = bcolors[ss], alpha = 0.2+0.3*hh)\n",
    "            plt.bar(box_size, n_stances_adjusted[hh,ss]/total_n_adjusted, width = 1/2, \n",
    "                    bottom = np.insert(np.cumsum(n_stances_adjusted.T.flatten()),0,0)[ss*2+hh]/total_n_adjusted,  color = bcolors[ss], alpha = 0.2+0.3*hh)\n",
    "plt.xlim([-10,6])\n",
    "plt.gca().get_xaxis().set_ticks([])\n",
    "plt.text(-9.5,0.95,'total n stances: %i'%total_n)\n",
    "plt.title('%s mm number of possible stances'%box_size)\n",
    "plt.xlabel('1, 3, 5 mm substrates (regular/adjusted)')\n",
    "plt.ylabel('proportion of stances')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # plt point clouds of where feet place down for model\n",
    "# plt.figure(figsize = (12,10))\n",
    "# for ss,s_type in enumerate(stance_types):\n",
    "    \n",
    "#         df_OI = foot_placement_df.loc[(foot_placement_df['stance_type']==s_type)]\n",
    "#         d_x = np.vstack(df_OI['foot_d_xs'].values)\n",
    "#         d_y = np.vstack(df_OI['foot_d_ys'].values)\n",
    "#         heights = np.vstack(df_OI['foot_heights'].values)\n",
    "        \n",
    "#         for ll in range(0,3):\n",
    "#             plt.subplot(3,3, ss*3+ll+1)\n",
    "# #             plt.xlim([-1.25,1.25])\n",
    "            \n",
    "#             for hh in [-1,0]:\n",
    "#                 where_height = heights[:,ll]==hh\n",
    "#                 plt.plot(d_x[where_height,ll], d_y[where_height,ll]*(ll%2*2-1), '.', color = ['b','g'][hh+1], alpha = 0.02, MarkerSize = 2)\n",
    "#                 plt.plot(np.mean(d_x[where_height,ll]), np.mean(d_y[where_height,ll]*(ll%2*2-1)), '+', color = ['b','g'][hh+1])\n",
    "#                 plt.plot([0,np.mean(d_x[where_height,ll])], [0,np.mean(d_y[where_height,ll])*(ll%2*2-1)], '-', color = 'k')\n",
    "                \n",
    "# #                 weights_to_use = np.vstack(1/df_OI['foot_dists'].values)[where_height, ll]\n",
    "#                 weights_to_use = 1/df_OI['stance_displacement'].values[where_height]\n",
    "#                 x_mean = np.average(d_x[where_height,ll], weights = weights_to_use)\n",
    "#                 y_mean = np.average(d_y[where_height,ll]*(ll%2*2-1),  weights = weights_to_use)\n",
    "#                 plt.plot([0,x_mean], [0,y_mean], '--', color = 'r')\n",
    "#                 plt.plot(0,0,'.k')\n",
    "\n",
    "#             if ll==0:\n",
    "#                 plt.ylabel('%s'%s_type)\n",
    "#             else:\n",
    "#                 plt.gca().get_yaxis().set_visible(False)\n",
    "#             if ss ==0:\n",
    "#                 plt.title('%s'%['fore','mid','hind'][ll])\n",
    "#             plt.ylim([-1.25,1.25])\n",
    "#             plt.xlim([-1.25,1.25])\n",
    "            \n",
    "            \n",
    "# plot distribution of stances along y-axis for 1mm range in center of block\n",
    "plt.figure()\n",
    "vals_OI = np.abs(foot_placement_df['body_x'].values%box_size-box_size/2)<=0.5\n",
    "stance_ys_OI = np.abs( (foot_placement_df['body_y'].values[vals_OI])/box_size - 0.5)/0.5\n",
    "\n",
    "\n",
    "hprecision = box_size/precision/2 # how many bins per 1 unit\n",
    "hbins = np.linspace(0, 1, hprecision+1)-0.01\n",
    "\n",
    "h_counts = np.histogram(stance_ys_OI, bins = hbins)[0]\n",
    "h_counts[0] = 2*h_counts[0]\n",
    "n_data = np.sum(stance_ys_OI)\n",
    "h_counts = h_counts/n_data\n",
    "plt.plot(hbins[:-1][h_counts>0]+(1/(2*hprecision)), h_counts[h_counts>0], ':', color = pltcolors[np.where(np.array([0,1,3,5])==box_size)[0][0]])\n",
    "plt.bar(hbins[:-1][h_counts>0], h_counts[h_counts>0], color = pltcolors[np.where(np.array([0,1,3,5])==box_size)[0][0]], alpha = 0.2, width =1/hprecision, align='edge')\n",
    "# plt.hist(stance_ys_OI, bins = hbins, color = pltcolors[2], alpha = 0.2, weights = np.ones(stance_ys_OI.shape)*(1/n_data))\n",
    "plt.xlabel('center   <------>   edges')\n",
    "plt.ylabel('proportion of stances')\n",
    "    \n",
    "#         # lowpass filter histogram data\n",
    "#         b,a = signal.butter(2, 1/(precision/4))\n",
    "#         temp = signal.filtfilt(b,a, np.hstack([np.flipud(h_counts[h_counts>0]),h_counts[h_counts>0], np.flipud(h_counts[h_counts>0])]) , padlen = 10)\n",
    "#         h_counts_filt= temp[ len(h_counts[h_counts>0]):(2*len(h_counts[h_counts>0]))]\n",
    "#         plt.plot(bins[:-1][h_counts>0]+(1/(2*precision)), h_counts_filt, linestyle = line_styles[height], color = pltcolors[ss])\n",
    "#         plt.text(0.72+height/10, .06-ss*0.003, 'n: %i'%len(hist_OI[heights==height]), color  = pltcolors[ss])\n",
    "#         plt.ylim([0,0.07])\n",
    "\n",
    "\n",
    "\n",
    "# del df_OI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile video of random times during trials to see how many feet in contact - UNFINISHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_save_frames(raw_video_path, frame_range, verbose, video_to_save):\n",
    "    \"\"\"\n",
    "    Independent of the frame range loaded, background has to be computed over total video or else can run into\n",
    "    tracking problems\n",
    "    \"\"\"\n",
    "    vid = cv2.VideoCapture(raw_video_path)\n",
    "    Height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    Width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    NumFrames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if not (NumFrames > 0):\n",
    "        raise IOError('Codec issue: cannot read number of frames.')\n",
    "\n",
    "    # restrict to desired range of frames\n",
    "    if frame_range is None:\n",
    "        frame_range = (0, int(NumFrames))\n",
    "    else:\n",
    "        # check doesn't exceed number of frames\n",
    "        if frame_range[0] + frame_range[1] > NumFrames:\n",
    "            frame_range = (int(frame_range[0]), int(NumFrames - frame_range[0]))\n",
    "\n",
    "    # initialize blank frames\n",
    "    frames = np.zeros((frame_range[1], Height, Width), np.uint8)\n",
    "\n",
    "    # set the first frame to read in\n",
    "    vid.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for kk in range(frame_range[0]):\n",
    "        tru, ret = vid.read(1)\n",
    "    # vid.set(cv.CAP_PROP_POS_FRAMES, frame) # this way of setting the frame doesn't work on all cv versions\n",
    "\n",
    "    # read in all frames\n",
    "    for kk in range(frame_range[1]):\n",
    "        tru, ret = vid.read(1)\n",
    "\n",
    "        # check if video frames are being loaded\n",
    "        if not tru:\n",
    "            raise IOError('Codec issue: cannot load frames.')\n",
    "        frames[kk, :, :] = ret[:, :, 0]  # assumes loading color\n",
    "        \n",
    "        # crop to center around ant\n",
    "        video_to_save.write(ret)\n",
    "        \n",
    "        if ((kk % 100) == 0) and verbose:\n",
    "            print(kk)\n",
    "            \n",
    "    vid.release()\n",
    "    return frames, NumFrames, frame_range\n",
    "\n",
    "\n",
    "# def save_image(vlocation, nfig, name_base):\n",
    "#     pname = os.path.join(vlocation, '%s%d.png'%(name_base,nfig))\n",
    "#     plt.savefig(pname)\n",
    "#     nfig = nfig + 1\n",
    "#     plt.pause(0.2)\n",
    "# #     plt.close('all')\n",
    "#     return nfig\n",
    "\n",
    "\n",
    "# def save_video(vlocation, name_base):\n",
    "#     # save images as movie\n",
    "#     if os.path.isfile((vlocation+'/%s.mp4'%name_base)):\n",
    "#         os.remove(vlocation + \"/%s.mp4\"%name_base)\n",
    "#         print('** Deleted %s.mp4 file'%name_base)\n",
    "#     print('saving %s.mp4 file'%name_base)\n",
    "#     command_p1 = \"ffmpeg -r 4 -i '%s/%s\"%(vlocation, name_base)\n",
    "#     command_p2 = \" -vcodec libx264 '%s/%s.mp4'\"%(vlocation, name_base)\n",
    "#     command = command_p1 + \"%01d.png'\" + command_p2\n",
    "# #     print(command)\n",
    "#     os.system(command)\n",
    "#     plt.pause(10)\n",
    "\n",
    "#     # delete all trackway vids\n",
    "#     pics2delete = glob.glob(os.path.join(vlocation, '%s*.png'%name_base))\n",
    "#     for pic in pics2delete:\n",
    "#         os.remove(pic)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtypes = sorted(list(set(df['substrate'].values)))\n",
    "coltypes = sorted(list(set(df['substrate'].values)))\n",
    "vlocation = '/media/gravishlab/SeagateExpansionDrive/AntTrack'\n",
    "# vid_to_save = vlocation+'/Feet_In_Contact_%s.mp4'%subtype\n",
    "\n",
    "for ss, subtype in enumerate(subtypes[0:1]):\n",
    "    vid_name = vlocation+'/Feet_In_Contact_%s.mp4'%subtype\n",
    "    vid_to_save = cv2.VideoWriter(vid_name, cv2.VideoWriter_fourcc('M','J','P','G'), 30, (1000,550) )\n",
    "\n",
    "    t_idcs = df.loc[(df['substrate']==subtype) & (df['colony']!='Tunnel_20180329-30')].index.values\n",
    "    idcs_OI = np.random.choice(t_idcs,100)\n",
    "#     print(idcs_OI)\n",
    "    \n",
    "    for ii,idc in enumerate(idcs_OI[0:1]):\n",
    "        non_nan_frs = df.iloc[idc]['frames'][np.logical_and(\n",
    "            np.isfinite(df.iloc[idc]['thorax_x_filt_fullfr']), np.isfinite(df.iloc[idc]['thorax_y_filt_fullfr']) )]\n",
    "        while len(non_nan_frs)==0:\n",
    "            idc = idc+1\n",
    "            non_nan_frs = df.iloc[idc]['frames'][np.logical_and(\n",
    "                np.isfinite(df.iloc[idc]['thorax_x_filt_fullfr']), np.isfinite(df.iloc[idc]['thorax_y_filt_fullfr']) )]\n",
    "            idcs_OI[ii]=idc\n",
    "            \n",
    "        t_xs = df.iloc[idc]['thorax_x_filt_fullfr']\n",
    "        t_ys = df.iloc[idc]['thorax_y_filt_fullfr']\n",
    "        frs = df.iloc[idc]['frames']\n",
    "        \n",
    "        fr_OI = np.random.choice(non_nan_frs,1)\n",
    "        fr_idc_OI = np.where(frs==fr_OI)[0][0]\n",
    "        t_x = t_xs[fr_idc_OI]\n",
    "        fr_OI = frs[fr_idc_OI]\n",
    "        t_y = t_ys[fr_idc_OI]\n",
    "        \n",
    "        print('trial %i - frame OI: %i - x,y: %0.1f,%0.1f'%(idc,fr_OI, t_x,t_y))\n",
    "        \n",
    "        frame_range = [int(fr_OI-5),11]\n",
    "        frames, NumFrames, frame_range = load_and_save_frames(df.iloc[idc]['video'], frame_range, vid_to_save, t_x, t_y)\n",
    "#         frames, NumFrames, frame_range = load_video(df.iloc[idc]['video'], [int(fr_OI-5),int(fr_OI+5)], True)\n",
    "\n",
    "        del idcs_OI, t_idcs, ii, idc, t_xs, t_ys, non_nan_frs, fr_OI, fr_idc_OI, t_x, t_y\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    vid_to_save.release()\n",
    "#         for fr_idc in range(frames.shape[0]):\n",
    "#             frame_to_save = frames[fr_idc,:,:]\n",
    "#             gray_frame = cv2.normalize(frame_to_save, None, 255, 0, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_8U)\n",
    "#             save_image(vlocation, im_n, 'LEAPtracking_filter')\n",
    "# save_video(vlocation, 'LEAPtracking_filter')\n",
    "        \n",
    "        \n",
    "    \n",
    "#     yvals_OI = df.loc[(all_strides['substrate']==subtype) & (all_strides['colony']!='Tunnel_20180329-30')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare manual and automatic tracked TDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find trials to manually track\n",
    "\n",
    "# which trials?\n",
    "# for tt in range(2000,2030):#[1662]:\n",
    "#     print(tt, ' -- ', np.sum(df['joint3_good_strides'][tt]), np.sum(df['joint4_good_strides'][tt]), np.sum(df['joint5_good_strides'][tt]), ' -- %s'%df['time'][tt])\n",
    "\n",
    "# which ROI?\n",
    "# for tt in [2417,2437,2448,2464]:\n",
    "for tt in [1960, 1990, 2011]: \n",
    "    print('\\n', tt, ' -- ', np.sum(df['joint3_good_strides'][tt]), np.sum(df['joint4_good_strides'][tt]), np.sum(df['joint5_good_strides'][tt]), ' -- %s'%df['time'][tt])\n",
    "    for jj in range(3,6):\n",
    "        print(df['frames'][tt][df['joint%i_TD_idcs'%jj][tt][:-1][df['joint%i_good_strides'%jj][tt]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1616,1617,1626,1662]\n",
    "# [1924,1943,1961,2016,1960,1990],\n",
    "# [2106,2114,2129,2177]\n",
    "# [2417,2437,2448,2464]\n",
    "\n",
    "from numpy import genfromtxt\n",
    "cutoff = 10\n",
    "\n",
    "all_trials = ([\n",
    "    [1616,1617,1626,1662],\n",
    "    [1924,1943,1961,2016,1960,1990],\n",
    "    [2106,2114,2129,2177],\n",
    "    [2417,2437,2448,2464]])\n",
    "\n",
    "\n",
    "for trials in all_trials[0:4]:\n",
    "\n",
    "\n",
    "    all_TD_offsets = [[],[],[]]\n",
    "    total_TDs_OI = 0\n",
    "    total_TDs_correct = 0\n",
    "\n",
    "    for tt in trials:\n",
    "        print('\\n', tt, ' -- ', np.sum(df['joint3_good_strides'][tt]), np.sum(df['joint4_good_strides'][tt]), np.sum(df['joint5_good_strides'][tt]))\n",
    "        mfile = ('/').join(df['video'][tt].split('/')[:-1]) + '/' + df['video'][tt].split('/')[-1].split('1627')[0] + 'manualTDs.csv'\n",
    "        print(mfile)\n",
    "        manual_data = np.fliplr(genfromtxt(mfile, delimiter=','))\n",
    "\n",
    "        for jj in range(0,3):\n",
    "\n",
    "            mTDs = manual_data[:,jj]\n",
    "            mTDs = mTDs[np.isfinite(mTDs)]\n",
    "            aTDs =df['frames'][tt][df['joint%i_TD_idcs'%(jj+3)][tt][:-1][df['joint%i_good_strides'%(jj+3)][tt]]]\n",
    "\n",
    "            temp = np.tile(aTDs[:,np.newaxis],len(mTDs)).T-np.tile(mTDs[:,np.newaxis],len(aTDs))\n",
    "            aTDs_OI = np.sum(np.abs(temp)<15,axis=0)>0\n",
    "            n_aTDs_OI = np.sum(aTDs_OI)\n",
    "\n",
    "            aTDs_OI_checked_idcs = []\n",
    "            aTDs_OI_checked =[]\n",
    "            TDs_offset = []\n",
    "            temp2 = mTDs.copy()\n",
    "            for aTD in aTDs[aTDs_OI]:\n",
    "                idx = np.argmin(np.abs(temp2-aTD))\n",
    "                aTDs_OI_checked_idcs.append(0)\n",
    "                if np.abs(temp2-aTD)[idx]<cutoff:\n",
    "                    aTDs_OI_checked.append(temp2[idx])\n",
    "                    TDs_offset.append(aTD-temp2[idx])\n",
    "                    temp2 = np.delete(temp2, idx)\n",
    "                del idx\n",
    "\n",
    "\n",
    "            n_aTDs_OI_checked = len(aTDs_OI_checked)\n",
    "\n",
    "\n",
    "\n",
    "            all_TD_offsets[jj]=all_TD_offsets[jj]+TDs_offset\n",
    "            total_TDs_OI = total_TDs_OI + n_aTDs_OI\n",
    "            total_TDs_correct = total_TDs_correct + n_aTDs_OI_checked\n",
    "\n",
    "            print(aTDs, aTDs[aTDs_OI], mTDs)\n",
    "#             print(aTDs[aTDs_OI], mTDs)\n",
    "            print('%i/%i TDs correctly identfied, offsets:'%( n_aTDs_OI_checked ,n_aTDs_OI), TDs_offset)\n",
    "\n",
    "\n",
    "    ave_offset = np.mean(np.array([item for sublist in all_TD_offsets for item in sublist]))\n",
    "    print('\\n\\nTOTAL %i/%i TDs correctly identified, ave offset = %0.2f\\n\\n'%(total_TDs_correct, total_TDs_OI, ave_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### list and inspect trials with weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find df and file_list locations of weird trials\n",
    "trackways_OI = np.unique(all_strides['trackway'][np.abs(all_strides['St_rotation'].values)>100].values)\n",
    "print('Trackways: ', trackways_OI[0:10])\n",
    "files_OI = np.where(np.isin(np.array(file_list), df['video'][trackways_OI].values))[0]\n",
    "print('Files: ', files_OI[0:10])\n",
    "\n",
    "\n",
    "\n",
    "# is it an angle issue?\n",
    "tway = 416\n",
    "print('\\nVIDEO: ', df['video'][tway])\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot2grid((2,2),(0,0))\n",
    "plt.plot(df['angle_improved'][tway], '.k')\n",
    "plt.ylabel('angle improved')\n",
    "plt.subplot2grid((2,2),(1,0))\n",
    "plt.plot(df['thorax_x_filt'][tway], '.k')\n",
    "plt.plot(df['neck_x_filt'][tway], '.r')\n",
    "plt.ylabel('x filt WRT ant')\n",
    "\n",
    "#     print(str_starts, str_ends)\n",
    "#     plt.plot()\n",
    "plt.subplot2grid((2,2),(0,1), rowspan =2)\n",
    "plt.plot(df['thorax_x_filt_fullfr'][tway],df['thorax_y_filt_fullfr'][tway], '.k')\n",
    "n_str = 0\n",
    "for jj in range(0,1):#6):\n",
    "    str_starts = df['joint%i_TD_idcs'%jj][tway][:-1][df['joint%i_good_strides'%jj][tway]]\n",
    "    str_ends = df['joint%i_TD_idcs'%jj][tway][1:][df['joint%i_good_strides'%jj][tway]]-1\n",
    "    pltcolors = np.random.rand(len(str_starts),3)#plt.cm.get_cmap('hsv', len(str_starts))\n",
    "    plt.gca().set_prop_cycle(color = pltcolors)\n",
    "    plt.plot(np.array([df['thorax_x_filt_fullfr'][tway],df['neck_x_filt_fullfr'][tway]])[:,str_starts],\n",
    "             np.array([df['thorax_y_filt_fullfr'][tway],df['neck_y_filt_fullfr'][tway]])[:,str_starts], '-')\n",
    "    plt.gca().set_prop_cycle(color = pltcolors)\n",
    "    plt.plot(np.array([df['thorax_x_filt_fullfr'][tway],df['neck_x_filt_fullfr'][tway]])[:,str_ends],\n",
    "             np.array([df['thorax_y_filt_fullfr'][tway],df['neck_y_filt_fullfr'][tway]])[:,str_ends], ':')\n",
    "    plt.gca().set_prop_cycle(color = pltcolors)\n",
    "    plt.plot(np.array([df['neck_x_filt_fullfr'][tway][str_starts],df['neck_x_filt_fullfr'][tway][str_ends]]),\n",
    "             np.array([df['neck_y_filt_fullfr'][tway][str_starts],df['neck_y_filt_fullfr'][tway][str_ends]]), ':')\n",
    "    for ii,kk in enumerate(str_starts):\n",
    "        textsize = 6\n",
    "        if np.abs(df['joint%i_St_rotation'%jj][tway][ii]) > 80:\n",
    "            textsize = 12\n",
    "        plt.text(df['thorax_x_filt_fullfr'][tway][kk]+10, df['thorax_y_filt_fullfr'][tway][kk]+5, \n",
    "                 '%0.1f, %0.1f'%(df['joint%i_travel_dir'%jj][tway][ii], df['joint%i_St_rotation'%jj][tway][ii]), color = pltcolors[ii], \n",
    "                fontsize = textsize)\n",
    "    n_str = n_str + len(str_starts)\n",
    "plt.ylabel('y filt WRT full frame')\n",
    "plt.ylabel('x filt WRT full frame')\n",
    "plt.gca().axis('equal')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "print('\\nFACING ROTATIONS:')\n",
    "for jj in range(0,6):\n",
    "    print('Joint %i: '%jj, df['joint%i_St_rotation'%jj][tway].astype(int))\n",
    "    \n",
    "print('\\nTRAVEL DIR WRT STARTING FACING:')\n",
    "for jj in range(0,6):\n",
    "    print('Joint %i: '%jj, df['joint%i_travel_dir'%jj][tway].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Analysis of stride frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourier of one trackway\n",
    "plt.close('all')\n",
    "\n",
    "subOI = '0mm'\n",
    "colOI = '20180313-14'\n",
    "trOI = '13_093129'\n",
    "\n",
    "win_wid = 130\n",
    "n_dp_cutoff = 120\n",
    "inc = 10 # how much bump window with each iteration\n",
    "rate = 240\n",
    "\n",
    "# for comparison to manually tracked stepping\n",
    "# st_timing = [1.000,1.112,1.233,1.337,1.441,1.533,1.687,1.799,2.062,2.200,2.320,2.429,2.549,2.783,2.887]\n",
    "# st_frs = [round(st*239.2) for st in st_timing]\n",
    "\n",
    "\n",
    "# tr_nums = longtracks[(longtracks['colony']=='Tunnel_' + colOI) & \n",
    "#                      (longtracks['substrate']==subOI) &\n",
    "#                      (longtracks['datetime']==\n",
    "#                       datetime.datetime.strptime('201803'+trOI, \"%Y%m%d_%H%M%S\"))].index\n",
    "\n",
    "tr_nums = [91]\n",
    "\n",
    "fig = plt.figure(figsize = (7,13))\n",
    "gs = gridspec.GridSpec(3,1)\n",
    "gs.tight_layout(fig, rect = [0.5, 0, 1,1], h_pad = 0.5)\n",
    "ax1 = plt.subplot(gs[0,0])\n",
    "ax2 = plt.subplot(gs[1,0])\n",
    "ax3 = plt.subplot(gs[2,0])\n",
    "\n",
    "for tr_num in tr_nums:\n",
    "\n",
    "    # tr_num = 8978\n",
    "\n",
    "    gs = gridspec.GridSpec(3,1)\n",
    "    gs.update( hspace = 0.3, wspace = 0.01)\n",
    "    trC = np.random.rand(3,)\n",
    "\n",
    "\n",
    "    x = longtracks.loc[tr_num].copy()\n",
    "    print(x.colony, x.substrate)\n",
    "    blankvaltrace = np.full(x.frames.shape,np.nan)\n",
    "    blankvtrace = np.full(x.frames.shape,np.nan)\n",
    "    frs = [ frame in x.frames_final for frame in x.frames] #[int(fr) for fr in x.frames_final]\n",
    "    blankvaltrace[frs] = x.dist_90fr\n",
    "    blankvtrace[frs] = x.v_final\n",
    "\n",
    "    # PLOT THINGS\n",
    "#     ax1.plot([st_frs, st_frs],[np.zeros(len(st_frs)), 1500*np.ones(len(st_frs))],\n",
    "#                              ':', c = 'k', alpha = 0.5, linewidth = 1)\n",
    "    ax1.plot(x.frames[1:], x.vfilt, '-k', alpha = 0.5);\n",
    "    ax1.plot(x.frames+1, blankvtrace, '-', c = trC);\n",
    "    ax1.plot(x.frames, blankvaltrace*(240/90), '.r', alpha = 0.5);\n",
    "    ax1.set_xlim((0,717))\n",
    "    ax1.set_xlabel('frame');\n",
    "    ax1.set_ylabel('v (pix/s)')\n",
    "    ax1.set_title('%s -- %s -- %s' % (x.colony, x.substrate, x.datetime.strftime('%H_%M_%S')));\n",
    "\n",
    "    # fft on whole track\n",
    "    fft_input = blankvtrace[np.isfinite(blankvtrace)]\n",
    "    p = 20* np.log10(np.abs(np.fft.rfft(fft_input)))\n",
    "    xf = np.linspace(0,rate/2,len(p))\n",
    "    ax2.plot(xf,p, c = trC)\n",
    "    ax2.set_ylabel('log(power)');\n",
    "    ax2.set_xlabel('freq (Hz)');\n",
    "    ax2.set_title('FFT for all non-nan data');\n",
    "    \n",
    "\n",
    "    # fft each chunk of non nan\n",
    "    starts = np.where(np.diff(np.isfinite(blankvtrace)))[0][0::2]\n",
    "    stops = np.where(np.diff(np.isfinite(blankvtrace)))[0][1::2]\n",
    "    start_frs = x.frames[1:][(np.diff(np.isfinite(blankvtrace)))][0::2]+1\n",
    "    for sta, sto, stafr in zip(starts,stops, start_frs):\n",
    "        n_dp = sto - sta\n",
    "        if n_dp > n_dp_cutoff:\n",
    "    #                     print('---- # data points in chunk: %s' %n_dp)\n",
    "            chunk = blankvtrace[sta+1:sto]\n",
    "            cushion = np.full(win_wid-10,np.nan)\n",
    "            chunk = np.hstack((cushion,chunk,cushion))\n",
    "            \n",
    "\n",
    "            powers = np.full(int(120*10+1),np.nan)\n",
    "            power_vs = []\n",
    "\n",
    "            for kk,win_edge in enumerate(range(0, n_dp+win_wid-10, inc)):\n",
    "    #             print('---%s' % win_edge)\n",
    "                win_data = chunk[win_edge:win_edge+win_wid]\n",
    "                fft_input = win_data[np.isfinite(win_data)]\n",
    "    #             print('-- %i: %i' %(win_edge, len(fft_input)))\n",
    "                if (len(fft_input)> n_dp_cutoff) and (np.nanstd(fft_input) < 350):\n",
    "                    p = 20* np.log10(np.abs(np.fft.rfft(fft_input)))\n",
    "                    xf = np.linspace(0,rate/2,len(p))\n",
    "#                     print('-- %0.3f -- %0.3f' %(np.nanstd(fft_input), np.nanstd(fft_input)/np.nanmean(fft_input)))\n",
    "                    \n",
    "\n",
    "                    randomC = np.random.rand(3,)\n",
    "                    ax3.plot(xf,p, c = randomC)\n",
    "                    ax1.plot([win_edge-(win_wid-10)+stafr, win_edge+10+stafr],[np.nanmean(fft_input), np.nanmean(fft_input)],\n",
    "                             '-', c = randomC, alpha = 0.5)\n",
    "                    ax1.add_patch(Rectangle(\n",
    "                        (win_edge-(win_wid-10)+stafr, np.nanmean(fft_input)-np.nanstd(fft_input)), win_wid, 2*np.nanstd(fft_input),\n",
    "                                 alpha = 0.1, color = randomC ))\n",
    "\n",
    "                    temp = np.interp(np.linspace(0,120,120*10+1),xf,p)\n",
    "                    print('-- %0.3f -- Peak FRs: %0.2f, %0.2f' %(np.nanmean(fft_input), \n",
    "                                                                 argrelextrema(temp, np.greater)[0][0]/10,\n",
    "                                                                argrelextrema(temp, np.greater)[0][1]/10))\n",
    "                    powers = np.vstack((powers,temp))\n",
    "                    power_vs = np.append(power_vs, np.nanmean(fft_input))\n",
    "\n",
    "    powers = powers[1::]\n",
    "    avg_power = np.nanmean(powers,axis=0)\n",
    "\n",
    "    ax3.plot(np.linspace(0,rate/2,len(temp)),avg_power, '--k', linewidth = 3, label = 'ave')\n",
    "    ax3.set_ylabel('log(power)');\n",
    "    ax3.set_xlabel('frequency (Hz)');\n",
    "    ax3.set_title('FFT for moving window w/ 50-60 non-nan data points')\n",
    "    ax3.text(90,80,'increment = 10 fr')\n",
    "    ax3.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEATMAP - fourier vs travel velocity for each chunk\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "subtypes = sorted(longtracks['substrate'].unique())\n",
    "coltypes = sorted(longtracks['colony'].unique())\n",
    "\n",
    "win_wid = 120\n",
    "n_dp_cutoff = 110\n",
    "inc = 10 # how much bump window with each iteration\n",
    "rate = 240\n",
    "all_chunks = []\n",
    "\n",
    "for coltype in coltypes[0:1]:\n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize = (15,12))\n",
    "    gs = gridspec.GridSpec(1,8, width_ratios = [2,0.5,2,0.5,2,0.5,2,0.5])\n",
    "    gs.update(left = 0.05, right = 0.95, hspace = 0.3, wspace = 0.0)\n",
    "    cbar_ax = fig.add_axes([.95,.1,.03,.8])\n",
    "    \n",
    "    for ss,subtype in enumerate(subtypes[0:4]):\n",
    "        print('%s -- %s' % (coltype, subtype))\n",
    "        allpowers = np.full(int(120*10+1),np.nan)\n",
    "        allpowers_vs = []\n",
    "        allpowers_sorted = []\n",
    "        allpowers_vs_sorted = []\n",
    "        allpeaks = []\n",
    "        \n",
    "        for k,x in longtracks.loc[(longtracks['substrate']==subtype) & (longtracks['colony']==coltype)].iterrows():\n",
    "#             print('-- %s' % x.datetime.strftime('%Y%m%d_%H%M%S'))\n",
    "\n",
    "            blankvaltrace = np.full(x.frames.shape,np.nan)\n",
    "            blankvtrace = np.full(x.frames.shape,np.nan)\n",
    "            frs = [ frame in x.frames_final for frame in x.frames] #[int(fr) for fr in x.frames_final]\n",
    "            blankvaltrace[frs] = x.dist_90fr\n",
    "            blankvtrace[frs] = x.v_final\n",
    "\n",
    "            # fft each chunk of non nan\n",
    "            starts = np.where(np.diff(np.isfinite(blankvtrace)))[0][0::2]\n",
    "            stops = np.where(np.diff(np.isfinite(blankvtrace)))[0][1::2]\n",
    "            for sta, sto in zip(starts,stops):\n",
    "                n_dp = sto - sta\n",
    "                if n_dp > n_dp_cutoff:\n",
    "#                     print('---- # data points in chunk: %s' %n_dp)\n",
    "                    chunk = blankvtrace[sta+1:sto]\n",
    "                    cushion = np.full(win_wid-10,np.nan)\n",
    "                    chunk = np.hstack((cushion,chunk,cushion))\n",
    "            \n",
    "                    powers = np.full(int(120*10+1),np.nan)\n",
    "                    power_vs = []\n",
    "                    peak_fqs = []\n",
    "                    \n",
    "                    \n",
    "                    for kk,win_edge in enumerate(range(0, n_dp+win_wid-10, inc)):\n",
    "                        tmp = {}\n",
    "                        win_data = chunk[win_edge:win_edge+win_wid]\n",
    "                        win_data_nonan = win_data[np.isfinite(win_data)]\n",
    "            #             print('-- %i: %i' %(win_edge, len(fft_input)))\n",
    "                        if (len(win_data_nonan)> n_dp_cutoff) and (np.nanstd(win_data_nonan) < 350):\n",
    "                            fft_input = win_data_nonan - np.nanmean(win_data_nonan) # get rid of low freq by subtracting mean value\n",
    "                            p = 20* np.log10(np.abs(np.fft.rfft(fft_input)))\n",
    "                            xf = np.linspace(0,rate/2,len(p))\n",
    "\n",
    "                            temp = np.interp(np.linspace(0,120,120*10+1),xf,p)\n",
    "                            powers = np.vstack((powers,temp))\n",
    "                            power_vs = np.append(power_vs, np.nanmean(win_data_nonan))\n",
    "                            \n",
    "                            # find rel max\n",
    "                            rel_max_idcs = argrelextrema(temp,np.greater)[0]\n",
    "                            rel_maxs = temp[rel_max_idcs]\n",
    "                            peak_freqs = rel_max_idcs[np.argsort(rel_maxs)[::-1]]/10\n",
    "                            \n",
    "                            # save to dataframe\n",
    "                            tmp['colony']= coltype\n",
    "                            tmp['substrate'] = subtype\n",
    "                            tmp['video'] = x.video\n",
    "                            tmp['datetime'] = x.datetime\n",
    "                            tmp['v'] = fft_input\n",
    "                            tmp['v_ave'] = np.nanmean(win_data_nonan)\n",
    "                            tmp['frames'] = np.linspace(win_edge-(win_wid-10)+sta,win_edge+10+sta, win_wid)\n",
    "                            tmp['pow_spec'] = temp\n",
    "                            tmp['pow_spec_raw'] = p\n",
    "                            tmp['pow_freq_raw'] = xf\n",
    "                            tmp['peak_freqs'] = peak_freqs\n",
    "                            all_chunks.append(tmp)\n",
    "                            \n",
    "                            peak_fqs = np.append(peak_fqs, peak_freqs[0])\n",
    "\n",
    "                    if not np.isnan(powers).all(): # only the holder vector of nan -- vel std too large for all windows\n",
    "                        powers = powers[1::]\n",
    "                        avg_power = np.nanmean(powers,axis=0)\n",
    "                        allpowers = np.vstack((allpowers,powers))\n",
    "                        allpowers_vs = np.append(allpowers_vs, power_vs)\n",
    "                        allpeaks = np.append(allpeaks, peak_fqs)\n",
    "\n",
    "\n",
    "        allpowers = allpowers[1::]\n",
    "        allpowers_sorted = allpowers[np.argsort(allpowers_vs)]\n",
    "        allpowers_vs_sorted = np.sort(allpowers_vs)\n",
    "        allpeaks_sorted = allpeaks[np.argsort(allpowers_vs)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # PLOT THINGS\n",
    "        plt.subplot(gs[0,ss*2])\n",
    "        v_box = 5\n",
    "        if ss == 0:\n",
    "            max_v = int(v_box*round(np.max(allpowers_vs)/v_box))\n",
    "        min_v = 0\n",
    "        subsample = int((max_v-min_v)/v_box+1)\n",
    "        target_vs = np.linspace(min_v,max_v, subsample)\n",
    "        \n",
    "        # plot chunk closest to target v\n",
    "#         target_vs_idcs = [np.abs(allpowers_vs_sorted-val).argmin() if np.abs(allpowers_vs_sorted-val).min() < (max_v-min_v)/(subsample-1)*(1/2) \n",
    "#                           else np.nan for val in target_vs]\n",
    "#         hmap_to_plot = np.vstack( [allpowers_sorted[idc] if not np.isnan(idc) else np.full(int(120*10+1),np.nan) \n",
    "#                                    for idc in target_vs_idcs ])\n",
    "        \n",
    "        # average all chunks within range\n",
    "        def average_powerspec(val):\n",
    "            chunkidcs = []\n",
    "            chunkidcs = np.logical_and(allpowers_vs_sorted>val, allpowers_vs_sorted<val+5) #[((v > val) and (v < val+v_box)) for v in allpowers_vs_sorted]\n",
    "#             chunkidcs = list(allpowers_vs_sorted>val) and list(allpowers_vs_sorted<(val+5))\n",
    "            if chunkidcs.any(): # are there any chunk power spectrums within velocity range of interest?\n",
    "                chunks_ave = np.mean(allpowers_sorted[chunkidcs], axis=0)\n",
    "            else:\n",
    "                chunks_ave = np.full(int(120*10+1),np.nan)\n",
    "            return chunks_ave\n",
    "        hmap_to_plot = np.vstack( [average_powerspec(val) for val in target_vs[0:-1] ])\n",
    "        chunk_hist = [sum(np.logical_and(allpowers_vs_sorted>val, allpowers_vs_sorted<val+5)) for val in target_vs[0:-1]]\n",
    "\n",
    "        # plot heatmap\n",
    "        if ss == 1:\n",
    "            hmap = sns.heatmap(hmap_to_plot, xticklabels = 100, yticklabels = 10, cbar = True, cbar_kws = {'label': 'log(power)'}, cbar_ax = cbar_ax, vmin = 0, vmax = 100)\n",
    "        else:\n",
    "            hmap = sns.heatmap(hmap_to_plot, xticklabels = 100, yticklabels = 10, cbar = False, vmin = 0, vmax = 100)\n",
    "        \n",
    "        if ss == 0:\n",
    "            plt.ylabel('ave v (pix/s)');\n",
    "            plt.yticks(rotation=0)\n",
    "            hmap.set_yticklabels(['%i' % v for v in target_vs[::10]])\n",
    "        else:\n",
    "            hmap.set_yticklabels([])\n",
    "            plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.xticks(rotation=-90)\n",
    "        hmap.set_xticklabels(np.arange(0,121,10))\n",
    "#         plt.axvline(x=201, color = 'k', linestyle = ':', alpha = 0.5, linewidth = 1)\n",
    "        plt.xlabel('freq (Hz)');\n",
    "        plt.xlim((0,600))\n",
    "        plt.title('%s -- total n: %i' % (subtype, len(allpowers_sorted)), loc = 'left')\n",
    "        \n",
    "        \n",
    "        # plot hist\n",
    "        plt.subplot(gs[0,ss*2+1])\n",
    "        plt.hist(allpowers_vs_sorted,subsample-1,(min_v,max_v), orientation ='horizontal',color = 'k', alpha = 0.5)\n",
    "        plt.gca().get_yaxis().set_visible(False)\n",
    "        plt.gca().get_xaxis().set_visible(False)\n",
    "        plt.gca().set_ylim((min_v,max_v))\n",
    "        plt.gca().set_xlim((0,250))\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.gca().set_frame_on(False)\n",
    "        \n",
    "        # run linear regression model and plot on top\n",
    "# #         x = fft_data[(fft_data['colony']==coltype) & (fft_data['substrate']==subtype)]['v_ave']\n",
    "# #         y = np.array([fs[0] for fs in fft_data[(fft_data['colony']==coltype) & (fft_data['substrate']==subtype)]['peak_freqs']])\n",
    "# #         y = y[np.argsort(x).values]\n",
    "# #         x = np.array(sorted(x))\n",
    "#         x = allpowers_vs_sorted\n",
    "#         y = allpeaks_sorted\n",
    "        \n",
    "#         x_c = sm.add_constant(x) # if do not want model to go through zero\n",
    "#         x_i = np.linspace(min_v, max_v, subsample)\n",
    "#         model = sm.OLS(y, x_c).fit()\n",
    "#         predictions = model.predict(x_c)\n",
    "#         predictions_interp = np.interp(x_i, x, predictions)\n",
    "#         hmap.plot(predictions_interp*10,x_i/v_box,':b')\n",
    "#         hmap.text(400,10,'freq = %0.3f *x + %0.2f'% (model.params[1],model.params[0]), color = 'b')\n",
    "\n",
    "        \n",
    "        \n",
    "#         plt.tight_layout()\n",
    "    plt.suptitle('Colony: %s -- from %i to %i pix/s, averaged over box of %i pix/s' % (coltype, min_v, max_v, v_box), \n",
    "                 x=0.02, y = 0.95, fontsize = 16, horizontalalignment = 'left')\n",
    "    plt.savefig(vid_locations + 'Figures/FFT/C%i_Heatmap.png' % (coltypes.index(coltype)+1))\n",
    "#     plt.savefig(vid_locations + 'Figures/FFT/C%i_Heatmap.eps' % (coltypes.index(coltype)+1))\n",
    "\n",
    "fft_data = pd.DataFrame(all_chunks)\n",
    "print('ALL DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FFT_DATA AS PICKLE FOR FUTURE USE\n",
    "fft_data.to_pickle(vid_locations + 'FFT_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND INFO FOR A SINGLE CHUNK SO THAT CAN COMPARE TO MANUALLY COUNTING STRIDE RATE\n",
    "# fft_data = \n",
    "\n",
    "# find subset of all chunks for a given colony and substrate type\n",
    "dataOI = fft_data[(fft_data['colony']==coltypes[0]) & (fft_data['substrate']==subtypes[3])].copy()\n",
    "sorted_vs = dataOI['v_ave'].sort_values(axis = 0, ascending = True)\n",
    "\n",
    "def print_chunk_info(g):\n",
    "    peak_fq = find_peak_fq(g['pow_spec'])\n",
    "    print('\\t%s, %s, %s, %0.2f Hz, %i to %i, %0.3f-%0.3f s' %(g['colony'].split('201803')[1], \n",
    "                                                                                     g['substrate'],g['datetime'], peak_fq,\n",
    "                                                                                     g['frames'][0], g['frames'][-1], g['frames'][0]/239.2, \n",
    "                                                                                     g['frames'][-1]/239.2) )\n",
    "\n",
    "def find_peak_fq(pspec):\n",
    "    if np.isnan(pspec).all():\n",
    "        return np.nan\n",
    "    idcs = argrelextrema(pspec, np.greater)[0]\n",
    "    rel_maxs = pspec[idcs[idcs>30]]\n",
    "    peak_freqs = idcs[idcs>30][np.argsort(rel_maxs)[::-1]]/10\n",
    "    return peak_freqs[0]\n",
    "    \n",
    "\n",
    "# n_vals = 10\n",
    "# for val in np.linspace(list(sorted_vs)[0]+5,list(sorted_vs)[-1]-5,10):\n",
    "\n",
    "for val in [250,400,550]:\n",
    "    print('\\n%0.1f\\n'%val)\n",
    "    \n",
    "    chunksOI_idcs = sorted_vs[(sorted_vs>(val-2.5)) & (sorted_vs<(val+2.5))].index\n",
    "    chunksOI_idcs_sorted = (dataOI.loc[chunksOI_idcs]['datetime']).sort_values(axis=0).index\n",
    "    [print_chunk_info(dataOI.loc[idx]) for idx in chunksOI_idcs_sorted]\n",
    "#     print(dataOI.iloc[chunksOI_idcs][['substrate','colony']], dataOI.iloc[chunksOI_idcs]['v_ave'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN LINEAR REGRESSION AVERAGING ALL POWER SPECTRA WITHIN VELOCITY RANGES \n",
    "from scipy import optimize\n",
    "plt.close('all')\n",
    "\n",
    "# print('read in data')\n",
    "subtypes = sorted(longtracks['substrate'].unique())\n",
    "coltypes = sorted(longtracks['colony'].unique())\n",
    "\n",
    "# define what data to use for specific colony and substrate\n",
    "colOI = coltypes[3]\n",
    "subOI = subtypes[1]\n",
    "v_ave = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['v_ave']\n",
    "peak_fqs = np.array([fs[0] for fs in fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['peak_freqs']])\n",
    "ps = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['pow_spec']\n",
    "\n",
    "# define features for averaging over velocity range\n",
    "v_box = 5\n",
    "max_v = int(round(np.max(v_ave)))\n",
    "min_v = 0\n",
    "subsample = int((max_v-min_v)/v_box+1)\n",
    "target_vs = np.linspace(min_v,max_v, subsample)\n",
    "\n",
    "# functions\n",
    "def average_powerspec(val):\n",
    "    chunkidcs = []\n",
    "    chunkidcs = np.logical_and(v_ave>val, v_ave<val+5) \n",
    "    if chunkidcs.any(): # are there any chunk power spectrums within velocity range of interest?\n",
    "        chunks_ave = np.mean(ps[chunkidcs], axis=0)\n",
    "    else:\n",
    "        chunks_ave = np.full(int(120*10+1),np.nan)\n",
    "    return chunks_ave\n",
    "def find_peak_fq(pspec):\n",
    "    if np.isnan(pspec).all():\n",
    "        return np.nan\n",
    "    idcs = argrelextrema(pspec, np.greater)[0]\n",
    "    rel_maxs = pspec[idcs[idcs>30]]\n",
    "    peak_freqs = idcs[idcs>30][np.argsort(rel_maxs)[::-1]]/10\n",
    "    return peak_freqs[0]\n",
    "    \n",
    "# average power spectra over velocity range\n",
    "ps_averaged = np.vstack( [average_powerspec(val) for val in target_vs[0:-1] ])\n",
    "x = target_vs[0:-1]+v_box/2\n",
    "y = [find_peak_fq(temp) for temp in ps_averaged]\n",
    "peak_idcs = [find_peak_fq(temp) if (not np.isnan(temp).any()) else np.nan for temp in ps_averaged]\n",
    "# get rid of nans\n",
    "x_nonan = x[np.logical_not(np.isnan(y))]\n",
    "x_c = sm.add_constant(x_nonan)\n",
    "y_nonan = np.array(y)[np.logical_not(np.isnan(y))]\n",
    "\n",
    "# fit slope and intercept model\n",
    "model = sm.OLS(y_nonan, x_c).fit()\n",
    "predictions = model.predict(x_c)\n",
    "\n",
    "\n",
    "\n",
    "# look at specific power spectra to find criterion for including point in linear regression\n",
    "fig  = plt.figure(figsize = (8,12))\n",
    "ax1 =plt.axes([0.1, 0.6, .8, 0.3])\n",
    "plt.plot(x_nonan,y_nonan,'.k', alpha = 0.2)\n",
    "plt.plot(x_nonan, predictions, '-k')\n",
    "plt.title('Col: %s -- Sub: %s\\npeak freq for power spectra averaged over every 5pix/s window' % (colOI, subOI));\n",
    "plt.text(700,7,'freq = %0.3f * v + %0.2f'% (model.params[1],model.params[0]), color = 'k')\n",
    "\n",
    "for sp in range(0,6):\n",
    "    plt.figure(fig.number)\n",
    "    ranC = np.random.rand(3,)\n",
    "    ax =plt.axes([0.08+sp*.15, 0.45, .15, 0.1])\n",
    "    pt =12+sp*10#int((len(x)-10)/5.5)\n",
    "    while np.isnan(y[pt]):\n",
    "        pt = pt + 1\n",
    "    ps_averaged[pt][ps_averaged[pt]<0] = np.nan #0.001 # get rid of negative power spectra values\n",
    "    xs = np.linspace(0,120,120*10+1)\n",
    "    xs_nonan = xs[np.logical_not(np.isnan(ps_averaged[pt]))]\n",
    "    ys = ps_averaged[pt]\n",
    "    ys_nonan = ps_averaged[pt][np.logical_not(np.isnan(ps_averaged[pt]))]\n",
    "    plt.plot(xs,ys, c = ranC)\n",
    "#     norm2 = colors.Normalize(vmin=0, vmax = 100)\n",
    "#     sc = plt.scatter(xs,ys, s= 5,\n",
    "#             cmap=cm.magma, c = ys, alpha = 0.8, norm=norm2)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlim((0,120))\n",
    "    plt.axvline(x = y[pt], alpha = 0.2)  \n",
    "    if not sp == 0:\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "    else:\n",
    "        plt.ylabel('log(power)')\n",
    "    ax1.plot(x[pt],y[pt], '.', c= ranC, Markersize = 10)\n",
    "    ax1.text(x[pt],0, '%0.1f'%x[pt], color= ranC)\n",
    "    \n",
    "    \n",
    "#     # fit y = A*e^(B*x)\n",
    "#     coeffs = np.polyfit(xs, np.log(ys), 1, w=np.sqrt(ys))\n",
    "#     ax.plot(xs, np.exp(coeffs[1]) * np.exp(xs * coeffs[0]),':k', alpha = 0.5, label = 'y=A*e^(B*x)')\n",
    "#     peak_res = ps_averaged[pt][int(y[pt]*10)] - np.exp(coeffs[1]) * np.exp(xs[int(y[pt]*10)] * coeffs[0])\n",
    "#     ax.text(90, 15, '%0.1f'% peak_res, color = 'k', alpha = 0.5, fontsize = 8)\n",
    "    \n",
    "    \n",
    "    # fit y = A*x^B\n",
    "    coeffs = np.polyfit(np.log(xs_nonan[6::]), np.log(ys_nonan[6::]), 1)\n",
    "#     print(coeffs)\n",
    "    ax.plot(xs[1::], np.exp(coeffs[1]) * xs[1::]**coeffs[0],'--', alpha = 0.5, color= 'k', label = ' y=A*x^B')\n",
    "    peak_res = ps_averaged[pt][int(y[pt]*10)] - (np.exp(coeffs[1]) * y[pt]**coeffs[0])\n",
    "    ax.text(115, 5, 'peak res: %0.1f'% peak_res, color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "    if sp == 5:\n",
    "        ax.legend(fontsize = 6, frameon=False, bbox_to_anchor = (.95, 1.25));\n",
    "    \n",
    "    \n",
    "    # fit average line\n",
    "    cv_n = 200\n",
    "    fitline = np.convolve(ys_nonan[10:], np.ones((cv_n,))/cv_n, mode = 'valid')\n",
    "    fitline_i = np.interp(xs,xs_nonan[int(cv_n/2+10):int((-cv_n)/2+1)],fitline)\n",
    "    ax.plot(xs,fitline_i, ':b', alpha = 0.5)\n",
    "    peak_res = ps_averaged[pt][int(y[pt]*10)] - fitline_i[int(y[pt]*10)]\n",
    "#     print(np.nanmean(ys-fitline_i))\n",
    "    ax.text(115, 15, 'peak res: %0.1f'% peak_res, color = 'r', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(ps_averaged[pt]-fitline_i, '-', color= ranC)\n",
    "    residuals = ps_averaged[pt][30:]-fitline_i[30:]\n",
    "    plt.axhline(y=np.nanmean(residuals))\n",
    "    plt.axhline(y=np.nanmean(residuals)+np.nanstd(residuals), LineStyle = '--')\n",
    "    plt.text(200,-50, 'stdev: %0.1f'% np.nanstd(residuals), color= ranC)\n",
    "    plt.axvline(x = y[pt]*10, alpha = 0.2)  \n",
    "    plt.text(200,-40, 'stdev of 60+ Hz: %0.1f'% np.nanstd(residuals[600-30:]), color= ranC)\n",
    "    \n",
    "#     # fit gaussian to peak\n",
    "#     def gauss(x, *p):\n",
    "#         A, mu, sigma, B = p\n",
    "#         return A* np.exp(-(x-mu)**2/(2.*sigma**2)) + B\n",
    "#     # restrict fitting to around found peak\n",
    "#     if int(y[pt]*10-100) < 0:\n",
    "#         ROI = range(5, int(2*y[pt]*10+5))\n",
    "#     else:\n",
    "#         ROI = range(int(y[pt]*10-100), int(y[pt]*10+100)) # only look at points around peak\n",
    "#     axI =plt.axes([0.18+sp*.15, 0.5, .04, 0.04])\n",
    "#     axI.plot(xs[ROI], ys[ROI]-np.nanmin(ys[ROI]), '-', c= ranC, alpha = 0.5)\n",
    "#     axI.set_frame_on(False)\n",
    "#     axI.get_xaxis().set_visible(False)\n",
    "#     axI.get_yaxis().set_visible(False)\n",
    "#     p0 = [2, y[pt], 3, 10] # initial guess of coefficients (A = amplitude?, mu = center, sigma = spread)\n",
    "#     try:\n",
    "#         coeff, var_matrix = curve_fit(gauss, xs[ROI][np.logical_not(np.isnan(ys[ROI]))], \n",
    "#                                       ys[ROI][np.logical_not(np.isnan(ys[ROI]))]-np.nanmin(ys[ROI]), \n",
    "#                                       p0=p0, bounds = ((0,0,0,0), (100,100,20,100)))\n",
    "# #         print( sp, ' -- ', coeff)\n",
    "#         gauss_fit = gauss(xs[ROI], *coeff)\n",
    "#         axI.plot(xs[ROI],gauss_fit, ':k', alpha = 0.5)\n",
    "#         ax.text(115, 90, r'A: %0.1f, $\\sigma$: %0.1f'% (coeff[0],coeff[2]), color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "#         plt.axis('equal')\n",
    "#     except:\n",
    "#         print(sp,'-- Could not find gauss fit parameters')\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "# # REDO LIN REGRESSION WHEN PEAK IS FAR FROM BEST FIT\n",
    "# def find_peak_res(pspec,peak_freq):\n",
    "#     if np.isnan(pspec).all():\n",
    "#         return np.nan\n",
    "\n",
    "#     pspec[pspec<0] = np.nan\n",
    "#     xs = np.linspace(0,120,120*10+1)\n",
    "#     xs_nonan = xs[np.logical_not(np.isnan(pspec))]\n",
    "#     pspec_nonan = pspec[np.logical_not(np.isnan(pspec))]\n",
    "# #     print(len(xs), len(pspec), len(pspec_nonan))\n",
    "#     coeffs = np.polyfit(np.log(xs_nonan[6:]), np.log(pspec_nonan[6:]), 1, w=np.sqrt(pspec_nonan[6:])) # fit y = A*e^(B*x)\n",
    "    \n",
    "#     # find peak freq\n",
    "# #     idcs = argrelextrema(pspec_nonan, np.greater)[0]\n",
    "# #     rel_maxs = pspec_nonan[idcs]\n",
    "# #     peak_freq = (idcs[np.argsort(rel_maxs)[::-1]]/10)[0]\n",
    "#     peak_res = pspec[int(peak_freq*10)] - (np.exp(coeffs[1]) * peak_freq**coeffs[0])\n",
    "#     return peak_res\n",
    "\n",
    "# def find_peak_var(pspec,peak_fq):\n",
    "#     if np.isnan(peak_fq):\n",
    "#         return np.nan\n",
    "#     if int(peak_fq*10-100) < 0:\n",
    "#         ROI = range(5, int(peak_fq*10+105))\n",
    "#     else:\n",
    "#         ROI = range(int(peak_fq*10-100), int(peak_fq*10+100)) # only look at points around peak\n",
    "#     xs = np.linspace(0,120,120*10+1)\n",
    "#     p0 = [2, y[pt], 3, 10] # initial guess of coefficients (A = amplitude?, mu = center, sigma = spread)\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(xs,pspec,'-k',alpha = 0.3)\n",
    "# #     plt.plot(xs[ROI],pspec[ROI],'-k',alpha = 0.7)\n",
    "#     try:\n",
    "#         coeff, var_matrix = curve_fit(gauss, xs[ROI][np.logical_not(np.isnan(pspec[ROI]))], \n",
    "#                                       pspec[ROI][np.logical_not(np.isnan(pspec[ROI]))]-np.nanmin(pspec[ROI]), p0=p0, bounds = ((0,0,0,0), (100,100,20,100)))\n",
    "# #         print(' -- ', coeff)\n",
    "#         gauss_fit = gauss(xs[ROI], *coeff)\n",
    "#         return coeff[2]\n",
    "# #         plt.plot(xs[ROI],gauss_fit, ':r')\n",
    "#     except:\n",
    "#         print(' Could not find gauss fit parameters')\n",
    "\n",
    "\n",
    "# peak_res = np.array([find_peak_res(temp, pf) for temp, pf in zip(ps_averaged, y)])\n",
    "# peak_var = np.array([find_peak_var(temp, pf) for temp, pf in zip(ps_averaged, y)])\n",
    "# res_cutoff = 1\n",
    "# ax1 =plt.axes([0.1, 0.1, .8, 0.3])\n",
    "# norm2 = colors.Normalize(vmin=0, vmax = 6)\n",
    "# plt.plot(x_nonan,y_nonan,'.k', alpha = 0.2)\n",
    "# sc = plt.scatter(np.array(x)[peak_res>res_cutoff],np.array(y)[peak_res>res_cutoff], s= 5,\n",
    "#             cmap=cm.magma, c = peak_var[peak_res>res_cutoff], alpha = 0.8, norm=norm2)\n",
    "# # plt.colorbar.make_axes(fig.add_axes([.95,.1,.03,.3]))\n",
    "\n",
    "# x_nonan = np.array(x)[peak_res>res_cutoff]\n",
    "# x_c = sm.add_constant(x_nonan)\n",
    "# y_nonan = np.array(y)[peak_res>res_cutoff]\n",
    "# model = sm.OLS(y_nonan, x_c).fit()\n",
    "# predictions = model.predict(x_c)\n",
    "# plt.plot(x_nonan, predictions, '-k')\n",
    "# plt.title('linear regression for peak frequencies with residual > %i' % res_cutoff);\n",
    "# plt.xlabel('v (pix/s)')\n",
    "# plt.xlim((0,1200))\n",
    "# ax1.text(700,7,'freq = %0.3f * v + %0.2f'% (model.params[1],model.params[0]), color = 'k')\n",
    "\n",
    "# cbar = plt.colorbar(sc, cax = fig.add_axes([.92,.1,.01,.3]))#fig.add_axes([.95,.1,.03,.3]))\n",
    "# cbar.set_label('gaussian fit sigma (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR A GIVEN COLONY AND SUBSTRATE, FIT A LINEAR MODEL TO THE PEAK FREQUENCY VS. VELOCITY FOR ***ALL CHUNKS***\"\n",
    "plt.close('all')\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# fft_data = pd.read_pickle(vid_locations + 'FFT_data')\n",
    "# print('read in data')\n",
    "subtypes = sorted(longtracks['substrate'].unique())\n",
    "coltypes = sorted(longtracks['colony'].unique())\n",
    "\n",
    "# define what data to use for specific colony and substrate\n",
    "colOI = coltypes[0]\n",
    "subOI = subtypes[0]\n",
    "v_ave = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['v_ave']\n",
    "peak_fqs = np.array([fs[0] for fs in fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['peak_freqs']])\n",
    "ps = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['pow_spec']\n",
    "\n",
    "# define inputs for models\n",
    "y = peak_fqs[np.argsort(v_ave).values].astype(np.float32)\n",
    "ps_sorted = list(ps[np.argsort(v_ave).values].values)\n",
    "x = np.array(sorted(v_ave))\n",
    "\n",
    "# interpolate data so can fit intercept model to it\n",
    "v_box = 5\n",
    "max_v = int(round(np.max(x)))\n",
    "min_v = 0\n",
    "subsample = int((max_v-min_v)/v_box+1)\n",
    "target_vs = np.linspace(min_v,max_v, subsample)\n",
    "\n",
    "x_c = sm.add_constant(x) # if do not want model to go through zero\n",
    "x_i = np.linspace(min_v, max_v, subsample)\n",
    "\n",
    "# plot raw data\n",
    "fig  = plt.figure(figsize = (8,12))\n",
    "ax1 =plt.axes([0.1, 0.6, .8, 0.3])\n",
    "plt.plot(x,y,'.k', alpha = 0.2)\n",
    "plt.title('Peak freq from all data chunks')\n",
    "plt.xlabel('v (pix/s)')\n",
    "plt.ylabel('freq with peak power')\n",
    "\n",
    "# intercept and slope model\n",
    "model = sm.OLS(y, x_c).fit()\n",
    "predictions = model.predict(x_c)\n",
    "predictions_interp = np.interp(x_i, x, predictions)\n",
    "# model.summary()\n",
    "plt.plot(x_i, predictions_interp,'-b')\n",
    "# plt.plot(x, predictions, ':r')\n",
    "plt.text(700,35,'freq = %0.3f * v + %0.2f'% (model.params[1],model.params[0]), color = 'b')\n",
    "\n",
    "# slope only model\n",
    "model = sm.OLS(y, x).fit()\n",
    "predictions = model.predict(x)\n",
    "# model.summary()\n",
    "plt.plot(x, predictions,'--g')\n",
    "plt.text(700,37,'freq = %0.3f * v'% (model.params[0]), color = 'g')\n",
    "\n",
    "# intercept and slope model removing any values where peak fr > 30\n",
    "# model = sm.OLS(y[y<30], x_c[y<30]).fit()\n",
    "# predictions = model.predict(x_c[y<30])\n",
    "# predictions_interp = np.interp(x_i, x[y<30], predictions)\n",
    "# model.summary()\n",
    "# plt.plot(x[y<30], predictions, ':g')\n",
    "# plt.text(700,35,'freq = %0.3f *x + %0.2f'% (model.params[1],model.params[0]), color = 'b')\n",
    "\n",
    "\n",
    "# look at specific power spectra to find criterion for including point in linear regression\n",
    "def gauss(x, *p):\n",
    "    A, mu, sigma, B = p\n",
    "    return A* np.exp(-(x-mu)**2/(2.*sigma**2)) + B\n",
    "\n",
    "for sp in range(0,6):\n",
    "    plt.figure(fig.number)\n",
    "    ranC = np.random.rand(3,)\n",
    "    ax =plt.axes([0.08+sp*.15, 0.45, .15, 0.1])\n",
    "#     pt = 10+sp*int(len(x)/5.1)\n",
    "    pt = 10+sp*50\n",
    "    while np.isnan(y[pt]):\n",
    "        pt = pt + 1\n",
    "    ps_sorted[pt][ps_sorted[pt]<0] = np.nan #0.001 # get rid of negative power spectra values\n",
    "    xs = np.linspace(0,120,120*10+1).astype(np.float32)\n",
    "    ys = ps_sorted[pt]\n",
    "    xs_nonan = xs[np.logical_not(np.isnan(ps_sorted[pt]))]\n",
    "    ys_nonan = ps_sorted[pt][np.logical_not(np.isnan(ps_sorted[pt]))]\n",
    "    plt.plot(xs,ys, c = ranC)\n",
    "    plt.ylim((0,100))\n",
    "#     plt.xlim((0,40))\n",
    "    plt.axvline(x = y[pt], alpha = 0.2)  \n",
    "    if not sp == 0:\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "    else:\n",
    "        plt.ylabel('log(power)')\n",
    "        plt.xlabel('freq (Hz)')\n",
    "    ax1.plot(x[pt],y[pt], '.', c= ranC, Markersize = 10)\n",
    "    \n",
    "    \n",
    "    # fit y = A*x^B\n",
    "    coeffs = np.polyfit(np.log(xs_nonan[1::]), np.log(ys_nonan[1::]), 1)\n",
    "    ax.plot(xs, np.exp(coeffs[1]) * xs**coeffs[0],'--', alpha = 0.5, color= 'k', label = ' y=A*x^B')\n",
    "    peak_res = ps_sorted[pt][int(y[pt]*10)] - np.exp(coeffs[1]) * xs[int(y[pt]*10)]**coeffs[0]\n",
    "    ax.text(39, 5, 'peak res: %0.1f'% peak_res, color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "    print('res: %f - ave res: %f ' % (peak_res, np.nanmean(ys[1:]-(np.exp(coeffs[1]) * xs[1:]**coeffs[0])) ))\n",
    "    if sp == 5:\n",
    "        ax.legend(fontsize = 6, frameon=False, bbox_to_anchor = (.4, 1.15));\n",
    "        \n",
    "    # fit y = A*e^(B*x)\n",
    "    coeffs = np.polyfit(xs_nonan, np.log(ys_nonan), 1, w=np.sqrt(ys_nonan))\n",
    "    ax.plot(xs, np.exp(coeffs[1]) * np.exp(xs * coeffs[0]),':k', alpha = 0.5, label = 'y=A*e^(B*x)')\n",
    "    peak_res = ps_sorted[pt][int(y[pt]*10)] - np.exp(coeffs[1]) * np.exp(xs[int(y[pt]*10)] * coeffs[0])\n",
    "    ax.text(39, 15, '%0.1f'% peak_res, color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "        \n",
    "    # fit average line\n",
    "    cv_n = 200\n",
    "    fitline = np.convolve(ys_nonan[10:], np.ones((cv_n,))/cv_n, mode = 'valid')\n",
    "    fitline_i = np.interp(xs,xs_nonan[int(cv_n/2+10):int((-cv_n)/2+1)],fitline)\n",
    "    ax.plot(xs,fitline_i, ':r', alpha = 0.5)\n",
    "    peak_res = ps_sorted[pt][int(y[pt]*10)] - fitline_i[(xs==y[pt])]\n",
    "#     print('res: %f - ave res: %f - rel res: %f' % (peak_res, np.nanmean(ys-fitline_i), np.abs(peak_res/np.nanmean(ys-fitline_i)) ))\n",
    "    ax.text(115, 15, 'peak res: %0.1f'% peak_res, color = 'r', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "    \n",
    "    # fit gaussian to peak\n",
    "    # restrict fitting to around found peak\n",
    "    if int(y[pt]*10-100) < 0:\n",
    "        ROI = range(5, int(y[pt]*10+105))\n",
    "    else:\n",
    "        ROI = range(int(y[pt]*10-100), int(y[pt]*10+100)) # only look at points around peak\n",
    "    axI =plt.axes([0.19+sp*.15, 0.51, .03, 0.03])\n",
    "    axI.plot(xs[ROI], ys[ROI]-np.nanmin(ys[ROI]), '-', c= ranC, alpha = 0.5)\n",
    "    axI.set_frame_on(False)\n",
    "    axI.get_xaxis().set_visible(False)\n",
    "    axI.get_yaxis().set_visible(False)\n",
    "    p0 = [2, y[pt], 3, 10] # initial guess of coefficients (A = amplitude?, mu = center, sigma = spread)\n",
    "    try:\n",
    "        coeff, var_matrix = curve_fit(gauss, xs[ROI][np.logical_not(np.isnan(ys[ROI]))], \n",
    "                                      ys[ROI][np.logical_not(np.isnan(ys[ROI]))]-np.nanmin(ys[ROI]), \n",
    "                                      p0=p0, bounds = ((0,0,0,0), (100,100,20,100)))\n",
    "        \n",
    "#         print( sp, ' -- ', coeff)\n",
    "        gauss_fit = gauss(xs[ROI], *coeff)\n",
    "        axI.plot(xs[ROI],gauss_fit, ':k', alpha = 0.5)\n",
    "        ax.text(115, 90, r'A: %0.1f, $\\sigma$: %0.1f'% (coeff[0],coeff[2]), color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "    except:\n",
    "        print(sp,'-- Could not find gauss fit parameters')\n",
    "        \n",
    "        \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(ps_sorted[pt]-fitline_i, '-', color= ranC)\n",
    "    residuals = ps_sorted[pt][30:]-fitline_i[30:]\n",
    "    plt.axhline(y=np.nanmean(residuals))\n",
    "    plt.axhline(y=np.nanmean(residuals)+np.nanstd(residuals), LineStyle = '--')\n",
    "    plt.text(200,5, 'stdev: %0.1f'% np.nanstd(residuals), color= ranC)\n",
    "    plt.axvline(x = y[pt]*10, alpha = 0.2)  \n",
    "    plt.text(200,2, 'stdev of 60+ Hz: %0.1f'% np.nanstd(residuals[600-30:]), color= ranC)\n",
    "    \n",
    "    \n",
    "def find_residuals(pspec):\n",
    "    cv_n = 200\n",
    "    xs = np.range(0,len(pspec))\n",
    "    xs_nonan = xs[np.logical_not(np.isnan(pspec))]\n",
    "    ys_nonan = pspec[np.logical_not(np.isnan(pspec))]\n",
    "    fitline = np.convolve(ys_nonan[10:], np.ones((cv_n,))/cv_n, mode = 'valid')\n",
    "    fitline_i = np.interp(xs,xs_nonan[int(cv_n/2+10):int((-cv_n)/2+1)],fitline)\n",
    "    residuals = pspec[30:]-fitline_i[30:]\n",
    "    res_mean = np.nanmean(residuals)\n",
    "    res_std = np.nanstd(residuals)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# # REDO LIN REGRESSION WHEN PEAK IS FAR FROM BEST FIT\n",
    "# def find_peak_res(pspec,peak_freq):\n",
    "#     if np.isnan(pspec).all():\n",
    "#         return np.nan\n",
    "\n",
    "#     pspec[pspec<0] = np.nan\n",
    "#     xs = np.linspace(0,120,120*10+1)\n",
    "#     xs_nonan = xs[np.logical_not(np.isnan(pspec))]\n",
    "#     pspec_nonan = pspec[np.logical_not(np.isnan(pspec))]\n",
    "# #     print(len(xs), len(pspec), len(pspec_nonan))\n",
    "#     coeffs = np.polyfit(np.log(xs_nonan), np.log(pspec_nonan), 1, w=np.sqrt(pspec_nonan)) # fit y = A*e^(B*x)\n",
    "    \n",
    "#     # find peak freq\n",
    "# #     idcs = argrelextrema(pspec_nonan, np.greater)[0]\n",
    "# #     rel_maxs = pspec_nonan[idcs]\n",
    "# #     peak_freq = (idcs[np.argsort(rel_maxs)[::-1]]/10)[0]\n",
    "#     peak_res = pspec[int(peak_freq*10)] - np.exp(coeffs[1]) * xs[int(peak_freq*10)]**coeffs[0]\n",
    "#     return peak_res\n",
    "\n",
    "# def find_peak_var(pspec,peak_fq):\n",
    "#     if np.isnan(peak_fq):\n",
    "#         return np.nan\n",
    "#     if int(peak_fq*10-100) < 0:\n",
    "#         ROI = range(5, int(peak_fq*10+105))\n",
    "#     else:\n",
    "#         ROI = range(int(peak_fq*10-100), int(peak_fq*10+100)) # only look at points around peak\n",
    "#     xs = np.linspace(0,120,120*10+1)\n",
    "#     p0 = [2, y[pt], 3, 10] # initial guess of coefficients (A = amplitude?, mu = center, sigma = spread)\n",
    "# #     plt.figure()\n",
    "# #     plt.plot(xs,pspec,'-k',alpha = 0.3)\n",
    "# #     plt.plot(xs[ROI],pspec[ROI],'-k',alpha = 0.7)\n",
    "#     try:\n",
    "#         coeff, var_matrix = curve_fit(gauss, xs[ROI][np.logical_not(np.isnan(pspec[ROI]))], \n",
    "#                                       pspec[ROI][np.logical_not(np.isnan(pspec[ROI]))]-np.nanmin(pspec[ROI]), p0=p0, bounds = ((0,0,0,0), (100,100,20,100)))\n",
    "# #         print(' -- ', coeff)\n",
    "#         gauss_fit = gauss(xs[ROI], *coeff)\n",
    "#         return coeff[2]\n",
    "# #         plt.plot(xs[ROI],gauss_fit, ':r')\n",
    "#     except:\n",
    "#         print(' Could not find gauss fit parameters')\n",
    "\n",
    "\n",
    "# peak_res = np.array([find_peak_res(temp, pf) for temp, pf in zip(ps_sorted, y)])\n",
    "# # peak_var = np.array([find_peak_var(temp, pf) for temp, pf in zip(ps_sorted, y)])\n",
    "# res_cutoff = 1\n",
    "# ax1 =plt.axes([0.1, 0.1, .8, 0.3])\n",
    "# # norm2 = colors.Normalize(vmin=0, vmax = 15)\n",
    "# # plt.plot(x,y,'.k', alpha = 0.05)\n",
    "# sc = plt.scatter(np.array(x)[peak_res>res_cutoff],np.array(y)[peak_res>res_cutoff], s= 5,\n",
    "#              c = 'b', alpha = 0.2, norm=norm2)\n",
    "# # sc = plt.scatter(np.array(x)[peak_res>res_cutoff],np.array(y)[peak_res>res_cutoff], s= 5,\n",
    "# #             cmap=cm.cool, c = peak_var[peak_res>res_cutoff], alpha = 0.8, norm=norm2)\n",
    "# # # plt.colorbar.make_axes(fig.add_axes([.95,.1,.03,.3]))\n",
    "\n",
    "# x_nonan = np.array(x)[peak_res>res_cutoff]\n",
    "# x_c = sm.add_constant(x_nonan)\n",
    "# y_nonan = np.array(y)[peak_res>res_cutoff]\n",
    "# model = sm.OLS(y_nonan, x_c).fit()\n",
    "# predictions = model.predict(x_c)\n",
    "# plt.plot(x_nonan, predictions, '-k')\n",
    "# plt.title('linear regression for peak frequencies with residual > %i' % res_cutoff);\n",
    "# plt.xlabel('v (pix/s)')\n",
    "# ax1.text(700,7,'freq = %0.3f * v + %0.2f'% (model.params[1],model.params[0]), color = 'k')\n",
    "\n",
    "# # cbar = plt.colorbar(sc, cax = fig.add_axes([.92,.1,.01,.3]))#fig.add_axes([.95,.1,.03,.3]))\n",
    "# # cbar.set_label('gaussian fit sigma (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through all chunks and remove \"bad\" trials based on noise from moving avg line\n",
    "\n",
    "plt.close('all')\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# fft_data = pd.read_pickle(vid_locations + 'FFT_data')\n",
    "# print('read in data')\n",
    "subtypes = sorted(longtracks['substrate'].unique())\n",
    "coltypes = sorted(longtracks['colony'].unique())\n",
    "\n",
    "# define what data to use for specific colony and substrate\n",
    "colOI = coltypes[0]\n",
    "subOI = subtypes[1]\n",
    "v_ave = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['v_ave']\n",
    "peak_fqs = np.array([fs[0] for fs in fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['peak_freqs']])\n",
    "ps = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['pow_spec']\n",
    "\n",
    "def find_peak_fq(pspec): # find rel max ignoring first 3 Hz\n",
    "    if np.isnan(pspec).all():\n",
    "        return np.nan\n",
    "    idcs = argrelextrema(pspec, np.greater)[0]\n",
    "    rel_maxs = pspec[idcs[idcs>30]]\n",
    "    peak_freqs = idcs[idcs>30][np.argsort(rel_maxs)[::-1]]/10\n",
    "    return peak_freqs[0]\n",
    "\n",
    "ps_sorted = ps.loc[v_ave.sort_values().index].values #list(ps.values[np.argsort(v_ave).values])\n",
    "peak_freqs2 = np.array([find_peak_fq(ps) for ps in ps_sorted])\n",
    "y=peak_freqs2\n",
    "x = v_ave.sort_values().values\n",
    "\n",
    "\n",
    "def find_residuals(pspec):\n",
    "    cv_n = 200\n",
    "    xs = np.linspace(0, 120, len(pspec))\n",
    "#     print(len(xs))\n",
    "    xs_nonan = xs[np.logical_not(np.isnan(pspec))]\n",
    "    ys_nonan = pspec[np.logical_not(np.isnan(pspec))]\n",
    "    fitline = np.convolve(ys_nonan[10:], np.ones((cv_n,))/cv_n, mode = 'valid')\n",
    "    fitline_i = np.interp(xs,xs_nonan[int(cv_n/2+10):int((-cv_n)/2+1)],fitline)\n",
    "    residuals = pspec[30:]-fitline_i[30:]\n",
    "    res_mean = np.nanmean(residuals[600-30:])\n",
    "    res_std = np.nanstd(residuals[30:])\n",
    "    res_std_half = np.nanstd(residuals[600-30:])\n",
    "    return res_mean, res_std, res_std_half\n",
    "    \n",
    "\n",
    "res_info = np.array([find_residuals(ps) for ps in ps_sorted])\n",
    "res_mean = res_info[:,0]\n",
    "res_std = res_info[:,1]\n",
    "res_std_half = res_info[:,2]\n",
    "res_cutoff = 0.7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PLOT THINGS\n",
    "\n",
    "fig  = plt.figure(figsize = (8,12))\n",
    "ax1 =plt.axes([0.1, 0.65, .8, 0.3])\n",
    "plt.plot(x,y,'.k', alpha = 0.02)\n",
    "plt.title('Peak freq from all data chunks')\n",
    "plt.xlabel('v (pix/s)')\n",
    "plt.ylabel('freq with peak power')\n",
    "\n",
    "\n",
    "\n",
    "ax2 =plt.axes([0.1, 0.05, .8, 0.25])\n",
    "# apply conditions\n",
    "newy = peak_freqs2[np.logical_and(res_std_half<res_cutoff,peak_freqs2>5)]\n",
    "newx = x[np.logical_and(res_std_half<res_cutoff,peak_freqs2>5)]\n",
    "plt.plot(x,peak_freqs2,'.k', alpha = 0.02)\n",
    "plt.plot(newx,newy,'.r', alpha = 0.1)\n",
    "# plt.plot(x,peak_freqs2,'.k', alpha = 0.02)\n",
    "# plt.plot(x[res_std_half<res_cutoff],peak_freqs2[res_std_half<res_cutoff],'.r', alpha = 0.2)\n",
    "plt.xlabel('v (pix/s)')\n",
    "plt.ylabel('freq with peak power')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for sp in range(0,5):\n",
    "    plt.figure(fig.number)\n",
    "    ranC = np.random.rand(3,)\n",
    "    ax =plt.axes([0.08+sp*.15, 0.5, .15, 0.1])\n",
    "#     pt = 10+sp*int(len(x)/5.1)\n",
    "    pt = 10+sp*350\n",
    "    while np.isnan(y[pt]) or res_std_half[pt]>res_cutoff:\n",
    "        pt = pt + 1\n",
    "    ps_sorted[pt][ps_sorted[pt]<0] = np.nan #0.001 # get rid of negative power spectra values\n",
    "    xs = np.linspace(0,120,120*10+1).astype(np.float32)\n",
    "    ys = ps_sorted[pt]\n",
    "    xs_nonan = xs[np.logical_not(np.isnan(ps_sorted[pt]))]\n",
    "    ys_nonan = ps_sorted[pt][np.logical_not(np.isnan(ps_sorted[pt]))]\n",
    "    plt.plot(xs,ys, c = ranC)\n",
    "    plt.ylim((0,100))\n",
    "    plt.xlim((0,60))\n",
    "    plt.axvline(x = y[pt], alpha = 0.2)  \n",
    "    if not sp == 0:\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "#     else:\n",
    "#         plt.ylabel('log(power)')\n",
    "#         plt.xlabel('freq (Hz)')\n",
    "    ax1.plot(x[pt],y[pt], '.', c= ranC, Markersize = 10)\n",
    "    \n",
    "    \n",
    "    # fit y = A*x^B\n",
    "    coeffs = np.polyfit(np.log(xs_nonan[1::]), np.log(ys_nonan[1::]), 1)\n",
    "    ax.plot(xs, np.exp(coeffs[1]) * xs**coeffs[0],'--', alpha = 0.5, color= 'k', label = ' y=A*x^B')\n",
    "    fitline_e = np.exp(coeffs[1]) * xs**coeffs[0]\n",
    "    peak_res = ps_sorted[pt][int(y[pt]*10)] - np.exp(coeffs[1]) * xs[int(y[pt]*10)]**coeffs[0]\n",
    "    peak_res2 = ps_sorted[pt][int(peak_freqs2[pt]*10)] - np.exp(coeffs[1]) * xs[int(peak_freqs2[pt]*10)]**coeffs[0]\n",
    "    ax.text(58, 15, 'peak res: %0.1f'% peak_res2, color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "#     ax.text(58, 5, 'peak res: %0.1f'% peak_res, color = 'b', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "    print('res: %f - ave res: %f ' % (peak_res2, np.nanmean(ys[1:]-(np.exp(coeffs[1]) * xs[1:]**coeffs[0])) ))\n",
    "    if sp == 5:\n",
    "        ax.legend(fontsize = 6, frameon=False, bbox_to_anchor = (.4, 1.15));\n",
    "\n",
    "        \n",
    "    # fit average line\n",
    "    cv_n = 200\n",
    "    fitline = np.convolve(ys_nonan[10:], np.ones((cv_n,))/cv_n, mode = 'valid')\n",
    "    fitline_i = np.interp(xs,xs_nonan[int(cv_n/2+10):int((-cv_n)/2+1)],fitline)\n",
    "    ax.plot(xs,fitline_i, ':r', alpha = 0.5)\n",
    "    peak_res = ps_sorted[pt][int(y[pt]*10)] - fitline_i[(xs==y[pt])]\n",
    "#     print('res: %f - ave res: %f - rel res: %f' % (peak_res, np.nanmean(ys-fitline_i), np.abs(peak_res/np.nanmean(ys-fitline_i)) ))\n",
    "    ax.text(58, 5, 'peak res: %0.1f'% peak_res, color = 'r', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "    \n",
    "    \n",
    "    # plot residuals\n",
    "    axr =plt.axes([0.08+sp*.15, 0.36, .15, 0.1])\n",
    "#     plt.plot(xs,ps_sorted[pt]-fitline_i, '-', color= ranC)\n",
    "    plt.plot(xs,ps_sorted[pt]-fitline_e, '-', color= ranC)\n",
    "    \n",
    "    \n",
    "    def find_peak_residual(pspec, fitline): # find rel max ignoring first 3 Hz\n",
    "        if np.isnan(pspec).all():\n",
    "            return np.nan\n",
    "        residuals = pspec - fitline\n",
    "        residuals[np.isnan(residuals)]=0\n",
    "        p_idcs = argrelextrema(residuals, np.greater)[0]\n",
    "        peaks = residuals[p_idcs]\n",
    "        t_idcs = argrelextrema(residuals, np.lesser)[0]\n",
    "        troughs = residuals[t_idcs]\n",
    "#         rel_maxs = pspec[idcs[idcs>30]]\n",
    "#         peak_freqs = idcs[idcs>30][np.argsort(rel_maxs)[::-1]]/10\n",
    "#         return peak_freqs[0]\n",
    "    \n",
    "    plt.axhline(y=res_mean[pt])\n",
    "    plt.axhline(y=res_mean[pt]+res_std[pt], LineStyle = '--')\n",
    "#     plt.axhline(y=res_mean[pt]+res_std_half[pt], LineStyle = ':')\n",
    "    plt.axvline(x=y[pt], alpha = 0.2)\n",
    "    plt.axvline(x=peak_freqs2[pt], Color ='r', alpha = 0.2)\n",
    "    ax.axvline(x=peak_freqs2[pt], Color ='r', alpha = 0.2)\n",
    "    plt.ylim((-10,15))\n",
    "    plt.xlim((0,60))\n",
    "    if not sp == 0:\n",
    "        axr.get_yaxis().set_visible(False)\n",
    "#         ax.get_xaxis().set_visible(False)\n",
    "#     plt.text(37,8, '%0.1f'% res_std_half[pt], color= ranC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test another way of finding peak frequencies\n",
    "plt.close('all')\n",
    "colOI = coltypes[0]\n",
    "subOI = subtypes[1]\n",
    "v_ave = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['v_ave']\n",
    "ps = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['pow_spec_raw']\n",
    "ps_fr = fft_data[(fft_data['colony']==colOI) & (fft_data['substrate']==subOI)]['pow_freq_raw']\n",
    "ps_sorted = ps.loc[v_ave.sort_values().index].values \n",
    "ps_fr_sorted = ps_fr.loc[v_ave.sort_values().index].values \n",
    "\n",
    "\n",
    "def find_res_peak(pspec, fitline):\n",
    "    residuals = pspec - fitline\n",
    "    residuals[np.isnan(residuals)]=0\n",
    "    p_idcs = argrelextrema(residuals, np.greater)[0]\n",
    "    if not p_idcs.any() < 0:\n",
    "        return np.nan\n",
    "    t_idcs = argrelextrema(residuals, np.less)[0]\n",
    "    t_idcs = t_idcs[t_idcs > p_idcs[0]]\n",
    "    t_idcs = t_idcs[:np.min([len(p_idcs), len(t_idcs)])]\n",
    "    p_idcs = p_idcs[:np.min([len(p_idcs), len(t_idcs)])]\n",
    "    peaks = residuals[p_idcs]\n",
    "    troughs = residuals[t_idcs]\n",
    "    true_peaks = p_idcs[np.logical_and((peaks > 5),(troughs < 0))]\n",
    "    print(len(xs[true_peaks]))\n",
    "    if xs[true_peaks].any():\n",
    "        return xs[true_peaks][0]\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def fit_exponential(pspec, pspec_xf):\n",
    "    coeffs = np.polyfit(np.log(pspec_xf[1::]), np.log(pspec[1::]), 1)\n",
    "    fitline_e = np.exp(coeffs[1]) * pspec_xf**coeffs[0]\n",
    "    return fitline_e\n",
    "\n",
    "test = np.array([fit_exponential(y,x) for y,x in zip(ps_sorted, ps_fr_sorted)])\n",
    "peak_freqs = np.array([find_res_peak(y, fit_exponential(y,x)) for y,x in zip(ps_sorted, ps_fr_sorted)])\n",
    "# v_ave_sorted = v_ave.sort_values().values\n",
    "\n",
    "\n",
    "# plt.figure(figsize = (8,12))\n",
    "# ax1 =plt.axes([0.1, 0.65, .8, 0.3])\n",
    "# plt.plot(v_ave_sorted,peak_freqs,'.k', alpha = 0.02)\n",
    "\n",
    "# for sp in range(0,6):\n",
    "#     pt = 10+sp*250\n",
    "\n",
    "#     xs = ps_fr_sorted[pt]\n",
    "#     ys = ps_sorted[pt]\n",
    "#     ax =plt.axes([0.08+sp*.15, 0.5, .15, 0.1])\n",
    "#     ax.plot(xs,ys,'-k')\n",
    "    \n",
    "\n",
    "#     # fit y = A*x^B\n",
    "#     coeffs = np.polyfit(np.log(xs[1::]), np.log(ys[1::]), 1)\n",
    "#     fitline_e = np.exp(coeffs[1]) * xs**coeffs[0]\n",
    "#     ax.plot(xs, fitline_e,'--', alpha = 0.5, color= 'k', label = ' y=A*x^B')\n",
    "#     plt.ylim((0,100))\n",
    "#     plt.xlim((0,60))\n",
    "# #     peak_res = ps_sorted[pt][int(y[pt]*10)] - np.exp(coeffs[1]) * xs[int(y[pt]*10)]**coeffs[0]\n",
    "# #     peak_res2 = ps_sorted[pt][int(peak_freqs2[pt]*10)] - np.exp(coeffs[1]) * xs[int(peak_freqs2[pt]*10)]**coeffs[0]\n",
    "# #     ax.text(58, 15, 'peak res: %0.1f'% peak_res2, color = 'k', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "# #     #     ax.text(58, 5, 'peak res: %0.1f'% peak_res, color = 'b', alpha = 0.5, fontsize = 8, horizontalalignment = 'right')\n",
    "# #     print('res: %f - ave res: %f ' % (peak_res2, np.nanmean(ys[1:]-(np.exp(coeffs[1]) * xs[1:]**coeffs[0])) ))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "#     axr =plt.axes([0.08+sp*.15, 0.36, .15, 0.1])\n",
    "#     axr.plot(xs, ys-fitline_e)\n",
    "#     plt.ylim((-15,15))\n",
    "#     plt.xlim((0,60))\n",
    "#     plt.axhline(y=0, LineStyle = '--', Color = 'k', alpha = 0.3)\n",
    "#     if not sp == 0:\n",
    "#         axr.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "    \n",
    "#     ax.axvline(x=xs[true_peaks[0]], Color ='r', alpha = 0.2)\n",
    "#     axr.axvline(x=xs[true_peaks[0]], Color ='r', alpha = 0.2)\n",
    "\n",
    "# #         rel_maxs = pspec[idcs[idcs>30]]\n",
    "# #         peak_freqs = idcs[idcs>30][np.argsort(rel_maxs)[::-1]]/10\n",
    "# #         return peak_freqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "# t = np.linspace(-1, 1, 200, endpoint=False)\n",
    "# sig  = np.cos(2 * np.pi * 7 * t) + signal.gausspulse(t - 0.4, fc=2)\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "\n",
    "tr_num = 8976\n",
    "x = longtracks.loc[tr_num].copy()\n",
    "t = x.frames_final\n",
    "sig= x.v\n",
    "widths = np.arange(1, 31)\n",
    "fig = plt.figure()\n",
    "plt.axes([.1,.55,.75,.4])\n",
    "plt.plot(t,sig)\n",
    "plt.xlim(t[0],t[-1])\n",
    "plt.gca().get_xaxis().set_visible(False)\n",
    "\n",
    "\n",
    "cwtmatr = signal.cwt(sig, signal.ricker, widths)\n",
    "ax2 = plt.axes([.1,.1,.75,.4])\n",
    "ax3 = fig.add_axes([.88,.1,.02,.4])\n",
    "im = ax2.imshow(cwtmatr, extent=[t[0],t[-1], widths.max(), 1], cmap='PRGn', aspect='auto',vmax=abs(cwtmatr).max(), vmin=-abs(cwtmatr).max())\n",
    "ax2.set_ylabel('widths')\n",
    "ax2.set_xlabel('time')\n",
    "plt.colorbar(im, cax = ax3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "fs = 10e3\n",
    "N = 1e5\n",
    "amp = 2 * np.sqrt(2)\n",
    "noise_power = 0.01 * fs / 2\n",
    "time = np.arange(N) / float(fs)\n",
    "mod = 500*np.cos(2*np.pi*0.25*time)\n",
    "carrier = amp * np.sin(2*np.pi*3e3*time + mod)\n",
    "noise = np.random.normal(scale=np.sqrt(noise_power), size=time.shape)\n",
    "noise *= np.exp(-time/5)\n",
    "x = carrier + noise\n",
    "# f, t2, Sxx = signal.spectrogram(np.array(sig), 240)\n",
    "# plt.pcolormesh(t2,f,Sxx)\n",
    "f, t, Sxx = signal.spectrogram(x, fs)\n",
    "plt.pcolormesh(t,f,Sxx)\n",
    "plt.ylabel('Freq (Hz)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT A HEATMAP FOR A SINGLE COLONY AND SUBSTRATE - SUBSAMPLE EVERY Nth SAMPLE\n",
    "\n",
    "plt.figure(figsize = (5,12))\n",
    "\n",
    "subsample = 20\n",
    "hmap = sns.heatmap(allpowers_sorted[::subsample], xticklabels = 1000, yticklabels = 10, cbar_kws = {'label': 'log(power)'})\n",
    "hmap.set_yticklabels(['%i' % v for v in allpowers_vs_sorted[::subsample][::10]])\n",
    "hmap.set_xticklabels(np.arange(0,121,10))\n",
    "plt.yticks(rotation=0)\n",
    "plt.ylabel('ave v (pix/s)');\n",
    "plt.xlabel('freq (Hz)');\n",
    "plt.title('%s -- %s -- subsample: %i' % (subtype, coltype[-5:], subsample))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trials for Shai/Brian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "for tr in range(1000,1020):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.text(0, 70, 'Trial: %i'%tr)\n",
    "\n",
    "    for joint_num in range(0,6):\n",
    "        plt.plot(df['joint%i_x_filt_WRTneck'%joint_num][tr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate orientation of ant\n",
    "\n",
    "\n",
    "def find_orientation_df(x): #'rotation', 'Len', 'Dur', 'travel_dir'\n",
    "    orie = np.arctan2(x['neck_y_filt_fullfr']-x['thorax_y_filt_fullfr'], x['neck_x_filt_fullfr']-x['thorax_x_filt_fullfr'])\n",
    "    return orie\n",
    "\n",
    "\n",
    "df['orientation']= df.apply(find_orientation_df, args = (), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving csv for trial 5\n",
      "     /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080521_16276736-0000.mp4\n",
      "saving csv for trial 1007\n",
      "     /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/3mm/20180314_094259_16276718-0000.mp4\n",
      "saving csv for trial 24\n",
      "     /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_083709_16276736-0000.mp4\n",
      "saving csv for trial 433\n",
      "     /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180313_095948_16276712-0000.mp4\n",
      "saving csv for trial 22\n",
      "     /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_083333_16276736-0000.mp4\n",
      "saving csv for trial 439\n",
      "     /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180313_100402_16276712-0000.mp4\n"
     ]
    }
   ],
   "source": [
    "for tr in [5,1007,24,433,22,439]:\n",
    "    print('saving csv for trial %i'%tr)\n",
    "    print('    ', df['video'][tr])\n",
    "    \n",
    "    s_location = vid_locations + 'GaitPhasing/' + 'Trial_%04.0f'%tr\n",
    "    vars_OI = ['frames', 'frames_final', 'x_kal', 'y_kal', 'x_raw', 'y_raw', 'x', 'y', 'angle', 'angle_improved', 'orientation']\n",
    "    for wrt in ['', '_filt_fullfr']:\n",
    "        for jj in ['thorax','joint']:\n",
    "            if jj == 'thorax':\n",
    "                for coord in ['x','y']:\n",
    "                    vars_OI.append('%s_%s%s'%(jj,coord,wrt))\n",
    "            else:\n",
    "                for jn in range(0,6):\n",
    "                    for coord in ['x','y']:\n",
    "                        vars_OI.append('%s%i_%s%s'%(jj,jn,coord,wrt))\n",
    "    for wrt in ['_filt_WRTneck']:\n",
    "        for jn in range(0,6):\n",
    "            for coord in ['x','y']:\n",
    "                vars_OI.append('joint%i_%s%s'%(jn,coord,wrt))\n",
    "\n",
    "    n_frs = len(df['angle'][tr])-1\n",
    "    tmp = np.full((n_frs, len(vars_OI)), np.nan)\n",
    "    idcs = np.isin(df['frames'][tr][1:],df['frames_final'][tr])\n",
    "\n",
    "    for vv,var in enumerate(vars_OI):\n",
    "        tmp2 = df[var].iloc[tr]\n",
    "        if (len(tmp2)-1)==n_frs:\n",
    "            tmp[:,vv] = tmp2[1:]\n",
    "        else:\n",
    "            tmp[idcs,vv] = tmp2\n",
    "        del tmp2\n",
    "\n",
    "\n",
    "    glenna = pd.DataFrame(tmp, columns = vars_OI)\n",
    "    glenna['frames'] = glenna['frames'].astype(int)\n",
    "    glenna.to_csv(s_location, sep = '\\t', index=False, float_format = '%11.4f', na_rep = 'nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arctan2(df['neck_y_filt_fullfr'][1]-df['thorax_y_filt_fullfr'][1], df['neck_x_filt_fullfr'][1]-df['thorax_x_filt_fullfr'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find fastest trials\n",
    "\n",
    "Use these df trackways to make sure that you aren't getting tracking artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortbyvs = longtracks.copy()\n",
    "\n",
    "allvs = longtracks.v\n",
    "allidcs = list(longtracks.index)\n",
    "maxvs = allvs.apply(np.max)\n",
    "sortbyvs['maxv'] = maxvs\n",
    "sortbyvs = sortbyvs.sort_values(['maxv'], ascending = False)\n",
    "\n",
    "print(sortbyvs.iloc[0:10][['maxv','substrate','datetime']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_num = 124\n",
    "norm2 = colors.Normalize(vmin=0, vmax = 1500)\n",
    "# plt.scatter(glenna.loc[tr_num].x, glenna.loc[tr_num].y)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "blankvtrace = np.full(glenna.loc[tr_num].frames.shape,np.nan)\n",
    "\n",
    "plt.plot(glenna.loc[tr_num].frames[1:], glenna.loc[tr_num].vfilt, '-k', alpha = 0.5);\n",
    "plt.plot(glenna.loc[tr_num].frames_final+1, glenna.loc[tr_num].v_final, '-g');\n",
    "plt.plot(glenna.loc[tr_num].frames[30-1:-30], glenna.loc[tr_num].v_runave, '.b', alpha = 0.5);\n",
    "plt.plot(glenna.loc[tr_num].frames_final, glenna.loc[tr_num].dist_90fr*(240/90), '.r', alpha = 0.5);\n",
    "plt.legend(('filtered v','v within ROI/moving','v_runavg','net pix over 90 fr'))\n",
    "# plt.scatter(df.frames_final[tr_num], temp, #'-' ,\n",
    "#          cmap=cm.cool, c=temp, edgecolor='none', norm=norm2)\n",
    "\n",
    "\n",
    "\n",
    "# longtracks.apply(np.convolve, args = (np.ones((60,))/60, mode = 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman filtering to smooth out tracked data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
