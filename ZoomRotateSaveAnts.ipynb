{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import matlab.engine\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import glob\n",
    "from scipy import stats\n",
    "from scipy.signal import argrelextrema\n",
    "import datetime\n",
    "import cv2\n",
    "import time\n",
    "import imutils\n",
    "import png\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import smtplib\n",
    "\n",
    "os.system(\"qmake --version\")\n",
    "os.system(\"python --version\")\n",
    "\n",
    "%matplotlib qt5\n",
    "%matplotlib auto\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "sys.path.append('/home/gravishlab/Documents/Python/')\n",
    "sys.path.append('/home/gravishlab/Documents/Python/Tracker/')\n",
    "sys.path.append('/home/gravishlab/Documents/Python/Tracker/Tracker/')\n",
    "from Tracker.Tracker import Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Videos:  8266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8266"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vid_locations = '/media/gravishlab/SeagateExpansionDrive/AntTrack/'\n",
    "file_list = []\n",
    "file_list = glob.glob(os.path.join(vid_locations, '**/**/*-0000.mp4'))\n",
    "# file_list = glob.glob(os.path.join(vid_locations, 'Tunnel_20180313-14/**/*0000.mp4'))\n",
    "file_list = sorted(file_list)\n",
    "\n",
    "print('Total Number of Videos: ',len(file_list))\n",
    "\n",
    "\n",
    "#file_list = file_list[0:15] +file_list[278:292] +file_list[578:592] +file_list[878:902] #   [::20] #[0:3000:5]       \n",
    "# file_list = file_list[0:500]\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_info = []\n",
    "\n",
    "for file in file_list:\n",
    "    tmps = file.split('/')\n",
    "#     print(tmps[-1].split('_')[1])\n",
    "#     print(os.path.splitext(tmps[-1])[0])\n",
    "    trial_info.append({'substrate': tmps[-2],\n",
    "                     'date': tmps[-1].split('_')[0],\n",
    "                     'time': tmps[-1].split('_')[1],\n",
    "                     'cam': tmps[-1].split('-')[0][-2:],\n",
    "                     'colony': tmps[-3]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FUNCTIONS\n",
    "\n",
    "def track_video(file):\n",
    "    print(kk, ' -- ', file)\n",
    "    video = Tracker(file,min_object_size=40)\n",
    "    \n",
    "    if not video.file_exists_assoc:\n",
    "        print('***', video.file_exists_assoc,  '*** -- ', file)\n",
    "        \n",
    "        \n",
    "    if True:\n",
    "        print('tracking')\n",
    "        video.threshold_val = 0.2\n",
    "        video.load_video()\n",
    "        video.compute_background()          # form background image\n",
    "        video.remove_background()           # remove background\n",
    "        video.threshold()                   # threshold to segment features\n",
    "        video.find_distance()               # remove dist before closing on clear bridge\n",
    "        video.morpho_closing()\n",
    "        video.find_objects()\n",
    "#             print('-- deleted .h5 file for ant %i'%obj_idx)\n",
    "        video.draw_contours()\n",
    "        video.save_JSON()\n",
    "        video.associate_contours(max_covariance=10,\n",
    "                         max_velocity=100,\n",
    "                         n_covariances_to_reject=20, \n",
    "                         max_tracked_objects=100,\n",
    "                         kalman_state_cov=1,\n",
    "                         kalman_init_cov=0.2,\n",
    "                         kalman_measurement_cov=1)\n",
    "        video.save_association_JSON()\n",
    "        print('done')\n",
    "        return video\n",
    "    \n",
    "\n",
    "def make_image_folder(file):\n",
    "    basename = ('/').join(file.split('/')[:-1])\n",
    "    foldername = file.split('/')[-1].split('.')[0]\n",
    "    savelocation = ('/').join([basename, foldername])\n",
    "    if not os.path.exists(savelocation):\n",
    "        os.mkdir(savelocation)\n",
    "        print('-- made new folder')\n",
    "    else:\n",
    "        print('-- folder already exists')\n",
    "    return savelocation;\n",
    "\n",
    "\n",
    "def run_SVM_for_LvR():\n",
    "    SVM_path = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/LvsR_trainingset/SVMdata.h5'\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "#     from sklearn.metrics import classification_report\n",
    "#     from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    if os.path.exists(SVM_path):\n",
    "        \n",
    "        # LOAD IN FROM H5 APPROACH:\n",
    "# #                 print('ant%i predictions exist'%ant_num)\n",
    "#         hf = h5py.File(SVM_path,'r')\n",
    "#         X = hf['X'][()].astype(np.float32) #hf.get('positions_pred')\n",
    "#         y = hf['y'][()] #hf.get('conf_pred')\n",
    "#         target_names = hf['target_names'][()]\n",
    "#         target_names = target_names.astype('<U5')\n",
    "    \n",
    "# #         target_names_h5 = hf['target_names'][()]\n",
    "# #         target_names_h5 = target_names_h5.astype('<U5')\n",
    "#         labels = hf['labels'][()]\n",
    "#         labels = labels.astype('<U5')\n",
    "        \n",
    "# #         target_names = np.array(list(set(labels))).astype('<U17')\n",
    "# #         y = np.squeeze(np.array([np.where(np.isin(target_names,item))[0] for item in labels]))\n",
    "# #         target_names = target_names.astype('<U5')\n",
    "        \n",
    "# #         print('h5 -- target names', target_names_h5)\n",
    "#         print('labels -- target names' , target_names)\n",
    "#         print(y[0:12])\n",
    "#         print(labels[0:12])\n",
    "#         plt.figure()\n",
    "#         print(X[11].shape)\n",
    "#         plt.imshow(np.reshape(X[11], (200,200)))\n",
    "        \n",
    "#         n_samples = X.shape[0]\n",
    "#         n_classes = target_names.shape[0]\n",
    "#         h = 200\n",
    "#         w = 200\n",
    "#         n_features = X.shape[1]\n",
    "        \n",
    "        \n",
    "        # LOAD IN ALL IMAGES APPROACH ---- SLOW\n",
    "        import imageio\n",
    "        im_locations = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/LvsR_trainingset'\n",
    "        file_list = []\n",
    "        file_list = glob.glob(os.path.join(im_locations, '**/**.png'))\n",
    "        file_list = sorted(file_list)\n",
    "        images = np.empty((0,200,200), int)\n",
    "        labels = []#np.chararray((0,1))\n",
    "        for im_path in file_list:\n",
    "            image = imageio.imread(im_path)\n",
    "            label = im_path.split('/')[-2]\n",
    "            images = np.append(images, image[np.newaxis,:,:], axis = 0)\n",
    "        #     print(images.shape, image[np.newaxis,:,:].shape)\n",
    "        #     np.append(labels, [label], axis = 0)\n",
    "            labels.append(label)\n",
    "        labels = np.array(labels) \n",
    "\n",
    "        n_samples = images.shape[0]\n",
    "        h = 200\n",
    "        w = 200\n",
    "\n",
    "        X = np.reshape(images, [n_samples, w*h])\n",
    "        n_features = X.shape[1]\n",
    "        target_names = np.array(list(set(labels))).astype('<U17')\n",
    "        y = np.squeeze(np.array([np.where(np.isin(target_names,item))[0] for item in labels]))\n",
    "        n_classes = target_names.shape[0]\n",
    "\n",
    "        \n",
    "        # compute eigenimages (unsupervised feature extraction)\n",
    "        n_components = 50\n",
    "        pca = PCA(n_components = n_components, svd_solver = 'randomized', whiten = True).fit(X)\n",
    "        # Projecting the input dat on the eigenimage orthonormal basis \n",
    "        x_pca = pca.transform(X)\n",
    "        # Train SVM classification model\n",
    "        param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "             'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "        clf = GridSearchCV(SVC(kernel ='rbf', class_weight = 'balanced'), param_grid)\n",
    "        clf = clf.fit(x_pca, y)\n",
    "        print('--- best estimator found by grid search:')\n",
    "        print('---', clf.best_estimator_)\n",
    "    else:\n",
    "        print('--- No data for SVM')\n",
    "    \n",
    "    return pca, clf, target_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def rotate_and_zoom_frame(video, obj_OI, fr_num, buffer, x_dim, y_dim):\n",
    "    idc = np.where(obj_OI['frames'] == fr_num)[0][0]\n",
    "    x = obj_OI['x'][idc]\n",
    "    y = obj_OI['y'][idc]\n",
    "\n",
    "    # set buffer around bkgd div image so ant is always in center for zoomed-in view\n",
    "    temp = video.frames_normed[int(fr_num)]\n",
    "    blank_frame = np.ones((y_dim+ 2*buffer, x_dim+ 2*buffer))* 0.7 #1.001# np.max(temp) # gray background  1.0001#\n",
    "#     blank_frame = np.zeros((y_dim+ 2*buffer, x_dim+ 2*buffer)) # black background\n",
    "    frame = blank_frame.copy()\n",
    "    frame[buffer:-buffer, buffer:-buffer] = temp\n",
    "\n",
    "    # zoom into around ant\n",
    "    xrange = range(int(round(x)), int(round(x+2*buffer)))\n",
    "    yrange = range(int(round(y)), int(round(y+2*buffer)))\n",
    "    xrange_actual = sorted(list( set(xrange) & set(range(0, x_dim+2*buffer) ) ))\n",
    "    yrange_actual = sorted(list( set(yrange) & set(range(0, y_dim+2*buffer) ) ))\n",
    "    frame_zoom = frame[np.ix_(yrange_actual, xrange_actual)]\n",
    "\n",
    "    # rotate ant\n",
    "    rotation = obj_OI['angle_smooth'][idc]\n",
    "    if not np.isnan(rotation):\n",
    "        rotated = imutils.rotate_bound(frame_zoom, -1*rotation)\n",
    "        rot_ranges = [range(int(x/2-100), int(x/2+100)) for x in rotated.shape];\n",
    "        rotated_zoom = rotated[np.ix_(rot_ranges[0], rot_ranges[1])]\n",
    "    else:\n",
    "        rotated_zoom = np.zeros((200,200))\n",
    "        \n",
    "    return frame, frame_zoom, rotated_zoom;\n",
    "\n",
    "\n",
    "def adjust_gain(temp, bkgd_cutoff = 5):                \n",
    "    # adjust gain of image -- option 2\n",
    "    temp = -1*(temp-1)\n",
    "    temp = temp/np.max(temp)\n",
    "    cutoff = 5\n",
    "    temp =(255-bkgd_cutoff)*temp + bkgd_cutoff\n",
    "    temp[temp<0]=0\n",
    "    \n",
    "    # adjust gain of image -- option 1\n",
    "#     print(np.min(temp),np.max(temp))\n",
    "#     temp = 2-temp\n",
    "#     min_o = np.min(temp)\n",
    "#     max_o = np.max(temp)\n",
    "#     temp = ((temp - min_o)/(max_o-min_o)*255)\n",
    "#     cutoff = (1-min_o)*1.4*255\n",
    "#     print(cutoff)\n",
    "#     temp[temp<bkgd_cutoff]=temp[temp<bkgd_cutoff]-10\n",
    "#     temp[temp<0]=0\n",
    "    return temp\n",
    "\n",
    "# plot full back div frame, zoomed in on ant, and rotated zoomed-in view\n",
    "def plot_compilation_fig_fn(frame, frame_zoom, rotated_zoom, buffer):\n",
    "    plt.close('all')\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(2,2)\n",
    "    gs.tight_layout(fig, rect = [0.5, 0, 1,1], h_pad = 0.5)\n",
    "    ax1 = plt.subplot(gs[0,0:2])\n",
    "    ax2 = plt.subplot(gs[1,0])\n",
    "    ax3 = plt.subplot(gs[1,1])\n",
    "\n",
    "    ax1.clear()\n",
    "    ax1.imshow(frame[buffer:-buffer, buffer:-buffer])\n",
    "#     ax1.plot(x,y,'.r', markersize =2)\n",
    "#     ax1.invert_yaxis()\n",
    "\n",
    "    ax2.imshow(frame_zoom)\n",
    "#     ax2.invert_yaxis()\n",
    "    ax2.axis('off')\n",
    "\n",
    "    ax3.clear()\n",
    "    ax3.axis('off')\n",
    "    if not np.max(rotated_zoom)==0:\n",
    "        ax3.imshow(rotated_zoom)\n",
    "#                 ax3.imshow(rotated)\n",
    "#         ax3.invert_yaxis()\n",
    "    plt.pause(0.2)\n",
    "    return;\n",
    "\n",
    "\n",
    "# plot only zoomed-in and rotated image\n",
    "def plot_rotated_img_fn(rotated_zoom, fr_num):\n",
    "    if not np.max(rotated_zoom)==0:\n",
    "        plt.close('all')\n",
    "        plt.figure(figsize = (5,5))\n",
    "        plt.imshow(rotated_zoom, cmap = 'gray')\n",
    "        plt.text(10,10,'Fr: %i'%fr_num, color = 'w')\n",
    "        plt.gca().axis('off')\n",
    "        plt.pause(0.5)\n",
    "    return;\n",
    "\n",
    "def save_video(folder, base):\n",
    "    # save images as movie\n",
    "    if os.path.isfile((folder + '/' + base + \".mp4\")):\n",
    "        os.remove(folder + '/' + base + \".mp4\")\n",
    "        print('** Deleted .mp4 file')\n",
    "    print('saving .mp4 file')\n",
    "#     command_to_run = \"ffmpeg -r 20 -i '\" + folder  + \"/\" + base + \"_fr%03.0.png' -vcodec libx264 '\" + folder + \"/\" + base + \".mp4'\"\n",
    "#     print(command_to_run)\n",
    "    os.system(\"ffmpeg -pattern_type glob -r 20 -i '\" + folder  + \"/\" + base + \"_fr*.png' -vcodec libx264 '\" \n",
    "              + folder + \"/\" + base + \".mp4'\")\n",
    "    plt.pause(4)\n",
    "    \n",
    "    # delete all trackway vids\n",
    "    pics2delete = glob.glob(os.path.join(folder, base+'_fr*.png'))\n",
    "    for pic in pics2delete:\n",
    "        os.remove(pic)\n",
    "    return\n",
    "    \n",
    "    \n",
    "# i created a gmail account just for this purpose\n",
    "username = 'codefromglenna'\n",
    "password = 'imacomputer'\n",
    "fromaddr = 'codefromglenna@gmail.com'\n",
    "toaddr   = '6106392662@vtext.com'\n",
    "\n",
    "def sendtxt(msg):\n",
    "    server = smtplib.SMTP('smtp.gmail.com:587');\n",
    "#     server.connect();\n",
    "    server.starttls();\n",
    "    server.login(username,password);\n",
    "    server.sendmail(fromaddr, toaddr, msg) # -- ' + time.ctime() )\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to find flipped angles, smooth, and interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILP ANGLE FUNCTIONS\n",
    "\n",
    "# for a given frame, determine if angle is flipped\n",
    "# def find_flipped_angles(obj, fr_OI, plots_on = False):\n",
    "#     all_angs = obj_OI['angle_improved']\n",
    "#     all_frs = obj_OI['frames']\n",
    "#     fr_OI_idc = np.where(all_frs == fr_OI)[0][-1]\n",
    "    \n",
    "#     # just look at window around frame\n",
    "#     win_idcs = np.logical_and( np.logical_and(all_frs >= fr_OI - 10, all_frs <= fr_OI + 10), all_frs != fr_OI) \n",
    "#     win_frs = all_frs[win_idcs]\n",
    "#     win_angs = all_angs[win_idcs]\n",
    "\n",
    "#     if plots_on:\n",
    "#         plt.plot(all_frs, np.sin(np.deg2rad(all_angs)), '.k', alpha = 0.2)\n",
    "#         plt.plot(all_frs, np.cos(np.deg2rad(all_angs)), '.b', alpha = 0.2)\n",
    "#         plt.plot(win_frs, np.sin(np.deg2rad(win_angs)), '.k')\n",
    "#         plt.plot(win_frs, np.cos(np.deg2rad(win_angs)), '.b')\n",
    "#         plt.plot(fr_OI, np.sin(np.deg2rad(all_angs[fr_OI_idc])), '*r')\n",
    "#         plt.plot(fr_OI, np.cos(np.deg2rad(all_angs[fr_OI_idc])), '*r')\n",
    "\n",
    "#     # what are sin and cos of nearby frames\n",
    "#     win_sin = np.nanmedian(np.sin(np.deg2rad(win_angs)))\n",
    "#     win_cos = np.nanmedian(np.cos(np.deg2rad(win_angs)))\n",
    "#     fr_sin = np.sin(np.deg2rad(all_angs[fr_OI_idc]))\n",
    "#     fr_cos = np.cos(np.deg2rad(all_angs[fr_OI_idc]))\n",
    "#     is_flipped = np.logical_or(np.abs(fr_sin - win_sin) > 0.5, np.abs(fr_cos - win_cos) > 0.5)\n",
    "#     print(is_flippe[-30:])\n",
    "    \n",
    "#     # smooth out angle by av\n",
    "# #     if is_flipped:\n",
    "# #         print('Fr: %0.0f -- sin: %0.2f vs. %0.2f -- cos: %0.2f vs. %0.2f'%(fr_OI, fr_sin, win_sin, fr_cos, win_cos))\n",
    "#     return is_flipped, all_angs[fr_OI_idc]\n",
    "\n",
    "\n",
    "def calc_mov_avg(x, N, cutoff_nan):\n",
    "    padded_x = np.insert(np.insert( np.insert(x, len(x), np.empty(int(N/2))*np.nan), 0, np.empty(int(N/2))*np.nan ),0,0)\n",
    "    n_nan = np.cumsum(np.isnan(padded_x)) \n",
    "    cumsum = np.nancumsum(padded_x) \n",
    "    window_sum = cumsum[N+1:] - cumsum[:-(N+1)] - x\n",
    "    window_n_nan = n_nan[N+1:] - n_nan[:-(N+1)] - np.isnan(x)\n",
    "    window_n_values = (N - window_n_nan).astype(float)\n",
    "    window_n_values[window_n_values<cutoff_nan] = np.nan # if fewer than cutoff values in window, ignore\n",
    "    movavg = (window_sum) / (window_n_values)\n",
    "    return movavg\n",
    "\n",
    "\n",
    "def find_flipped_angles_all(obj, plots_on = False):\n",
    "    \n",
    "    all_angs = obj_OI['angle_improved']\n",
    "    all_frs = obj_OI['frames']\n",
    "    all_sin = np.sin(np.deg2rad(all_angs))\n",
    "    all_cos = np.cos(np.deg2rad(all_angs))\n",
    "    \n",
    "    if plots_on:\n",
    "        plt.figure()\n",
    "        plt.subplot(3,1,1)\n",
    "        plt.plot(all_frs, all_sin, '-k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_sin, '.g', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_cos, '-k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_cos, '.b', alpha = 0.3)\n",
    "\n",
    "    # FLIP EVERY OTHER SECTION DEFINED WHERE COS OR SIN CHANGES BY MORE THAN 1\n",
    "    idcs = np.where(np.logical_not(np.isnan(all_sin)))[0]\n",
    "    d_sin = np.abs(np.diff(all_sin[idcs]))\n",
    "    d_cos = np.abs(np.diff(all_cos[idcs]))\n",
    "    d_big = np.logical_or(d_sin> 1.5, d_cos > 1.5)\n",
    "    d_big_cumsum = np.cumsum(np.insert(d_big,0,0))\n",
    "    d_big_opp = (d_big_cumsum%2).astype(bool)\n",
    "    \n",
    "    if plots_on:\n",
    "        plt.plot(all_frs[idcs[d_big_opp]], all_sin[idcs[d_big_opp]], '.r', MarkerSize = 2)\n",
    "        plt.plot(all_frs[idcs[d_big_opp]], all_cos[idcs[d_big_opp]], '.r', MarkerSize = 2)\n",
    "    \n",
    "    all_sin[idcs[d_big_opp]] = -1* all_sin[idcs[d_big_opp]]\n",
    "    all_cos[idcs[d_big_opp]] = -1* all_cos[idcs[d_big_opp]]\n",
    "    \n",
    "    def remove_90_turns(arr, all_frs):\n",
    "        idcs = np.where(np.isfinite(arr))[0]\n",
    "        d_arr = np.diff(arr[idcs])\n",
    "        d_sign = np.sign(d_arr)\n",
    "        d_med = np.logical_and( np.abs(d_arr) > 0.5, np.abs(d_arr) < 1.5)\n",
    "        d_med_cumsum = np.cumsum(np.insert(d_med,0,0))\n",
    "        d_med_opp = np.cumsum(np.insert(d_sign*d_med,0,0))#(d_med_cumsum%2).astype(bool)\n",
    "        if np.sum(d_med_opp==0)<np.sum(d_med_opp != 0):\n",
    "            d_med_opp = d_med_opp - np.median(d_med_opp)\n",
    "        arr[idcs]=np.clip(arr[idcs]-d_med_opp, -1, 1)  \n",
    "        return arr\n",
    "    all_sin = remove_90_turns(all_sin, all_frs)\n",
    "    all_cos = remove_90_turns(all_cos, all_frs)\n",
    "\n",
    "    # FIND WHERE DIFFERS FROM MOVING AVE BY AMOUNT AND SWITCH\n",
    "#     for reps in range(0,2):\n",
    "#         print(reps)\n",
    "#         sin_flip_comparison = calc_mov_avg(all_sin, 20, 1)\n",
    "#         cos_flip_comparison = calc_mov_avg(all_cos, 20, 1)\n",
    "\n",
    "#         is_flipped = np.logical_or(np.abs(all_sin - sin_flip_comparison) > 1, np.abs(all_cos - cos_flip_comparison) > 1)\n",
    "#         all_sin[is_flipped] = -1* all_sin[is_flipped]\n",
    "#         all_cos[is_flipped] = -1* all_cos[is_flipped]\n",
    "#         if plots_on:\n",
    "#             plt.subplot(2,1,1)\n",
    "#             plt.plot(all_frs, all_sin, '-k', alpha = 0.3)\n",
    "#             plt.plot(all_frs, all_sin, '.k', alpha = 0.3)\n",
    "#             plt.plot(all_frs, calc_mov_avg(all_sin, 20, 1), '.b', alpha = 0.3)\n",
    "#             plt.plot(all_frs, all_cos, '-k', alpha = 0.3)\n",
    "#             plt.plot(all_frs, all_cos, '.k', alpha = 0.3)\n",
    "#             plt.plot(all_frs, calc_mov_avg(all_cos, 20, 1), '.g', alpha = 0.3)\n",
    "        \n",
    "    all_sin_good = all_sin.copy()\n",
    "    all_cos_good = all_cos.copy()\n",
    "    all_sin_smooth = calc_mov_avg(all_sin_good, 10, 2)\n",
    "    all_cos_smooth = calc_mov_avg(all_cos_good, 10, 2)\n",
    "    all_angs_good = np.rad2deg(np.arctan2(all_sin_smooth, all_cos_smooth))\n",
    "\n",
    "    if plots_on:\n",
    "        plt.subplot(3,1,2)\n",
    "        plt.plot(all_frs, all_sin_good, '-k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_sin_good, '.k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_cos_good, '-k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_cos_good, '.k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_sin_smooth, '.g', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_cos_smooth, '.b', alpha = 0.3)\n",
    "        plt.subplot(3,1,3)\n",
    "        plt.plot(all_frs, all_angs, 'k', alpha = 0.3)\n",
    "        plt.plot(all_frs, all_angs_good, 'r')\n",
    "    return all_angs_good\n",
    "\n",
    "\n",
    "# # identify and flip any frames that are clearly facing towards the tail\n",
    "# def change_flipped_angles(obj, N, M, reps, plots_on = False):\n",
    "#     frs = obj['frames']\n",
    "#     raw_angs = obj['angle_improved']\n",
    "#     if np.sum(np.logical_not(np.isnan(raw_angs))) < 20:\n",
    "#         raw_angs = obj['angle']\n",
    "#         print(' -- not enough angle improved values, using contour angles')\n",
    "#     raw_angs_shift = (raw_angs+ 180)%360  \n",
    "#     angs = (raw_angs+180)%360 \n",
    "    \n",
    "#     for kk in range(0, reps):\n",
    "#         d_angs = np.diff(angs)\n",
    "#         d_angs_big = np.logical_and(d_angs>175, d_angs<185)\n",
    "#         nonan = np.logical_not(np.isnan(angs))\n",
    "#         angs_nonan = angs[nonan]\n",
    "#         frs_nonan = frs[nonan]\n",
    "#         # buffer edges with median of angle across whole trial\n",
    "#         angs_buff = np.insert(np.insert(angs_nonan, angs_nonan.size, np.ones(int(N/2+1))*np.nanmedian(angs)), 0, np.ones(int(N/2+1))*np.nanmedian(angs))\n",
    "#         # make mask so ignore nans in moving average\n",
    "#         mask = np.isnan(angs_buff)\n",
    "#         K = np.ones(int(N+M+1), dtype=int)\n",
    "#         K[int(N/2):int(N/2+M+1)]=0\n",
    "#         out = np.convolve(np.where(mask, 0, angs_buff), K, mode = 'same')/np.convolve(~mask,K, mode = 'same')\n",
    "#         wrong_way = np.logical_and(np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)])>150, np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)])<200)\n",
    "#         angs_nonan[wrong_way] = angs_nonan[wrong_way] \n",
    "#         new_angs = angs.copy()\n",
    "#         new_angs[nonan]=angs_nonan\n",
    "#         angs = new_angs\n",
    "# #     new_angs = new_angs-180\n",
    "        \n",
    "#     if plots_on:\n",
    "#         plt.figure()\n",
    "#         plt.subplot(2,1,1)\n",
    "#         plt.plot(frs, raw_angs, '.k')\n",
    "#         plt.subplot(2,1,2)\n",
    "#         plt.plot(frs, raw_angs_shift, '.k')\n",
    "#         plt.plot(frs, raw_angs_shift, '-k')\n",
    "#         plt.plot(frs, new_angs, '.r', MarkerSize =2)\n",
    "    \n",
    "#     return new_angs-180\n",
    "\n",
    "\n",
    "# average x,y,angle if isolated frame without head found (angle_improve = nan)\n",
    "def find_nan_gaps(arr, limit):  \n",
    "    from itertools import groupby\n",
    "    yy = np.isnan(arr)\n",
    "    xx = range(len(yy))\n",
    "    where_gapOI = np.full(arr.shape, False)\n",
    "    where_othergaps = np.full(arr.shape, False)\n",
    "    for k,g in groupby(iter(xx), lambda x: yy[x]):\n",
    "        if k == True: # if is a group of nan\n",
    "            g = list(g)\n",
    "            if any(x in g for x in [0, len(arr)-1]): # if first or last group\n",
    "                where_othergaps[np.array(g)]=True\n",
    "                continue       \n",
    "            if len(g)<= limit: # length is below limit\n",
    "                where_gapOI[np.array(g)]=True\n",
    "    return where_gapOI\n",
    "def find_interp_idcs(where_interpolate):\n",
    "    interp_idcs = []\n",
    "    for val in [-1,0,1]:\n",
    "        interp_idcs = np.concatenate([interp_idcs,np.where(where_interpolate)[0]+val])\n",
    "    interp_idcs = np.sort(np.array(list(set(interp_idcs)))) # get of repeat elements\n",
    "    interp_idcs = interp_idcs[np.logical_and(interp_idcs>-1, interp_idcs < len(where_interpolate))].astype(np.uint32) # only elements in range\n",
    "    return interp_idcs\n",
    "def interp_vals(arr, interp_idcs): # array includes nan values\n",
    "    temp = arr[interp_idcs]\n",
    "    interpolated_vals = np.interp(\n",
    "        interp_idcs, \n",
    "        interp_idcs[np.logical_not(np.isnan(temp))], temp[np.logical_not(np.isnan(temp))] )\n",
    "    interp = arr.copy()\n",
    "    interp[interp_idcs] = interpolated_vals\n",
    "    return interp\n",
    "# def averagexyangle(obj): # old version\n",
    "#     where_isolated_nan = np.where( np.concatenate(([False], \n",
    "#                                          np.diff(np.isnan(obj['angle_improved']).astype(np.float64) , 2)== -2, \n",
    "#                                          [False] )  ))[0]\n",
    "#     for idc in where_isolated_nan:\n",
    "#         entries_to_ave = [idc-1, idc+1]\n",
    "#         obj['x'][idc] = np.mean(obj['x'][entries_to_ave])\n",
    "#         obj['y'][idc] = np.mean(obj['y'][entries_to_ave])\n",
    "#         obj['angle_improved'][idc] = np.mean(obj['angle_improved'][entries_to_ave])\n",
    "#     return  obj\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through trials - MAIN BODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  --  /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180314_084502_16276712-0000.mp4\n",
      "tracking\n",
      "done\n",
      "-- folder already exists\n",
      "-- Saved .h5 file for ant 0\n",
      "-- Saved model predictions for ant 0 -- 10.2 s\n",
      "-- deleted .h5 file for ant 0\n",
      "-- Saved .h5 file for ant 1\n",
      "-- Saved model predictions for ant 1 -- 5.0 s\n",
      "-- deleted .h5 file for ant 1\n",
      "1  --  /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180314_084620_16276712-0000.mp4\n",
      "tracking\n",
      "done\n",
      "-- folder already exists\n",
      "-- Saved .h5 file for ant 0\n",
      "-- Saved model predictions for ant 0 -- 4.9 s\n",
      "-- deleted .h5 file for ant 0\n",
      "-- Saved .h5 file for ant 1\n",
      "-- Saved model predictions for ant 1 -- 4.6 s\n",
      "-- deleted .h5 file for ant 1\n",
      "-- Saved .h5 file for ant 2\n",
      "-- Saved model predictions for ant 2 -- 4.5 s\n",
      "-- deleted .h5 file for ant 2\n",
      "-- Saved .h5 file for ant 3\n",
      "-- Saved model predictions for ant 3 -- 4.8 s\n",
      "-- deleted .h5 file for ant 3\n",
      "not enough tracked frames. skipping ant 4\n",
      "-- Saved .h5 file for ant 5\n",
      "-- Saved model predictions for ant 5 -- 8.2 s\n",
      "-- deleted .h5 file for ant 5\n",
      "2  --  /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180314_084729_16276712-0000.mp4\n",
      "tracking\n",
      "done\n",
      "-- folder already exists\n",
      "-- Saved .h5 file for ant 0\n",
      "-- Saved model predictions for ant 0 -- 8.5 s\n",
      "-- deleted .h5 file for ant 0\n",
      "-- Saved .h5 file for ant 1\n",
      "-- Saved model predictions for ant 1 -- 4.6 s\n",
      "-- deleted .h5 file for ant 1\n",
      "not enough tracked frames. skipping ant 2\n",
      "not enough tracked frames. skipping ant 3\n",
      "not enough tracked frames. skipping ant 4\n",
      "not enough tracked frames. skipping ant 5\n",
      "not enough tracked frames. skipping ant 6\n",
      "not enough tracked frames. skipping ant 7\n",
      "not enough tracked frames. skipping ant 8\n",
      "not enough tracked frames. skipping ant 9\n",
      "not enough tracked frames. skipping ant 10\n",
      "not enough tracked frames. skipping ant 11\n",
      "not enough tracked frames. skipping ant 12\n",
      "-- Saved .h5 file for ant 13\n",
      "-- Saved model predictions for ant 13 -- 4.4 s\n",
      "-- deleted .h5 file for ant 13\n",
      "not enough tracked frames. skipping ant 14\n",
      "-- Saved .h5 file for ant 15\n",
      "-- Saved model predictions for ant 15 -- 4.7 s\n",
      "-- deleted .h5 file for ant 15\n",
      "not enough tracked frames. skipping ant 16\n",
      "3  --  /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180314_084931_16276712-0000.mp4\n",
      "tracking\n",
      "done\n",
      "-- folder already exists\n",
      "-- Saved .h5 file for ant 0\n",
      "-- Saved model predictions for ant 0 -- 7.8 s\n",
      "-- deleted .h5 file for ant 0\n",
      "4  --  /media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/1mm/20180314_085037_16276712-0000.mp4\n",
      "tracking\n",
      "done\n",
      "-- folder already exists\n",
      "-- Saved .h5 file for ant 0\n",
      "-- Saved model predictions for ant 0 -- 9.8 s\n",
      "-- deleted .h5 file for ant 0\n",
      "\n",
      "\n",
      "ALL DONE!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "\n",
    "track_vid = 1\n",
    "plot_compilation_fig = 0\n",
    "plot_rotated_img = 0\n",
    "plot_angle_fixes = False\n",
    "save_images = 0\n",
    "save_videos = 0\n",
    "save_hdf5 = 1\n",
    "run_model_predictions = 1\n",
    "\n",
    "# run SVM to determine L or R of each image\n",
    "print('Running PCA and making SVM model')\n",
    "pca, clf, target_names = run_SVM_for_LvR()\n",
    "print('\\n')\n",
    "\n",
    "starting_file = 0 # antennae files: 0, 400, 700, 900\n",
    "for kk, file in enumerate(file_list[starting_file:(starting_file+5)]):\n",
    "#     print(file, '***')\n",
    "\n",
    "    if kk%250 == 0:\n",
    "        sendtxt('analyzed %i videos'%kk)\n",
    "    \n",
    "    # track video to get up-to-date head finding\n",
    "    if track_vid:\n",
    "        video = track_video(file)\n",
    "    elif 'video' in globals():\n",
    "        if (video.videoname != file):\n",
    "            video = track_video(file)\n",
    "    else:\n",
    "        video = track_video(file)\n",
    "\n",
    "    # make folder for images if not already present\n",
    "    savelocation = make_image_folder(file)\n",
    "\n",
    "    # find video dimensions\n",
    "    x_dim = video.frames_normed[0].shape[1]\n",
    "    y_dim = video.frames_normed[0].shape[0]\n",
    "\n",
    "    # for each tracked ant\n",
    "    for obj_idx in range(0,len(video.objects)):\n",
    "#         print('Object %i'%obj_idx)\n",
    "        \n",
    "        allframes = []\n",
    "        \n",
    "        # limit to tracked ant data\n",
    "        obj_OI = video.objects[obj_idx].copy()\n",
    "        \n",
    "        # if only short fragment of trackway, don't track\n",
    "        if len(obj_OI['frames'])<50:\n",
    "            print('not enough tracked frames. skipping ant %i'%obj_idx)\n",
    "            continue\n",
    "           \n",
    "        # if ant is close to edges for most of trial, don't track\n",
    "        n_away_from_edge = np.sum(np.logical_not(np.any( # how many points aren't close to edge\n",
    "            np.abs([obj_OI['x']-video.Width/2,obj_OI['y']-video.Height/2]) > \n",
    "            np.array([video.Width/2 - 50,video.Height/2 - 50])[:,np.newaxis],axis=0) ))\n",
    "        if n_away_from_edge < 30:\n",
    "#             print('-- %i points far from edge. skipping ant %i'%(n_away_from_edge,obj_idx))\n",
    "            continue\n",
    "#         else:\n",
    "#             print('-- ant%i has %i points away from edge'%(obj_idx, n_away_from_edge))\n",
    "        \n",
    "    \n",
    "        # CORRECT FLIPPED ANGLES\n",
    "        obj_OI['angle_smooth'] =  find_flipped_angles_all(obj_OI, plots_on = plot_angle_fixes)\n",
    "#         obj_OI['angle_improved'] = change_flipped_angles(obj_OI, 20, 10, 4, plots_on = False) # old method\n",
    "        # average x,y,angle for gaps of <N nan\n",
    "        where_interp =find_nan_gaps(obj_OI['angle_improved'], 4)\n",
    "        if np.sum(where_interp)>0:\n",
    "            obj_OI['angle_smooth'] = interp_vals(obj_OI['angle_smooth'], \n",
    "                                                   find_interp_idcs(where_interp))\n",
    "        video.objects[obj_idx]['angle_improved']=obj_OI['angle_smooth'].copy()\n",
    "\n",
    "        \n",
    "\n",
    "        # rotate each frame and plot or save\n",
    "        for f_id, fr_num in enumerate(obj_OI['frames']):\n",
    "            \n",
    "            # if ant center is too close to a wall, make it an empty frame\n",
    "            if np.any( np.abs([obj_OI['x'][f_id]-video.Width/2, obj_OI['y'][f_id]-video.Height/2]) > \n",
    "                np.array([video.Width/2 - 50, video.Height/2 - 50]) ):\n",
    "                clean_frame = np.ones((200,200),dtype=np.uint8)\n",
    "#                 video.objects[obj_idx]['angle_improved'][f_id] = np.nan\n",
    "                \n",
    "            else:\n",
    "\n",
    "                buffer = 150 # how much pad around frame so that rotating zoomed in view keeps ant in center of frame?\n",
    "                frame, frame_zoom, rotated_zoom = rotate_and_zoom_frame(video, obj_OI, fr_num, buffer, x_dim, y_dim)\n",
    "\n",
    "                # adjust gain so that background is must darker than subject\n",
    "                gain_frame = adjust_gain(rotated_zoom, bkgd_cutoff = 5)\n",
    "\n",
    "                # get rid of contours\n",
    "                glenna= gain_frame.copy()\n",
    "                glenna[gain_frame>25]=1\n",
    "                glenna[gain_frame<=25]=0\n",
    "                kernel = cv2.getStructuringElement( cv2.MORPH_CROSS, (3,3))\n",
    "                glenna_close = cv2.morphologyEx(255*glenna.astype('uint8'), cv2.MORPH_CLOSE, kernel, iterations = 1)\n",
    "                _,contours,_ = cv2.findContours(glenna_close, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "                small_contours = [c for c in contours if cv2.contourArea(c) < 10]\n",
    "                large_contours = [c for c in contours if cv2.contourArea(c) > 30]\n",
    "                edge_contours = [c for c in contours if \n",
    "                                 np.any(np.logical_or(c == 1, c == 199))]\n",
    "#                 ant_contours = [c for c in large_contours if not\n",
    "#                                  np.any(np.logical_or(c == 1, c == 199))]\n",
    "\n",
    "                # remove contours touching the edge\n",
    "                clean_frame = gain_frame.copy()\n",
    "                clean_frame = cv2.drawContours(clean_frame, small_contours, -1, 3, -1)\n",
    "                clean_frame = cv2.drawContours(clean_frame, edge_contours, -1, 3, -1)\n",
    "\n",
    "                # if removed all ant-sized contours, make it a blank frame\n",
    "                if np.mean(clean_frame[95:105, 95:105]) < 100 :\n",
    "    #                 print('fr: %i - all ant blobs removed, %0.1f'%(fr_num, np.mean(clean_frame[95:105, 95:105])))\n",
    "                    clean_frame = np.ones((200,200),dtype=np.uint8)\n",
    "#                     video.objects[obj_idx]['angle_improved'][f_id] = np.nan\n",
    "\n",
    "#                 else: # if not blank, correct any flipped frames\n",
    "#                     # CORRECT ABBERANT ANGLES USING SVM\n",
    "#                     im_pca = pca.transform( np.reshape(clean_frame, [1, 200*200]))\n",
    "#                     im_pred = clf.predict(im_pca)\n",
    "\n",
    "#                     if target_names[im_pred] == 'Left' :\n",
    "#                         confs = clf.decision_function(im_pca)[0]\n",
    "#                         print('--- SVM thinks frame %0.0f is flipped. conf = %0.2f, %0.2f, %0.2f'%(fr_num, confs[0], confs[1], confs[2] ))\n",
    "#                         plt.figure()\n",
    "#                         plt.imshow(clean_frame)\n",
    "#                         apiojawg\n",
    "\n",
    "    #     #                 print(target_names[im_pred])\n",
    "    #     #                 plt.imshow(clean_frame)\n",
    "    #     #                 plt.figure()\n",
    "    #     #                 plt.imshow(np.fliplr(np.flipud(clean_frame)))\n",
    "    # #                     print('---- SVM thinks frame %0.0f is flipped, ang %0.1f'%(fr_num, fr_ang))\n",
    "    #                     if is_flipped:\n",
    "    # #                         print('---- comparison of sin/cos thinks frame %0.0f is flipped'%fr_num)\n",
    "    #                         clean_frame = np.fliplr(np.flipud(clean_frame))\n",
    "    #                         video.objects[obj_idx]['angle_improved'][f_id] = -1*np.sign(fr_ang)*(180-np.abs(fr_ang))\n",
    "    #                         print('----- switched frame %0.0f'%fr_num)\n",
    "\n",
    "                \n",
    "            allframes.append(clean_frame)\n",
    "                \n",
    "            if plot_compilation_fig:\n",
    "                plot_compilation_fig_fn(frame, frame_zoom, rotated_zoom, buffer)\n",
    "\n",
    "            if plot_rotated_img:\n",
    "                plot_rotated_img_fn(clean_frame, fr_num)\n",
    "                \n",
    "\n",
    "        # check if all video is backwards:\n",
    "        image_classifications = np.squeeze([clf.predict(pca.transform( np.reshape(im, [1, 200*200]))) for im in allframes[0:100]])\n",
    "        image_classifications = np.insert(image_classifications,0,[0,1,2]) # make sure has at least one 0, 1, and 2\n",
    "        classification_counts = np.bincount(image_classifications)\n",
    "#         print('R: ', classification_counts[target_names==\"Right\"], ' L: ', classification_counts[target_names==\"Left\"])\n",
    "        if classification_counts[target_names==\"Right\"] < classification_counts[target_names==\"Left\"]:\n",
    "            allframes = [np.fliplr(np.flipud(fr)) for fr in allframes]\n",
    "            video.objects[obj_idx]['angle_improved'] = video.objects[obj_idx]['angle_improved'] + 180\n",
    "            print('--- ant facing wrong way in video. flipping.')\n",
    "            \n",
    "        if save_images:\n",
    "            for ff,frame in enumerate(allframes):\n",
    "#                 if not np.max(rotated_zoom)==0:\n",
    "                fr_to_save = frame.astype(np.uint8) #((temp/np.max(temp)*255)-255).astype(np.uint8) #np.abs(((temp)/np.max(temp)*255)-255)\n",
    "                png.from_array(fr_to_save, 'L').save(\"%s/ant%i_fr%i.png\"%(savelocation, obj_idx, ff))\n",
    "\n",
    "            # save transparent ant cutouts for figure\n",
    "#             if obj_idx == 2:\n",
    "#                 frame_idcs = list(np.where(np.isin(video.objects[obj_idx]['frames'], [193,431]))[0])\n",
    "#                 print(frame_idcs)\n",
    "#                 for ff in frame_idcs: # save transparent cut-outs of ants for paper figure\n",
    "#                     frame = 255-allframes[ff]\n",
    "#                     rgb_frame = cv2.cvtColor(frame.astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "#                     rgba_frame = np.append(rgb_frame, 255*np.zeros((200,200))[:,:,np.newaxis].astype(np.uint8), axis=2).astype(np.uint8)\n",
    "#                     t_idcs=rgba_frame[:,:,0]>230\n",
    "#                     t_idcs_open = cv2.morphologyEx(t_idcs.astype(np.uint8), cv2.MORPH_OPEN, np.ones((3,3), np.uint8))\n",
    "#                     _,contours,_= cv2.findContours(t_idcs_open, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#                     tmp = np.zeros((200,200))\n",
    "#                     cv2.drawContours(tmp, contours, np.argmax(np.array([len(c) for c in contours])), 1, -1)\n",
    "#                     rgba_frame[:,:,3]=tmp*255\n",
    "#                     plt.figure()\n",
    "#                     plt.imshow(rgba_frame, cmap = 'gray')\n",
    "        \n",
    "        if save_videos:\n",
    "            save_video(savelocation, 'ant%i'%obj_idx)\n",
    "\n",
    "\n",
    "        # save as a hdf5 file\n",
    "        if save_hdf5:\n",
    "            temp =np.array([allframes])\n",
    "            temp = np.swapaxes(temp,0,1)\n",
    "            temp = np.swapaxes(temp,2,3)\n",
    "            hf = h5py.File(\"%s/ant%i.h5\"%(savelocation, obj_idx),'w')\n",
    "            hf.create_dataset('box', data=temp)\n",
    "            hf.close()\n",
    "            print('-- Saved .h5 file for ant %i'%obj_idx)\n",
    "#             video.save_JSON()\n",
    "#             video.associate_contours(max_covariance=10,\n",
    "#                              max_velocity=100,\n",
    "#                              n_covariances_to_reject=20, \n",
    "#                              max_tracked_objects=100,\n",
    "#                              kalman_state_cov=1,\n",
    "#                              kalman_init_cov=0.2,\n",
    "#                              kalman_measurement_cov=1)\n",
    "            video.save_association_JSON()\n",
    "#             print('-- re-saved contours and associated trackways for improved angle detection')\n",
    "            \n",
    "        if run_model_predictions:\n",
    "            start_time = time.time()\n",
    "            pfunc_path = '/home/gravishlab/Documents/MATLAB/leap/leap/predict_box.py'\n",
    "            h5_path = \"%s/ant%i.h5\"%(savelocation, obj_idx)\n",
    "#             model_path = '/home/gravishlab/Documents/MATLAB/leap/models/fast_train/180614_094549-n=209/final_model.h5'\n",
    "            model_path = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/models/180808_175924-n=679/final_model.h5'\n",
    "            save_path = \"%s/ant%i_predictions.h5\"%(savelocation, obj_idx)\n",
    "        \n",
    "#             # FOR ANTENNAE TRACKING\n",
    "#             model_path = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/models/180727_114754-n=428/final_model.h5'\n",
    "#             save_path = \"%s/ant%i_antennae_predictions.h5\"%(savelocation, obj_idx)\n",
    "        \n",
    "            command = \"python3 \\'%s\\' \\'%s\\' \\'%s\\' \\'%s\\' \"%(pfunc_path, h5_path, model_path, save_path)\n",
    "            \n",
    "            if os.path.exists(save_path):\n",
    "                os.remove(save_path)\n",
    "#             print(command)\n",
    "            os.system(command)\n",
    "            print('-- Saved model predictions for ant %i -- %0.1f s'%(obj_idx, time.time()-start_time))\n",
    "        \n",
    "            # remove .h5 because they're large\n",
    "            os.remove(h5_path)\n",
    "            print('-- deleted .h5 file for ant %i'%obj_idx)\n",
    "\n",
    "\n",
    "#     del video\n",
    "        \n",
    "print('\\n\\nALL DONE!!!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just run predictions on all files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080112_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.0 s\n",
      "-- Saved model predictions for ant 1 -- 11.0 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080315_16276736-0000\n",
      "-- Saved model predictions for ant 6 -- 5.4 s\n",
      "-- Saved model predictions for ant 7 -- 10.4 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080418_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.5 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080521_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.3 s\n",
      "-- Saved model predictions for ant 1 -- 10.0 s\n",
      "-- Saved model predictions for ant 11 -- 14.2 s\n",
      "-- Saved model predictions for ant 12 -- 18.1 s\n",
      "-- Saved model predictions for ant 15 -- 22.5 s\n",
      "-- Saved model predictions for ant 16 -- 27.0 s\n",
      "-- Saved model predictions for ant 2 -- 31.4 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080725_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 4.1 s\n",
      "-- Saved model predictions for ant 4 -- 9.7 s\n",
      "-- Saved model predictions for ant 5 -- 14.4 s\n",
      "-- Saved model predictions for ant 7 -- 18.3 s\n",
      "-- Saved model predictions for ant 8 -- 22.6 s\n",
      "-- Saved model predictions for ant 9 -- 26.8 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080829_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 6.8 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_081038_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.5 s\n",
      "-- Saved model predictions for ant 1 -- 9.8 s\n",
      "-- Saved model predictions for ant 2 -- 13.8 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_081139_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.7 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_081240_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.2 s\n",
      "/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_081350_16276736-0000\n",
      "-- Saved model predictions for ant 0 -- 5.0 s\n",
      "\n",
      "\n",
      "ALL DONE!!!\n"
     ]
    }
   ],
   "source": [
    "for kk, file in enumerate(file_list[0:10]):    \n",
    "    # make folder for images if not already present\n",
    "    basename = ('/').join(file.split('/')[:-1])\n",
    "    foldername = file.split('/')[-1].split('.')[0]\n",
    "    savelocation = ('/').join([basename, foldername])\n",
    "    print(savelocation)\n",
    "    if not os.path.exists(savelocation):\n",
    "        print('-- no folder! skipping... ')\n",
    "        continue\n",
    "      \n",
    "    \n",
    "    # find all ant files:\n",
    "    afiles = glob.glob(os.path.join(savelocation, 'ant*[0-9].h5'))\n",
    "#     print(afiles)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pfunc_path = '/home/gravishlab/Documents/MATLAB/leap/leap/predict_box.py'\n",
    "    model_path = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/models/180802_131333-n=639/final_model.h5'\n",
    "\n",
    "    for h5_path in afiles:\n",
    "#     h5_path = \"%s/ant%i.h5\"%(savelocation, obj_idx)\n",
    "# #             model_path = '/home/gravishlab/Documents/MATLAB/leap/models/fast_train/180614_094549-n=209/final_model.h5'\n",
    "        ant_num = h5_path.split('ant')[-1].split('.')[0]\n",
    "        save_path = \"%s/ant%s_predictions.h5\"%(savelocation, ant_num)\n",
    "        command = \"python3 \\'%s\\' \\'%s\\' \\'%s\\' \\'%s\\' \"%(pfunc_path, h5_path, model_path, save_path)\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)\n",
    "    #             print(command)\n",
    "        os.system(command)\n",
    "        print('-- Saved model predictions for ant %s -- %0.1f s'%(ant_num, time.time()-start_time))\n",
    "        \n",
    "print('\\n\\nALL DONE!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "1\n",
      "[]\n",
      "2\n",
      "[]\n",
      "3\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in greater\n",
      "  import sys\n",
      "/home/gravishlab/.virtualenvs/ants/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in less\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "plt.close('all')\n",
    "frs = video.objects[14]['frames']\n",
    "# plt.figure()\n",
    "# plt.plot(frs, video.objects[0]['angle_improved'],'k.')\n",
    "angs =video.objects[14]['angle_improved']%360 +180\n",
    "d_angs = np.diff(angs)\n",
    "d_angs_big = np.logical_and(d_angs>175, d_angs<185)\n",
    "plt.figure()\n",
    "plt.plot(frs,angs,'.b')\n",
    "plt.plot(frs,angs,'-b')\n",
    "\n",
    "plt.plot(frs[:-1][d_angs_big], angs[:-1][d_angs_big],'.r')\n",
    "\n",
    "N = 20\n",
    "M = 8\n",
    "reps = 4\n",
    "# key = np.ones((N+3,))/N\n",
    "# key[int(N/2-1):int(N/2+2)]=0\n",
    "# mask = np.isnan(angs)\n",
    "\n",
    "def remove_the_stuff(arr):\n",
    "    plt.figure()\n",
    "    plt.plot(frs,angs,'.b')\n",
    "    plt.plot(frs,angs,'-b')\n",
    "\n",
    "    nonan = np.logical_not(np.isnan(angs))\n",
    "    angs_nonan = angs[nonan]\n",
    "    frs_nonan = frs[nonan]\n",
    "    angs_buff = np.insert(np.insert(angs_nonan, angs_nonan.size, np.ones(int(N/2+1))*np.nanmedian(angs)), 0, np.ones(int(N/2+1))*np.nanmedian(angs))\n",
    "    # mov_ave = np.convolve(angs_buff, key, mode='valid')\n",
    "    # plt.plot(frs, mov_ave, ':g')\n",
    "\n",
    "    mask = np.isnan(angs_buff)\n",
    "    K = np.ones(int(N+M+1), dtype=int)\n",
    "    K[int(N/2):int(N/2+M+1)]=0\n",
    "    out = np.convolve(np.where(mask, 0, angs_buff), K, mode = 'same')/np.convolve(~mask,K, mode = 'same')\n",
    "    plt.plot(frs[np.logical_not(np.isnan(angs))], out[int(N/2+1):-int(N/2+1)], ':k')\n",
    "\n",
    "    plt.plot(frs[np.logical_not(np.isnan(angs))],np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)]),'-r')\n",
    "    wrong_way = np.logical_and(np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)])>150, np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)])<200)\n",
    "    print(frs_nonan[wrong_way])\n",
    "    angs_nonan[wrong_way] = (angs_nonan[wrong_way] - 180)%360\n",
    "    plt.plot(frs_nonan[wrong_way], angs_nonan[wrong_way], '.g')\n",
    "\n",
    "    new_angs = angs.copy()\n",
    "    new_angs[nonan]=angs_nonan\n",
    "    return new_angs\n",
    "\n",
    "for kk in range(0, reps):\n",
    "    print(kk)\n",
    "    angs = remove_the_stuff(angs)\n",
    "# plt.figure()\n",
    "# plt.plot(frs, new_angs, '.b')\n",
    "\n",
    "\n",
    "# N = 10 # how many points to look around (not including point of interest and direct neighbors)\n",
    "# nonan = np.logical_not(np.isnan(angs))\n",
    "# angs_nonan = angs[nonan]\n",
    "# frs_nonan = frs[nonan]\n",
    "# # buffer edges with median of angle across whole trial\n",
    "# angs_buff = np.insert(np.insert(angs_nonan, angs_nonan.size, np.ones(int(N/2+1))*np.nanmean(angs)), 0, np.ones(int(N/2+1))*np.nanmean(angs))\n",
    "# # make mask so ignore nans in moving average\n",
    "# mask = np.isnan(angs_buff)\n",
    "# K = np.ones(int(N+3), dtype=int)\n",
    "# K[int(N/2):int(N/2+3)]=0 # ignore pointOI and its neighbors\n",
    "# out = np.convolve(np.where(mask, 0, angs_buff), K, mode = 'same')/np.convolve(~mask,K, mode = 'same')\n",
    "# wrong_way = np.logical_and(np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)])>160, np.abs(angs_nonan-out[int(N/2+1):-int(N/2+1)])<200)\n",
    "# angs_nonan[wrong_way] = (angs_nonan[wrong_way] - 180)%360\n",
    "# new_angs = angs.copy()\n",
    "# new_angs[nonan]=angs_nonan\n",
    "# plt.figure()\n",
    "# plt.plot(frs, angs, '.k')\n",
    "# plt.plot(frs, new_angs, '.r', MarkerSize = 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load h5 file and get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"box\": shape (1500, 1, 192, 192), type \"|u1\">\n",
      "(1, 192, 192)\n",
      "<HDF5 dataset \"framesIdx\": shape (1, 1500), type \"<f8\">\n",
      "[210103. 162451. 329233. 122019. 107701. 158369. 337175. 231041. 226709.\n",
      " 210825.]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "hf = h5py.File('/home/gravishlab/Downloads/2018-05-03_cluster-sampled.k=10,n=150.h5','r')\n",
    "glenna = hf.get('box')\n",
    "print(glenna)\n",
    "print(glenna[0].shape)\n",
    "\n",
    "framesIDx = hf.get('framesIdx')\n",
    "print(framesIDx)\n",
    "print(framesIDx[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView(<HDF5 file \"ant1.h5\" (mode r)>)\n",
      "<HDF5 dataset \"box\": shape (589, 1, 200, 200), type \"<f8\">\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 200, 200)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf = h5py.File('/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080112_16276736-0000/ant1.h5','r')\n",
    "# hf = h5py.File('/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/0mm/20180313_080112_16276736-0000/training/ant0_fasttrain.h5','r')\n",
    "print(hf.keys())\n",
    "glenna = hf.get('box')\n",
    "print(glenna)\n",
    "glenna[0].shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine .h5 files to make larger training set - KEEP ALL SKELETON POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save combined .h5\n",
      "combined all .h5 labels\n"
     ]
    }
   ],
   "source": [
    "# import tracked h5s to combine\n",
    "base_folder = '/media/gravishlab/SeagateExpansionDrive/AntTrack/'\n",
    "# FILES FOR 180621_133300 --> FullTrainingSet_v1\n",
    "# tracked_files = [ \\\n",
    "#                   base_folder + 'Tunnel_20180313-14/0mm/20180313_080112_16276736-0000/ant0_wholeleg.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/0mm/20180313_080521_16276736-0000/ant1.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/1mm/20180313_080514_16276712-0000/ant5.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/1mm/20180313_081138_16276712-0000/ant0.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/3mm/20180313_095224_16276718-0000/ant0.h5']\n",
    "tracked_files = [ \\\n",
    "#                   base_folder + 'Tunnel_20180313-14/0mm/20180313_080112_16276736-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_080514_16276712-0000/ant5_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_081138_16276712-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_083905_16276712-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_084112_16276712-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/3mm/20180313_101520_16276718-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/5mm/20180313_105855_16276735-0000/ant0_wholeleg.h5']\n",
    "subsample = 1\n",
    "\n",
    "alltframes = np.empty((0,1,200,200))\n",
    "for tfile in tracked_files:\n",
    "    hf = h5py.File(tfile,'r')\n",
    "    box_info = hf.get('box').value\n",
    "    \n",
    "    mfile = tfile[:-2]+'labels.mat'\n",
    "    labeled_frames = loadmat(mfile, variable_names = 'positions')\n",
    "    if sum(np.logical_not(np.isnan(labeled_frames['positions'][0,0,:]))) > 200:\n",
    "        alltframes = np.append(alltframes, box_info[::2,:,:], axis=0)\n",
    "    else:\n",
    "        alltframes = np.append(alltframes, box_info[::subsample,:,:], axis=0)\n",
    "    hf.close()\n",
    "\n",
    "# save as a training model \n",
    "savefolder = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/'\n",
    "savelocation = savefolder+ 'Full_Training_Set.h5'\n",
    "hf = h5py.File(savelocation,'w')\n",
    "hf.create_dataset('box', data=alltframes)\n",
    "hf.close()\n",
    "print('save combined .h5')\n",
    "\n",
    "# combine labels mat files using matlab engine (can't import a table into python)\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.combine_skeleton_mat(tracked_files,savefolder,subsample)\n",
    "\n",
    "print('combined all .h5 labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine .h5 files to make larger training set - ONLY CERTAIN SKELETON POINTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled half\n",
      "(192, 1, 200, 200)\n",
      "(420, 1, 200, 200)\n",
      "(1060, 1, 200, 200)\n",
      "(1703, 1, 200, 200)\n",
      "(2135, 1, 200, 200)\n",
      "(2609, 1, 200, 200)\n",
      "(3174, 1, 200, 200)\n",
      "(3335, 1, 200, 200)\n",
      "(3912, 1, 200, 200)\n",
      "(4592, 1, 200, 200)\n",
      "(5061, 1, 200, 200)\n",
      "save combined .h5\n",
      "combined all .h5 labels\n"
     ]
    }
   ],
   "source": [
    "# import tracked h5s to combine\n",
    "base_folder = '/media/gravishlab/SeagateExpansionDrive/AntTrack/'\n",
    "# FILES FOR 180621_133300 --> FullTrainingSet_v1\n",
    "# tracked_files = [ \\\n",
    "#                   base_folder + 'Tunnel_20180313-14/0mm/20180313_080112_16276736-0000/ant0_wholeleg.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/0mm/20180313_080521_16276736-0000/ant1.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/1mm/20180313_080514_16276712-0000/ant5.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/1mm/20180313_081138_16276712-0000/ant0.h5',\n",
    "#                   base_folder + 'Tunnel_20180313-14/3mm/20180313_095224_16276718-0000/ant0.h5']\n",
    "tracked_files = [ \\\n",
    "                  base_folder + 'Tunnel_20180313-14/0mm/20180313_080112_16276736-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_080514_16276712-0000/ant5_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_081138_16276712-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_083905_16276712-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_083651_16276712-0000/ant0_onlyfeet.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/1mm/20180313_084112_16276712-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/3mm/20180313_101520_16276718-0000/ant0_wholeleg.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/3mm/20180313_095428_16276718-0000/ant0_onlyfeet.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/5mm/20180313_111526_16276735-0000/ant0_onlyfeet.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/5mm/20180313_112651_16276735-0000/ant0_onlyfeet.h5',\n",
    "                  base_folder + 'Tunnel_20180313-14/5mm/20180313_105855_16276735-0000/ant0_wholeleg.h5']\n",
    "subsample = 1\n",
    "\n",
    "alltframes = np.empty((0,1,200,200))\n",
    "for tfile in tracked_files:\n",
    "    hf = h5py.File(tfile,'r')\n",
    "    box_info = hf.get('box').value\n",
    "    \n",
    "    mfile = tfile[:-2]+'labels.mat'\n",
    "    labeled_frames = loadmat(mfile, variable_names = 'positions')\n",
    "    if sum(np.logical_not(np.isnan(labeled_frames['positions'][0,0,:]))) > 200:\n",
    "        alltframes = np.append(alltframes, box_info[::2,:,:], axis=0)\n",
    "        print('sampled half')\n",
    "    else:\n",
    "        alltframes = np.append(alltframes, box_info[::subsample,:,:], axis=0)\n",
    "    hf.close()\n",
    "    print(alltframes.shape)\n",
    "\n",
    "# save as a training model \n",
    "savefolder = '/media/gravishlab/SeagateExpansionDrive/AntTrack/LEAP_training/'\n",
    "savelocation = savefolder+ 'Full_Training_Set.h5'\n",
    "hf = h5py.File(savelocation,'w')\n",
    "hf.create_dataset('box', data=alltframes)\n",
    "hf.close()\n",
    "print('save combined .h5')\n",
    "\n",
    "\n",
    "# combine labels mat files using matlab engine (can't import a table into python)\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.combine_skeleton_mat_partialskel(tracked_files,savefolder,subsample)\n",
    "\n",
    "print('combined all .h5 labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot leg and antennae excursions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of untrustworthy points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = '/media/gravishlab/SeagateExpansionDrive/AntTrack/Tunnel_20180313-14/'\n",
    "predicted_files = glob.glob(os.path.join(vid_locations, 'Tunnel_20180313-14/**/*predictions.h5'))\n",
    "fileOI = predicted_files[3]\n",
    "print(fileOI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'excursions of distal limb points\\n0mm -- 20180313_081350_16276736-0000 -- ant0.h5')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot leg excursions\n",
    "\n",
    "ant_num = 0\n",
    "all_frames = [video.objects[obj]['frames'] for obj in video.objects]\n",
    "\n",
    "pfunc_path = '/home/gravishlab/Documents/MATLAB/leap/leap/predict_box.py'\n",
    "h5_path = \"%s/ant%i.h5\"%(savelocation, ant_num)\n",
    "model_path = '/home/gravishlab/Documents/MATLAB/leap/models/fast_train/180614_094549-n=209/final_model.h5'\n",
    "save_path = \"%s/ant%i_predictions.h5\"%(savelocation, ant_num)\n",
    "\n",
    "# hf_b = h5py.File(h5_path,'r')\n",
    "# box = hf_b.get('box')\n",
    "hf = h5py.File(save_path,'r')\n",
    "joint_loc = hf['positions_pred'][()].astype(np.float32) #hf.get('positions_pred')\n",
    "joint_conf = hf['conf_pred'][()] #hf.get('conf_pred')\n",
    "hf.close\n",
    "joint_bad = joint_conf<0.4\n",
    "joint_bad_idcs = np.swapaxes(np.tile(joint_bad,(2,1,1)), 0,1)\n",
    "joint_loc[joint_bad_idcs] = np.nan\n",
    "joint_loc = joint_loc-100\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,7],'-') # R forelimb\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,11],'-') # R midlimb\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,15],'-') # R hindlimb\n",
    "\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,19],'-') # L forelimb\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,23],'-') # L midlimb\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,27],'-') # L hindlimb\n",
    "\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('travel direction (pix)')\n",
    "plt.title('excursions of distal limb points\\n%s'%(' -- ').join(h5_path.split('/')[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'antennae placement\\n0mm -- 20180313_081350_16276736-0000 -- ant0.h5')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot antennae positions\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,28],'-b') # L antenna tip\n",
    "plt.plot(all_frames[ant_num], joint_loc[:,0,32],'-r') # R antenna tip\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('travel direction (pix)')\n",
    "plt.title('antennae placement\\n%s'%(' -- ').join(h5_path.split('/')[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
